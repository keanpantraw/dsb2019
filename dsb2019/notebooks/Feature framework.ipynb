{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from target_encoding import TargetEncoderClassifier, TargetEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from functools import reduce\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import json\n",
    "from functools import partial\n",
    "\n",
    "from dsb2019.models.tracking import track_experiment, track_submission_info\n",
    "from dsb2019.data.validation import InstallationFold, cross_validate, quad_kappa\n",
    "from dsb2019.visualization import session_browser\n",
    "from dsb2019.data import DATA_DIR\n",
    "from dsb2019.models import MODELS_DIR\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, Trials, tpe, STATUS_OK\n",
    "from pandas.testing import assert_frame_equal\n",
    "tqdm.pandas()\n",
    "pd.options.display.max_rows=999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsb2019.features import framework as feature_framework\n",
    "from dsb2019.features import game as game_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_DIR / 'raw/train.csv')\n",
    "test = pd.read_csv(DATA_DIR / 'raw/test.csv')\n",
    "train_labels = pd.read_csv(DATA_DIR / 'raw/train_labels.csv')\n",
    "submission = pd.read_csv(DATA_DIR / 'raw/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = ['Scrub-A-Dub', 'All Star Sorting', 'Mushroom Sorter (Assessment)',\n",
    "       'Air Show', 'Crystals Rule', 'Bird Measurer (Assessment)',\n",
    "       'Dino Drink', 'Bubble Bath', 'Dino Dive', 'Chow Time',\n",
    "       'Cauldron Filler (Assessment)', 'Pan Balance', 'Happy Camel',\n",
    "       'Cart Balancer (Assessment)', 'Chest Sorter (Assessment)',\n",
    "       'Leaf Leader']\n",
    "\n",
    "\n",
    "def unwrap_event_data(df):\n",
    "    unwrapped=pd.DataFrame(data=list(df.event_data.apply(json.loads).values))\n",
    "    return pd.concat([unwrapped.reset_index(),df.reset_index()],axis=1)\n",
    "\n",
    "\n",
    "def process_installations(train_labels, train, process_log):\n",
    "    result = []\n",
    "    train=train.sort_values(\"timestamp\")\n",
    "    installations = train.groupby(\"installation_id\")\n",
    "    for i, game_session, title, installation_id, accuracy_group in tqdm(train_labels[[\"game_session\", \"title\", \"installation_id\", \"accuracy_group\"]].itertuples(), \n",
    "                                                              total=len(train_labels)):\n",
    "        player_log = installations.get_group(installation_id).reset_index()\n",
    "        log_length = player_log[(player_log.game_session==game_session) & (player_log.title==title)].index[0]\n",
    "        player_log = player_log.iloc[:(log_length + 1)]\n",
    "        player_log[\"accuracy_group\"] = accuracy_group\n",
    "        player_log[\"target_game_session\"] = game_session\n",
    "        features = process_log(player_log)\n",
    "        features[\"installation_id\"] = installation_id\n",
    "        features[\"target_game_session\"] = game_session\n",
    "        features[\"accuracy_group\"] = accuracy_group\n",
    "        result.append(features)\n",
    "    return pd.DataFrame(data=result).fillna(-1)\n",
    " \n",
    "    \n",
    "def process_log(df):\n",
    "    assessment_title=df.title.iloc[-1]    \n",
    "\n",
    "    history = df.iloc[:-1]\n",
    "    history = history[history.type.isin([\"Game\", \"Assessment\"])].copy()\n",
    "\n",
    "    def calculate_ratios(df):\n",
    "        n_correct=df.correct_move.sum()\n",
    "        n_incorrect=df.wrong_move.sum()\n",
    "        ratio=n_correct/(n_correct+n_incorrect)\n",
    "        return n_correct, n_incorrect, ratio\n",
    "    \n",
    "    def make_move_stats(df, title,n_lags=2):\n",
    "        df=df.copy()\n",
    "        if len(df):\n",
    "            df = unwrap_event_data(df)\n",
    "        if \"correct\" in df.columns:\n",
    "            df[\"correct_move\"] = df.correct == True\n",
    "            df[\"wrong_move\"] = df.correct == False\n",
    "        else:\n",
    "            df[\"correct_move\"]=False\n",
    "            df[\"wrong_move\"]=False\n",
    "        result = []\n",
    "        result.extend(zip([f\"n_correct {title}\", f\"n_incorrect {title}\", f\"global_ratio {title}\"], calculate_ratios(df)))\n",
    "        if n_lags:\n",
    "            last_sessions = df.game_session.unique()[-n_lags:]\n",
    "            for i in range(n_lags):\n",
    "                if i < len(last_sessions): \n",
    "                    result.extend(zip([f\"n_correct {title} {i}\", f\"n_incorrect {title} {i}\",f\"ratio {title} {i}\"], \n",
    "                                      calculate_ratios(df[df.game_session==last_sessions[i]])))\n",
    "                else:\n",
    "                    result.extend(zip([f\"n_correct {title} {i}\", f\"n_incorrect {title} {i}\",f\"ratio {title} {i}\"], [None, None, None]))\n",
    "        return {k: v for k, v in result}\n",
    "    result = {\"title\": games.index(assessment_title)}\n",
    "    for game in games:\n",
    "        stats=history[history.title==game]\n",
    "        stats=make_move_stats(stats, game)\n",
    "        result.update(stats)\n",
    "    return result\n",
    "\n",
    "\n",
    "#train_features = process_installations(train_labels, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17690 [00:00<?, ?it/s]/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:42: RuntimeWarning: invalid value encountered in long_scalars\n",
      "100%|██████████| 17690/17690 [45:37<00:00,  6.46it/s] \n"
     ]
    }
   ],
   "source": [
    "gold_train_features = process_installations(train_labels, train, process_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_processor = feature_framework.LogProcessor([game_features.assessment_title], \n",
    "                                               {name: [partial(game_features.make_move_stats, title=name)] for name in game_features.games})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating tasks: 100%|██████████| 170/170 [00:33<00:00,  5.08it/s]\n",
      "Completing tasks: 100%|██████████| 170/170 [08:52<00:00,  3.13s/it]\n"
     ]
    }
   ],
   "source": [
    "framework_train_features = feature_framework.process_installations(train_labels, train, log_processor, n_jobs=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_train_features=gold_train_features[sorted(gold_train_features.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_train_features.sort_values([\"installation_id\", \"target_game_session\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "framework_train_features.sort_values([\"installation_id\", \"target_game_session\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "framework_train_features.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_frame_equal(gold_train_features, framework_train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I know they're equal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
