{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from target_encoding import TargetEncoderClassifier, TargetEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from functools import reduce\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import json\n",
    "from functools import partial\n",
    "\n",
    "from dsb2019.data.validation import InstallationFold, cross_validate\n",
    "from dsb2019.data import DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = ['event_id', 'game_session', 'installation_id', 'event_count', 'event_code', 'title', 'game_time', 'type', 'world']\n",
    "\n",
    "train = pd.read_csv(DATA_DIR / 'interim/train.csv', usecols=keep_cols)\n",
    "test = pd.read_csv(DATA_DIR / 'raw/test.csv', usecols=keep_cols)\n",
    "train_labels = pd.read_csv(DATA_DIR / 'raw/train_labels.csv')\n",
    "submission = pd.read_csv(DATA_DIR / 'raw/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_and_reduce(df):\n",
    "    # group1 and group2 are intermediary \"game session\" groups,\n",
    "    # which are reduced to one record by game session. group1 takes\n",
    "    # the max value of game_time (final game time in a session) and \n",
    "    # of event_count (total number of events happened in the session).\n",
    "    # group2 takes the total number of event_code of each type\n",
    "    group1 = df.drop(columns=['event_id', 'event_code']).groupby(\n",
    "        ['game_session', 'installation_id', 'title', 'type', 'world']\n",
    "    ).max().reset_index()\n",
    "\n",
    "    group2 = pd.get_dummies(\n",
    "        df[['installation_id', 'event_code']], \n",
    "        columns=['event_code']\n",
    "    ).groupby(['installation_id']).sum()\n",
    "\n",
    "    # group3, group4 and group5 are grouped by installation_id \n",
    "    # and reduced using summation and other summary stats\n",
    "    group3 = pd.get_dummies(\n",
    "        group1.drop(columns=['game_session', 'event_count', 'game_time']),\n",
    "        columns=['title', 'type', 'world']\n",
    "    ).groupby(['installation_id']).sum()\n",
    "\n",
    "    group4 = group1[\n",
    "        ['installation_id', 'event_count', 'game_time']\n",
    "    ].groupby(\n",
    "        ['installation_id']\n",
    "    ).agg([np.sum, np.mean, np.std])\n",
    "\n",
    "    return group2.join(group3).join(group4).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/reshape/merge.py:617: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4242, 101)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>installation_id</th>\n",
       "      <th>event_code_2000</th>\n",
       "      <th>event_code_2010</th>\n",
       "      <th>event_code_2020</th>\n",
       "      <th>event_code_2025</th>\n",
       "      <th>event_code_2030</th>\n",
       "      <th>event_code_2035</th>\n",
       "      <th>event_code_2040</th>\n",
       "      <th>event_code_2050</th>\n",
       "      <th>event_code_2060</th>\n",
       "      <th>...</th>\n",
       "      <th>world_CRYSTALCAVES</th>\n",
       "      <th>world_MAGMAPEAK</th>\n",
       "      <th>world_NONE</th>\n",
       "      <th>world_TREETOPCITY</th>\n",
       "      <th>(event_count, sum)</th>\n",
       "      <th>(event_count, mean)</th>\n",
       "      <th>(event_count, std)</th>\n",
       "      <th>(game_time, sum)</th>\n",
       "      <th>(game_time, mean)</th>\n",
       "      <th>(game_time, std)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006a69f</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3770</td>\n",
       "      <td>47.125000</td>\n",
       "      <td>58.443822</td>\n",
       "      <td>5539085</td>\n",
       "      <td>69238.562500</td>\n",
       "      <td>177339.983179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0006c192</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>73.771365</td>\n",
       "      <td>1847290</td>\n",
       "      <td>36945.800000</td>\n",
       "      <td>78711.834756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00129856</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>791</td>\n",
       "      <td>87.888889</td>\n",
       "      <td>94.013888</td>\n",
       "      <td>1021220</td>\n",
       "      <td>113468.888889</td>\n",
       "      <td>133732.656759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001d0ed0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>19.230769</td>\n",
       "      <td>47.561566</td>\n",
       "      <td>1206665</td>\n",
       "      <td>23205.096154</td>\n",
       "      <td>64354.986560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00225f67</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>921</td>\n",
       "      <td>36.840000</td>\n",
       "      <td>65.697971</td>\n",
       "      <td>823576</td>\n",
       "      <td>32943.040000</td>\n",
       "      <td>58550.909492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  installation_id  event_code_2000  event_code_2010  event_code_2020  \\\n",
       "0        0006a69f             80.0              3.0            110.0   \n",
       "1        0006c192             50.0              0.0             50.0   \n",
       "2        00129856              9.0              0.0             19.0   \n",
       "3        001d0ed0             52.0              3.0             51.0   \n",
       "4        00225f67             25.0              0.0             11.0   \n",
       "\n",
       "   event_code_2025  event_code_2030  event_code_2035  event_code_2040  \\\n",
       "0             12.0             95.0              8.0             21.0   \n",
       "1              2.0             44.0              2.0              6.0   \n",
       "2              1.0             17.0              0.0              0.0   \n",
       "3              2.0             44.0              2.0             10.0   \n",
       "4              3.0              9.0              0.0              0.0   \n",
       "\n",
       "   event_code_2050  event_code_2060  ...  world_CRYSTALCAVES  world_MAGMAPEAK  \\\n",
       "0             18.0              7.0  ...                 0.0             35.0   \n",
       "1              5.0              1.0  ...                13.0             15.0   \n",
       "2              0.0              0.0  ...                 2.0              3.0   \n",
       "3              9.0              0.0  ...                26.0              2.0   \n",
       "4              0.0              1.0  ...                 7.0              0.0   \n",
       "\n",
       "   world_NONE  world_TREETOPCITY  (event_count, sum)  (event_count, mean)  \\\n",
       "0         4.0               41.0                3770            47.125000   \n",
       "1         4.0               18.0                2025            40.500000   \n",
       "2         0.0                4.0                 791            87.888889   \n",
       "3         1.0               23.0                1000            19.230769   \n",
       "4         1.0               17.0                 921            36.840000   \n",
       "\n",
       "   (event_count, std)  (game_time, sum)  (game_time, mean)  (game_time, std)  \n",
       "0           58.443822           5539085       69238.562500     177339.983179  \n",
       "1           73.771365           1847290       36945.800000      78711.834756  \n",
       "2           94.013888           1021220      113468.888889     133732.656759  \n",
       "3           47.561566           1206665       23205.096154      64354.986560  \n",
       "4           65.697971            823576       32943.040000      58550.909492  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = group_and_reduce(train)\n",
    "test = group_and_reduce(test)\n",
    "\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_labels[['installation_id', 'accuracy_group']]\n",
    "train = train.merge(labels, how='left', on='installation_id').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(train, test, alpha=10, max_unique=50):\n",
    "    test = test.drop(\"accuracy_group\", axis=1)\n",
    "    len_uniques = []\n",
    "    train_labeled = train.fillna(-999)\n",
    "    test_labeled = test.fillna(-999)\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        train.drop(['installation_id', 'accuracy_group'], axis=1),\n",
    "        train['accuracy_group'],\n",
    "        test_size=0.15,\n",
    "        random_state=2019,\n",
    "    )\n",
    "    \n",
    "    for c in train.columns.drop(['installation_id', 'accuracy_group']):\n",
    "        le = LabelEncoder()\n",
    "        le.fit(pd.concat([train_labeled[c], test_labeled[c]])) \n",
    "        train_labeled[c] = le.transform(train_labeled[c])\n",
    "        test_labeled[c] = le.transform(test_labeled[c])\n",
    "        len_uniques.append(len(le.classes_))\n",
    "\n",
    "    x_train_labeled_ix, x_val_labeled_ix = train_test_split(\n",
    "        np.arange(len(train_labeled)),\n",
    "        test_size=0.15,\n",
    "        random_state=2019,\n",
    "    )\n",
    "    x_train_labeled = train_labeled.drop(['installation_id', 'accuracy_group'], axis=1).iloc[x_train_labeled_ix]\n",
    "    x_val_labeled = train_labeled.drop(['installation_id', 'accuracy_group'], axis=1).iloc[x_val_labeled_ix]\n",
    "    \n",
    "    cv = InstallationFold(train_labeled.installation_id.values[x_train_labeled_ix])\n",
    "\n",
    "    enc = TargetEncoder(alpha=alpha, max_unique=max_unique, split=[cv])\n",
    "    x_train_encoded = enc.transform_train(x_train_labeled, y=y_train)\n",
    "    x_val_encoded = enc.transform_test(x_val_labeled)\n",
    "    x_test_encoded = enc.transform_test(test.drop(['installation_id'], axis=1))\n",
    "\n",
    "    x_train_encoded = pd.DataFrame(x_train_encoded)\n",
    "    x_val_encoded = pd.DataFrame(x_val_encoded)\n",
    "    x_test_encoded = pd.DataFrame(x_test_encoded)\n",
    "\n",
    "    x_train_all = pd.concat([x_train.reset_index(drop=True), x_train_encoded], axis=1)\n",
    "    x_val_all = pd.concat([x_val.reset_index(drop=True), x_val_encoded], axis=1)\n",
    "    x_test_all = pd.concat([test.drop(['installation_id'], axis=1), x_test_encoded], axis=1)\n",
    "\n",
    "    return x_train_all, x_val_all, x_test_all, y_train, y_val\n",
    "\n",
    "\n",
    "def train_baseline(x_train_all,x_val_all,y_train,y_val):\n",
    "    train_set = lgb.Dataset(x_train_all, y_train)\n",
    "    val_set = lgb.Dataset(x_val_all, y_val)\n",
    "\n",
    "    params = {\n",
    "        'learning_rate': 0.01,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'feature_fraction': 0.9,\n",
    "        'num_leaves': 14,\n",
    "        'lambda_l1': 0.1,\n",
    "        'lambda_l2': 1,\n",
    "        'metric': 'multiclass',\n",
    "        'objective': 'multiclass',\n",
    "        'num_classes': 4,\n",
    "        'random_state': 2019\n",
    "    }\n",
    "\n",
    "    return lgb.train(params, train_set, num_boost_round=10000, early_stopping_rounds=300, valid_sets=[train_set, val_set], verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = InstallationFold()\n",
    "\n",
    "quad_kappa = partial(cohen_kappa_score, weights=\"quadratic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.13656\tvalid_1's multi_logloss: 1.13909\n",
      "[200]\ttraining's multi_logloss: 1.09596\tvalid_1's multi_logloss: 1.11357\n",
      "[300]\ttraining's multi_logloss: 1.06822\tvalid_1's multi_logloss: 1.09935\n",
      "[400]\ttraining's multi_logloss: 1.04797\tvalid_1's multi_logloss: 1.09277\n",
      "[500]\ttraining's multi_logloss: 1.03175\tvalid_1's multi_logloss: 1.08917\n",
      "[600]\ttraining's multi_logloss: 1.01818\tvalid_1's multi_logloss: 1.08674\n",
      "[700]\ttraining's multi_logloss: 1.00634\tvalid_1's multi_logloss: 1.08573\n",
      "[800]\ttraining's multi_logloss: 0.995825\tvalid_1's multi_logloss: 1.085\n",
      "[900]\ttraining's multi_logloss: 0.986284\tvalid_1's multi_logloss: 1.08475\n",
      "[1000]\ttraining's multi_logloss: 0.977567\tvalid_1's multi_logloss: 1.08499\n",
      "[1100]\ttraining's multi_logloss: 0.969572\tvalid_1's multi_logloss: 1.08557\n",
      "Early stopping, best iteration is:\n",
      "[855]\ttraining's multi_logloss: 0.990464\tvalid_1's multi_logloss: 1.08463\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.13544\tvalid_1's multi_logloss: 1.16683\n",
      "[200]\ttraining's multi_logloss: 1.09425\tvalid_1's multi_logloss: 1.13943\n",
      "[300]\ttraining's multi_logloss: 1.0667\tvalid_1's multi_logloss: 1.12443\n",
      "[400]\ttraining's multi_logloss: 1.04668\tvalid_1's multi_logloss: 1.11738\n",
      "[500]\ttraining's multi_logloss: 1.0307\tvalid_1's multi_logloss: 1.11392\n",
      "[600]\ttraining's multi_logloss: 1.01716\tvalid_1's multi_logloss: 1.11181\n",
      "[700]\ttraining's multi_logloss: 1.00516\tvalid_1's multi_logloss: 1.11051\n",
      "[800]\ttraining's multi_logloss: 0.994544\tvalid_1's multi_logloss: 1.10954\n",
      "[900]\ttraining's multi_logloss: 0.985115\tvalid_1's multi_logloss: 1.10907\n",
      "[1000]\ttraining's multi_logloss: 0.976372\tvalid_1's multi_logloss: 1.10924\n",
      "[1100]\ttraining's multi_logloss: 0.968347\tvalid_1's multi_logloss: 1.10987\n",
      "[1200]\ttraining's multi_logloss: 0.96091\tvalid_1's multi_logloss: 1.11036\n",
      "Early stopping, best iteration is:\n",
      "[929]\ttraining's multi_logloss: 0.982513\tvalid_1's multi_logloss: 1.10889\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.13058\tvalid_1's multi_logloss: 1.15412\n",
      "[200]\ttraining's multi_logloss: 1.08827\tvalid_1's multi_logloss: 1.13187\n",
      "[300]\ttraining's multi_logloss: 1.0596\tvalid_1's multi_logloss: 1.11951\n",
      "[400]\ttraining's multi_logloss: 1.03895\tvalid_1's multi_logloss: 1.11455\n",
      "[500]\ttraining's multi_logloss: 1.0226\tvalid_1's multi_logloss: 1.11164\n",
      "[600]\ttraining's multi_logloss: 1.00865\tvalid_1's multi_logloss: 1.1095\n",
      "[700]\ttraining's multi_logloss: 0.996561\tvalid_1's multi_logloss: 1.10865\n",
      "[800]\ttraining's multi_logloss: 0.986015\tvalid_1's multi_logloss: 1.10852\n",
      "[900]\ttraining's multi_logloss: 0.976402\tvalid_1's multi_logloss: 1.10914\n",
      "[1000]\ttraining's multi_logloss: 0.967753\tvalid_1's multi_logloss: 1.10956\n",
      "Early stopping, best iteration is:\n",
      "[757]\ttraining's multi_logloss: 0.990429\tvalid_1's multi_logloss: 1.10842\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.13668\tvalid_1's multi_logloss: 1.16555\n",
      "[200]\ttraining's multi_logloss: 1.09564\tvalid_1's multi_logloss: 1.14249\n",
      "[300]\ttraining's multi_logloss: 1.06755\tvalid_1's multi_logloss: 1.12997\n",
      "[400]\ttraining's multi_logloss: 1.04666\tvalid_1's multi_logloss: 1.12302\n",
      "[500]\ttraining's multi_logloss: 1.03026\tvalid_1's multi_logloss: 1.11938\n",
      "[600]\ttraining's multi_logloss: 1.01661\tvalid_1's multi_logloss: 1.1174\n",
      "[700]\ttraining's multi_logloss: 1.0047\tvalid_1's multi_logloss: 1.11657\n",
      "[800]\ttraining's multi_logloss: 0.994152\tvalid_1's multi_logloss: 1.11609\n",
      "[900]\ttraining's multi_logloss: 0.984615\tvalid_1's multi_logloss: 1.11599\n",
      "[1000]\ttraining's multi_logloss: 0.975847\tvalid_1's multi_logloss: 1.11607\n",
      "[1100]\ttraining's multi_logloss: 0.967564\tvalid_1's multi_logloss: 1.11647\n",
      "[1200]\ttraining's multi_logloss: 0.959931\tvalid_1's multi_logloss: 1.11701\n",
      "Early stopping, best iteration is:\n",
      "[944]\ttraining's multi_logloss: 0.980655\tvalid_1's multi_logloss: 1.11583\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.13031\tvalid_1's multi_logloss: 1.13614\n",
      "[200]\ttraining's multi_logloss: 1.08745\tvalid_1's multi_logloss: 1.11135\n",
      "[300]\ttraining's multi_logloss: 1.05918\tvalid_1's multi_logloss: 1.09934\n",
      "[400]\ttraining's multi_logloss: 1.0388\tvalid_1's multi_logloss: 1.09405\n",
      "[500]\ttraining's multi_logloss: 1.02246\tvalid_1's multi_logloss: 1.09124\n",
      "[600]\ttraining's multi_logloss: 1.00871\tvalid_1's multi_logloss: 1.08998\n",
      "[700]\ttraining's multi_logloss: 0.996953\tvalid_1's multi_logloss: 1.0899\n",
      "[800]\ttraining's multi_logloss: 0.986313\tvalid_1's multi_logloss: 1.08985\n",
      "[900]\ttraining's multi_logloss: 0.9768\tvalid_1's multi_logloss: 1.08979\n",
      "[1000]\ttraining's multi_logloss: 0.968114\tvalid_1's multi_logloss: 1.08961\n",
      "[1100]\ttraining's multi_logloss: 0.95996\tvalid_1's multi_logloss: 1.09011\n",
      "[1200]\ttraining's multi_logloss: 0.952424\tvalid_1's multi_logloss: 1.09082\n",
      "Early stopping, best iteration is:\n",
      "[937]\ttraining's multi_logloss: 0.973482\tvalid_1's multi_logloss: 1.08955\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.13474\tvalid_1's multi_logloss: 1.1289\n",
      "[200]\ttraining's multi_logloss: 1.09348\tvalid_1's multi_logloss: 1.1015\n",
      "[300]\ttraining's multi_logloss: 1.06576\tvalid_1's multi_logloss: 1.08783\n",
      "[400]\ttraining's multi_logloss: 1.04527\tvalid_1's multi_logloss: 1.08095\n",
      "[500]\ttraining's multi_logloss: 1.0288\tvalid_1's multi_logloss: 1.07722\n",
      "[600]\ttraining's multi_logloss: 1.01483\tvalid_1's multi_logloss: 1.07524\n",
      "[700]\ttraining's multi_logloss: 1.00273\tvalid_1's multi_logloss: 1.07429\n",
      "[800]\ttraining's multi_logloss: 0.992014\tvalid_1's multi_logloss: 1.0736\n",
      "[900]\ttraining's multi_logloss: 0.982297\tvalid_1's multi_logloss: 1.0731\n",
      "[1000]\ttraining's multi_logloss: 0.973462\tvalid_1's multi_logloss: 1.07294\n",
      "[1100]\ttraining's multi_logloss: 0.965346\tvalid_1's multi_logloss: 1.07338\n",
      "[1200]\ttraining's multi_logloss: 0.957644\tvalid_1's multi_logloss: 1.07382\n",
      "Early stopping, best iteration is:\n",
      "[962]\ttraining's multi_logloss: 0.97676\tvalid_1's multi_logloss: 1.07284\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.13148\tvalid_1's multi_logloss: 1.16014\n",
      "[200]\ttraining's multi_logloss: 1.08899\tvalid_1's multi_logloss: 1.13563\n",
      "[300]\ttraining's multi_logloss: 1.06038\tvalid_1's multi_logloss: 1.12164\n",
      "[400]\ttraining's multi_logloss: 1.03976\tvalid_1's multi_logloss: 1.11513\n",
      "[500]\ttraining's multi_logloss: 1.02338\tvalid_1's multi_logloss: 1.11176\n",
      "[600]\ttraining's multi_logloss: 1.00928\tvalid_1's multi_logloss: 1.10963\n",
      "[700]\ttraining's multi_logloss: 0.997155\tvalid_1's multi_logloss: 1.10978\n",
      "[800]\ttraining's multi_logloss: 0.986365\tvalid_1's multi_logloss: 1.10997\n",
      "[900]\ttraining's multi_logloss: 0.976743\tvalid_1's multi_logloss: 1.11026\n",
      "Early stopping, best iteration is:\n",
      "[624]\ttraining's multi_logloss: 1.00626\tvalid_1's multi_logloss: 1.10938\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.13423\tvalid_1's multi_logloss: 1.14867\n",
      "[200]\ttraining's multi_logloss: 1.09196\tvalid_1's multi_logloss: 1.12442\n",
      "[300]\ttraining's multi_logloss: 1.06438\tvalid_1's multi_logloss: 1.11235\n",
      "[400]\ttraining's multi_logloss: 1.04422\tvalid_1's multi_logloss: 1.10568\n",
      "[500]\ttraining's multi_logloss: 1.02812\tvalid_1's multi_logloss: 1.10195\n",
      "[600]\ttraining's multi_logloss: 1.01465\tvalid_1's multi_logloss: 1.09972\n",
      "[700]\ttraining's multi_logloss: 1.00277\tvalid_1's multi_logloss: 1.09851\n",
      "[800]\ttraining's multi_logloss: 0.992377\tvalid_1's multi_logloss: 1.0981\n",
      "[900]\ttraining's multi_logloss: 0.982975\tvalid_1's multi_logloss: 1.09818\n",
      "[1000]\ttraining's multi_logloss: 0.974404\tvalid_1's multi_logloss: 1.09853\n",
      "[1100]\ttraining's multi_logloss: 0.966534\tvalid_1's multi_logloss: 1.09898\n",
      "Early stopping, best iteration is:\n",
      "[842]\ttraining's multi_logloss: 0.988331\tvalid_1's multi_logloss: 1.09798\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.13777\tvalid_1's multi_logloss: 1.12727\n",
      "[200]\ttraining's multi_logloss: 1.09616\tvalid_1's multi_logloss: 1.09888\n",
      "[300]\ttraining's multi_logloss: 1.06833\tvalid_1's multi_logloss: 1.08429\n",
      "[400]\ttraining's multi_logloss: 1.04765\tvalid_1's multi_logloss: 1.07712\n",
      "[500]\ttraining's multi_logloss: 1.03124\tvalid_1's multi_logloss: 1.07313\n",
      "[600]\ttraining's multi_logloss: 1.01718\tvalid_1's multi_logloss: 1.07097\n",
      "[700]\ttraining's multi_logloss: 1.00532\tvalid_1's multi_logloss: 1.07039\n",
      "[800]\ttraining's multi_logloss: 0.994838\tvalid_1's multi_logloss: 1.07041\n",
      "[900]\ttraining's multi_logloss: 0.985367\tvalid_1's multi_logloss: 1.07062\n",
      "[1000]\ttraining's multi_logloss: 0.976632\tvalid_1's multi_logloss: 1.07116\n",
      "Early stopping, best iteration is:\n",
      "[773]\ttraining's multi_logloss: 0.997554\tvalid_1's multi_logloss: 1.0703\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.13422\tvalid_1's multi_logloss: 1.13762\n",
      "[200]\ttraining's multi_logloss: 1.09133\tvalid_1's multi_logloss: 1.1119\n",
      "[300]\ttraining's multi_logloss: 1.06269\tvalid_1's multi_logloss: 1.09776\n",
      "[400]\ttraining's multi_logloss: 1.04218\tvalid_1's multi_logloss: 1.09072\n",
      "[500]\ttraining's multi_logloss: 1.02569\tvalid_1's multi_logloss: 1.08747\n",
      "[600]\ttraining's multi_logloss: 1.01175\tvalid_1's multi_logloss: 1.08599\n",
      "[700]\ttraining's multi_logloss: 0.999581\tvalid_1's multi_logloss: 1.08498\n",
      "[800]\ttraining's multi_logloss: 0.988824\tvalid_1's multi_logloss: 1.0848\n",
      "[900]\ttraining's multi_logloss: 0.979102\tvalid_1's multi_logloss: 1.08521\n",
      "[1000]\ttraining's multi_logloss: 0.970231\tvalid_1's multi_logloss: 1.08576\n",
      "[1100]\ttraining's multi_logloss: 0.962047\tvalid_1's multi_logloss: 1.08589\n",
      "Early stopping, best iteration is:\n",
      "[828]\ttraining's multi_logloss: 0.986025\tvalid_1's multi_logloss: 1.08478\n"
     ]
    }
   ],
   "source": [
    "# def fit_fold(df, train_ix, test_ix):\n",
    "#     train = df.iloc[train_ix].reset_index().copy()\n",
    "#     test = df.iloc[test_ix].reset_index().copy()\n",
    "#     x_train_all, x_val_all, x_test_all, y_train, y_val = make_features(train, test)\n",
    "    \n",
    "#     baseline = train_baseline(x_train_all, y_train, x_val_all, y_val)\n",
    "#     test_pred = baseline.predict(x_test_all).argmax(axis=1)\n",
    "#     test_true = test.accuracy_group.values\n",
    "#     return test_true, test_pred\n",
    "\n",
    "\n",
    "# def cross_validate(train, labels):\n",
    "#     predicts = []\n",
    "#     for ix_train, ix_test in cv.split(train, labels, train.installation_id.values):\n",
    "#         predicts.append(fit_fold(train, ix_train, ix_test))\n",
    "#     return predicts\n",
    "\n",
    "\n",
    "def make_features_wrapper(train, test):\n",
    "    x_train_all, x_val_all, x_test_all, y_train, y_val = make_features(train, test)\n",
    "    return (x_train_all,x_val_all,y_train,y_val), (x_test_all,test.accuracy_group.values)\n",
    "\n",
    "def make_predictions(model,x_test_all,y_test):\n",
    "    pred=model.predict(x_test_all).argmax(axis=1)\n",
    "    return pred,y_test\n",
    "\n",
    "predicts=cross_validate(train, labels, make_features_wrapper,train_baseline,make_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.27011945695376877,\n",
       " [0.18795348797645461,\n",
       "  0.2391604057276987,\n",
       "  0.2483432873866015,\n",
       "  0.40894568508759244,\n",
       "  0.2814380333956784,\n",
       "  0.280771883268473,\n",
       "  0.28840192708756696,\n",
       "  0.25680617685981255,\n",
       "  0.20808903802526313,\n",
       "  0.3012846447225468])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([quad_kappa(true, pred) for pred, true in predicts]), [quad_kappa(true, pred) for pred, true in predicts]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
