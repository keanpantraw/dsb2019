{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from target_encoding import TargetEncoderClassifier, TargetEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from functools import reduce\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import json\n",
    "from functools import partial\n",
    "\n",
    "from dsb2019.data.validation import InstallationFold\n",
    "from dsb2019.data import DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = ['event_id', 'game_session', 'installation_id', 'event_count', 'event_code', 'title', 'game_time', 'type', 'world']\n",
    "\n",
    "train = pd.read_csv(DATA_DIR / 'raw/train.csv', usecols=keep_cols)\n",
    "test = pd.read_csv(DATA_DIR / 'raw/test.csv', usecols=keep_cols)\n",
    "train_labels = pd.read_csv(DATA_DIR / 'raw/train_labels.csv')\n",
    "submission = pd.read_csv(DATA_DIR / 'raw/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_and_reduce(df):\n",
    "    # group1 and group2 are intermediary \"game session\" groups,\n",
    "    # which are reduced to one record by game session. group1 takes\n",
    "    # the max value of game_time (final game time in a session) and \n",
    "    # of event_count (total number of events happened in the session).\n",
    "    # group2 takes the total number of event_code of each type\n",
    "    group1 = df.drop(columns=['event_id', 'event_code']).groupby(\n",
    "        ['game_session', 'installation_id', 'title', 'type', 'world']\n",
    "    ).max().reset_index()\n",
    "\n",
    "    group2 = pd.get_dummies(\n",
    "        df[['installation_id', 'event_code']], \n",
    "        columns=['event_code']\n",
    "    ).groupby(['installation_id']).sum()\n",
    "\n",
    "    # group3, group4 and group5 are grouped by installation_id \n",
    "    # and reduced using summation and other summary stats\n",
    "    group3 = pd.get_dummies(\n",
    "        group1.drop(columns=['game_session', 'event_count', 'game_time']),\n",
    "        columns=['title', 'type', 'world']\n",
    "    ).groupby(['installation_id']).sum()\n",
    "\n",
    "    group4 = group1[\n",
    "        ['installation_id', 'event_count', 'game_time']\n",
    "    ].groupby(\n",
    "        ['installation_id']\n",
    "    ).agg([np.sum, np.mean, np.std])\n",
    "\n",
    "    return group2.join(group3).join(group4).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/reshape/merge.py:617: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17000, 101)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>installation_id</th>\n",
       "      <th>event_code_2000</th>\n",
       "      <th>event_code_2010</th>\n",
       "      <th>event_code_2020</th>\n",
       "      <th>event_code_2025</th>\n",
       "      <th>event_code_2030</th>\n",
       "      <th>event_code_2035</th>\n",
       "      <th>event_code_2040</th>\n",
       "      <th>event_code_2050</th>\n",
       "      <th>event_code_2060</th>\n",
       "      <th>...</th>\n",
       "      <th>world_CRYSTALCAVES</th>\n",
       "      <th>world_MAGMAPEAK</th>\n",
       "      <th>world_NONE</th>\n",
       "      <th>world_TREETOPCITY</th>\n",
       "      <th>(event_count, sum)</th>\n",
       "      <th>(event_count, mean)</th>\n",
       "      <th>(event_count, std)</th>\n",
       "      <th>(game_time, sum)</th>\n",
       "      <th>(game_time, mean)</th>\n",
       "      <th>(game_time, std)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001e90f</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1357</td>\n",
       "      <td>135.700000</td>\n",
       "      <td>230.198972</td>\n",
       "      <td>1172787</td>\n",
       "      <td>117278.700000</td>\n",
       "      <td>182750.896625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000447c4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181</td>\n",
       "      <td>36.200000</td>\n",
       "      <td>54.182100</td>\n",
       "      <td>277707</td>\n",
       "      <td>55541.400000</td>\n",
       "      <td>80311.743287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0006a69f</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3801</td>\n",
       "      <td>47.512500</td>\n",
       "      <td>58.236531</td>\n",
       "      <td>5575453</td>\n",
       "      <td>69693.162500</td>\n",
       "      <td>177206.811293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006c192</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2224</td>\n",
       "      <td>44.480000</td>\n",
       "      <td>76.898619</td>\n",
       "      <td>2063664</td>\n",
       "      <td>41273.280000</td>\n",
       "      <td>82496.162713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0009a5a9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>412</td>\n",
       "      <td>58.857143</td>\n",
       "      <td>77.962445</td>\n",
       "      <td>1854998</td>\n",
       "      <td>264999.714286</td>\n",
       "      <td>627146.960108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  installation_id  event_code_2000  event_code_2010  event_code_2020  \\\n",
       "0        0001e90f             10.0              0.0             61.0   \n",
       "1        000447c4              5.0              0.0              3.0   \n",
       "2        0006a69f             80.0              4.0            112.0   \n",
       "3        0006c192             50.0              0.0             52.0   \n",
       "4        0009a5a9              7.0              0.0             10.0   \n",
       "\n",
       "   event_code_2025  event_code_2030  event_code_2035  event_code_2040  \\\n",
       "0              0.0             60.0              0.0             15.0   \n",
       "1              0.0              3.0              0.0              0.0   \n",
       "2             12.0             97.0              8.0             21.0   \n",
       "3              2.0             45.0              2.0              6.0   \n",
       "4              0.0              9.0              0.0              0.0   \n",
       "\n",
       "   event_code_2050  event_code_2060  ...  world_CRYSTALCAVES  world_MAGMAPEAK  \\\n",
       "0             15.0              1.0  ...                 0.0              7.0   \n",
       "1              0.0              1.0  ...                 0.0              4.0   \n",
       "2             18.0              7.0  ...                 0.0             35.0   \n",
       "3              5.0              1.0  ...                13.0             15.0   \n",
       "4              0.0              1.0  ...                 0.0              6.0   \n",
       "\n",
       "   world_NONE  world_TREETOPCITY  (event_count, sum)  (event_count, mean)  \\\n",
       "0         1.0                2.0                1357           135.700000   \n",
       "1         1.0                0.0                 181            36.200000   \n",
       "2         4.0               41.0                3801            47.512500   \n",
       "3         4.0               18.0                2224            44.480000   \n",
       "4         1.0                0.0                 412            58.857143   \n",
       "\n",
       "   (event_count, std)  (game_time, sum)  (game_time, mean)  (game_time, std)  \n",
       "0          230.198972           1172787      117278.700000     182750.896625  \n",
       "1           54.182100            277707       55541.400000      80311.743287  \n",
       "2           58.236531           5575453       69693.162500     177206.811293  \n",
       "3           76.898619           2063664       41273.280000      82496.162713  \n",
       "4           77.962445           1854998      264999.714286     627146.960108  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = group_and_reduce(train)\n",
    "test = group_and_reduce(test)\n",
    "\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_labels[['installation_id', 'accuracy_group']]\n",
    "train = train.merge(labels, how='left', on='installation_id').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(train, test, alpha=10, max_unique=50):\n",
    "    test = test.drop(\"accuracy_group\", axis=1)\n",
    "    len_uniques = []\n",
    "    train_labeled = train.fillna(-999)\n",
    "    test_labeled = test.fillna(-999)\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        train.drop(['installation_id', 'accuracy_group'], axis=1),\n",
    "        train['accuracy_group'],\n",
    "        test_size=0.15,\n",
    "        random_state=2019,\n",
    "    )\n",
    "    \n",
    "    for c in train.columns.drop(['installation_id', 'accuracy_group']):\n",
    "        le = LabelEncoder()\n",
    "        le.fit(pd.concat([train_labeled[c], test_labeled[c]])) \n",
    "        train_labeled[c] = le.transform(train_labeled[c])\n",
    "        test_labeled[c] = le.transform(test_labeled[c])\n",
    "        len_uniques.append(len(le.classes_))\n",
    "\n",
    "    x_train_labeled_ix, x_val_labeled_ix = train_test_split(\n",
    "        np.arange(len(train_labeled)),\n",
    "        test_size=0.15,\n",
    "        random_state=2019,\n",
    "    )\n",
    "    x_train_labeled = train_labeled.drop(['installation_id', 'accuracy_group'], axis=1).iloc[x_train_labeled_ix]\n",
    "    x_val_labeled = train_labeled.drop(['installation_id', 'accuracy_group'], axis=1).iloc[x_val_labeled_ix]\n",
    "    \n",
    "    cv = InstallationFold(train_labeled.installation_id.values[x_train_labeled_ix])\n",
    "\n",
    "    enc = TargetEncoder(alpha=alpha, max_unique=max_unique, split=[cv])\n",
    "    x_train_encoded = enc.transform_train(x_train_labeled, y=y_train)\n",
    "    x_val_encoded = enc.transform_test(x_val_labeled)\n",
    "    x_test_encoded = enc.transform_test(test.drop(['installation_id'], axis=1))\n",
    "\n",
    "    x_train_encoded = pd.DataFrame(x_train_encoded)\n",
    "    x_val_encoded = pd.DataFrame(x_val_encoded)\n",
    "    x_test_encoded = pd.DataFrame(x_test_encoded)\n",
    "\n",
    "    x_train_all = pd.concat([x_train.reset_index(drop=True), x_train_encoded], axis=1)\n",
    "    x_val_all = pd.concat([x_val.reset_index(drop=True), x_val_encoded], axis=1)\n",
    "    x_test_all = pd.concat([test.drop(['installation_id'], axis=1), x_test_encoded], axis=1)\n",
    "\n",
    "    return x_train_all, x_val_all, x_test_all, y_train, y_val\n",
    "\n",
    "\n",
    "def train_baseline(x_train_all, y_train, x_val_all, y_val):\n",
    "    train_set = lgb.Dataset(x_train_all, y_train)\n",
    "    val_set = lgb.Dataset(x_val_all, y_val)\n",
    "\n",
    "    params = {\n",
    "        'learning_rate': 0.01,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'feature_fraction': 0.9,\n",
    "        'num_leaves': 14,\n",
    "        'lambda_l1': 0.1,\n",
    "        'lambda_l2': 1,\n",
    "        'metric': 'multiclass',\n",
    "        'objective': 'multiclass',\n",
    "        'num_classes': 4,\n",
    "        'random_state': 2019\n",
    "    }\n",
    "\n",
    "    return lgb.train(params, train_set, num_boost_round=10000, early_stopping_rounds=300, valid_sets=[train_set, val_set], verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = InstallationFold()\n",
    "\n",
    "quad_kappa = partial(cohen_kappa_score, weights=\"quadratic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_fold(df, train_ix, test_ix):\n",
    "    train = df.iloc[train_ix].reset_index().copy()\n",
    "    test = df.iloc[test_ix].reset_index().copy()\n",
    "    x_train_all, x_val_all, x_test_all, y_train, y_val = make_features(train, test)\n",
    "    \n",
    "    baseline = train_baseline(x_train_all, y_train, x_val_all, y_val)\n",
    "    test_pred = baseline.predict(x_test_all).argmax(axis=1)\n",
    "    test_true = test.accuracy_group.values\n",
    "    return test_true, test_pred\n",
    "    \n",
    "def cross_validate(train, labels):\n",
    "    predicts = []\n",
    "    for ix_train, ix_test in cv.split(train, labels, train.installation_id.values):\n",
    "        predicts.append(fit_fold(train, ix_train, ix_test))\n",
    "    return predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.11235\tvalid_1's multi_logloss: 1.10856\n",
      "[200]\ttraining's multi_logloss: 1.06362\tvalid_1's multi_logloss: 1.0694\n",
      "[300]\ttraining's multi_logloss: 1.03288\tvalid_1's multi_logloss: 1.0498\n",
      "[400]\ttraining's multi_logloss: 1.01165\tvalid_1's multi_logloss: 1.04048\n",
      "[500]\ttraining's multi_logloss: 0.994967\tvalid_1's multi_logloss: 1.03497\n",
      "[600]\ttraining's multi_logloss: 0.981358\tvalid_1's multi_logloss: 1.03196\n",
      "[700]\ttraining's multi_logloss: 0.970015\tvalid_1's multi_logloss: 1.03006\n",
      "[800]\ttraining's multi_logloss: 0.959897\tvalid_1's multi_logloss: 1.02865\n",
      "[900]\ttraining's multi_logloss: 0.950783\tvalid_1's multi_logloss: 1.02795\n",
      "[1000]\ttraining's multi_logloss: 0.942395\tvalid_1's multi_logloss: 1.02806\n",
      "[1100]\ttraining's multi_logloss: 0.934777\tvalid_1's multi_logloss: 1.02855\n",
      "[1200]\ttraining's multi_logloss: 0.927858\tvalid_1's multi_logloss: 1.02925\n",
      "Early stopping, best iteration is:\n",
      "[925]\ttraining's multi_logloss: 0.948652\tvalid_1's multi_logloss: 1.02781\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.11105\tvalid_1's multi_logloss: 1.14059\n",
      "[200]\ttraining's multi_logloss: 1.06231\tvalid_1's multi_logloss: 1.0999\n",
      "[300]\ttraining's multi_logloss: 1.03161\tvalid_1's multi_logloss: 1.07741\n",
      "[400]\ttraining's multi_logloss: 1.00994\tvalid_1's multi_logloss: 1.0672\n",
      "[500]\ttraining's multi_logloss: 0.99368\tvalid_1's multi_logloss: 1.06271\n",
      "[600]\ttraining's multi_logloss: 0.979772\tvalid_1's multi_logloss: 1.06004\n",
      "[700]\ttraining's multi_logloss: 0.967995\tvalid_1's multi_logloss: 1.05763\n",
      "[800]\ttraining's multi_logloss: 0.957848\tvalid_1's multi_logloss: 1.05633\n",
      "[900]\ttraining's multi_logloss: 0.948925\tvalid_1's multi_logloss: 1.05543\n",
      "[1000]\ttraining's multi_logloss: 0.940885\tvalid_1's multi_logloss: 1.05533\n",
      "[1100]\ttraining's multi_logloss: 0.933564\tvalid_1's multi_logloss: 1.05578\n",
      "[1200]\ttraining's multi_logloss: 0.926825\tvalid_1's multi_logloss: 1.05588\n",
      "Early stopping, best iteration is:\n",
      "[984]\ttraining's multi_logloss: 0.942088\tvalid_1's multi_logloss: 1.05514\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.10554\tvalid_1's multi_logloss: 1.12775\n",
      "[200]\ttraining's multi_logloss: 1.05481\tvalid_1's multi_logloss: 1.09377\n",
      "[300]\ttraining's multi_logloss: 1.02289\tvalid_1's multi_logloss: 1.07599\n",
      "[400]\ttraining's multi_logloss: 1.00101\tvalid_1's multi_logloss: 1.06842\n",
      "[500]\ttraining's multi_logloss: 0.984181\tvalid_1's multi_logloss: 1.06476\n",
      "[600]\ttraining's multi_logloss: 0.970311\tvalid_1's multi_logloss: 1.06196\n",
      "[700]\ttraining's multi_logloss: 0.958687\tvalid_1's multi_logloss: 1.06026\n",
      "[800]\ttraining's multi_logloss: 0.948344\tvalid_1's multi_logloss: 1.05964\n",
      "[900]\ttraining's multi_logloss: 0.93941\tvalid_1's multi_logloss: 1.05961\n",
      "[1000]\ttraining's multi_logloss: 0.931374\tvalid_1's multi_logloss: 1.06001\n",
      "[1100]\ttraining's multi_logloss: 0.92396\tvalid_1's multi_logloss: 1.06028\n",
      "Early stopping, best iteration is:\n",
      "[859]\ttraining's multi_logloss: 0.942957\tvalid_1's multi_logloss: 1.05953\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.1123\tvalid_1's multi_logloss: 1.13233\n",
      "[200]\ttraining's multi_logloss: 1.06245\tvalid_1's multi_logloss: 1.09628\n",
      "[300]\ttraining's multi_logloss: 1.03102\tvalid_1's multi_logloss: 1.07746\n",
      "[400]\ttraining's multi_logloss: 1.00929\tvalid_1's multi_logloss: 1.06917\n",
      "[500]\ttraining's multi_logloss: 0.992775\tvalid_1's multi_logloss: 1.06454\n",
      "[600]\ttraining's multi_logloss: 0.979241\tvalid_1's multi_logloss: 1.06188\n",
      "[700]\ttraining's multi_logloss: 0.967678\tvalid_1's multi_logloss: 1.0597\n",
      "[800]\ttraining's multi_logloss: 0.957542\tvalid_1's multi_logloss: 1.05873\n",
      "[900]\ttraining's multi_logloss: 0.948358\tvalid_1's multi_logloss: 1.05793\n",
      "[1000]\ttraining's multi_logloss: 0.939908\tvalid_1's multi_logloss: 1.05764\n",
      "[1100]\ttraining's multi_logloss: 0.932257\tvalid_1's multi_logloss: 1.05768\n",
      "[1200]\ttraining's multi_logloss: 0.925222\tvalid_1's multi_logloss: 1.05802\n",
      "[1300]\ttraining's multi_logloss: 0.918863\tvalid_1's multi_logloss: 1.05858\n",
      "Early stopping, best iteration is:\n",
      "[1040]\ttraining's multi_logloss: 0.936723\tvalid_1's multi_logloss: 1.05752\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.10564\tvalid_1's multi_logloss: 1.11122\n",
      "[200]\ttraining's multi_logloss: 1.05438\tvalid_1's multi_logloss: 1.07639\n",
      "[300]\ttraining's multi_logloss: 1.02238\tvalid_1's multi_logloss: 1.05821\n",
      "[400]\ttraining's multi_logloss: 1.00073\tvalid_1's multi_logloss: 1.05004\n",
      "[500]\ttraining's multi_logloss: 0.983956\tvalid_1's multi_logloss: 1.04524\n",
      "[600]\ttraining's multi_logloss: 0.970213\tvalid_1's multi_logloss: 1.04334\n",
      "[700]\ttraining's multi_logloss: 0.958718\tvalid_1's multi_logloss: 1.04252\n",
      "[800]\ttraining's multi_logloss: 0.948401\tvalid_1's multi_logloss: 1.04236\n",
      "[900]\ttraining's multi_logloss: 0.939055\tvalid_1's multi_logloss: 1.04226\n",
      "[1000]\ttraining's multi_logloss: 0.930748\tvalid_1's multi_logloss: 1.04267\n",
      "[1100]\ttraining's multi_logloss: 0.923141\tvalid_1's multi_logloss: 1.0433\n",
      "Early stopping, best iteration is:\n",
      "[867]\ttraining's multi_logloss: 0.942018\tvalid_1's multi_logloss: 1.04212\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.10897\tvalid_1's multi_logloss: 1.10236\n",
      "[200]\ttraining's multi_logloss: 1.05921\tvalid_1's multi_logloss: 1.06255\n",
      "[300]\ttraining's multi_logloss: 1.02837\tvalid_1's multi_logloss: 1.04199\n",
      "[400]\ttraining's multi_logloss: 1.00626\tvalid_1's multi_logloss: 1.03238\n",
      "[500]\ttraining's multi_logloss: 0.989418\tvalid_1's multi_logloss: 1.02795\n",
      "[600]\ttraining's multi_logloss: 0.975718\tvalid_1's multi_logloss: 1.02516\n",
      "[700]\ttraining's multi_logloss: 0.964342\tvalid_1's multi_logloss: 1.02333\n",
      "[800]\ttraining's multi_logloss: 0.954379\tvalid_1's multi_logloss: 1.02295\n",
      "[900]\ttraining's multi_logloss: 0.945442\tvalid_1's multi_logloss: 1.02298\n",
      "[1000]\ttraining's multi_logloss: 0.937278\tvalid_1's multi_logloss: 1.02306\n",
      "Early stopping, best iteration is:\n",
      "[769]\ttraining's multi_logloss: 0.957352\tvalid_1's multi_logloss: 1.02286\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.10677\tvalid_1's multi_logloss: 1.13153\n",
      "[200]\ttraining's multi_logloss: 1.05594\tvalid_1's multi_logloss: 1.09737\n",
      "[300]\ttraining's multi_logloss: 1.02421\tvalid_1's multi_logloss: 1.08026\n",
      "[400]\ttraining's multi_logloss: 1.00261\tvalid_1's multi_logloss: 1.07176\n",
      "[500]\ttraining's multi_logloss: 0.986172\tvalid_1's multi_logloss: 1.06751\n",
      "[600]\ttraining's multi_logloss: 0.972168\tvalid_1's multi_logloss: 1.06511\n",
      "[700]\ttraining's multi_logloss: 0.96027\tvalid_1's multi_logloss: 1.06416\n",
      "[800]\ttraining's multi_logloss: 0.949875\tvalid_1's multi_logloss: 1.06359\n",
      "[900]\ttraining's multi_logloss: 0.940502\tvalid_1's multi_logloss: 1.06319\n",
      "[1000]\ttraining's multi_logloss: 0.931991\tvalid_1's multi_logloss: 1.06319\n",
      "[1100]\ttraining's multi_logloss: 0.924481\tvalid_1's multi_logloss: 1.06349\n",
      "[1200]\ttraining's multi_logloss: 0.917505\tvalid_1's multi_logloss: 1.0643\n",
      "Early stopping, best iteration is:\n",
      "[954]\ttraining's multi_logloss: 0.93576\tvalid_1's multi_logloss: 1.06292\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.11059\tvalid_1's multi_logloss: 1.11398\n",
      "[200]\ttraining's multi_logloss: 1.06019\tvalid_1's multi_logloss: 1.07923\n",
      "[300]\ttraining's multi_logloss: 1.0285\tvalid_1's multi_logloss: 1.06078\n",
      "[400]\ttraining's multi_logloss: 1.00661\tvalid_1's multi_logloss: 1.05134\n",
      "[500]\ttraining's multi_logloss: 0.990168\tvalid_1's multi_logloss: 1.04646\n",
      "[600]\ttraining's multi_logloss: 0.976609\tvalid_1's multi_logloss: 1.04313\n",
      "[700]\ttraining's multi_logloss: 0.965065\tvalid_1's multi_logloss: 1.04147\n",
      "[800]\ttraining's multi_logloss: 0.954844\tvalid_1's multi_logloss: 1.04045\n",
      "[900]\ttraining's multi_logloss: 0.945779\tvalid_1's multi_logloss: 1.03994\n",
      "[1000]\ttraining's multi_logloss: 0.937565\tvalid_1's multi_logloss: 1.03946\n",
      "[1100]\ttraining's multi_logloss: 0.930009\tvalid_1's multi_logloss: 1.03927\n",
      "[1200]\ttraining's multi_logloss: 0.922924\tvalid_1's multi_logloss: 1.03928\n",
      "[1300]\ttraining's multi_logloss: 0.916572\tvalid_1's multi_logloss: 1.03958\n",
      "[1400]\ttraining's multi_logloss: 0.910544\tvalid_1's multi_logloss: 1.03972\n",
      "Early stopping, best iteration is:\n",
      "[1174]\ttraining's multi_logloss: 0.924719\tvalid_1's multi_logloss: 1.03919\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.1107\tvalid_1's multi_logloss: 1.09532\n",
      "[200]\ttraining's multi_logloss: 1.06092\tvalid_1's multi_logloss: 1.05569\n",
      "[300]\ttraining's multi_logloss: 1.0298\tvalid_1's multi_logloss: 1.03679\n",
      "[400]\ttraining's multi_logloss: 1.00816\tvalid_1's multi_logloss: 1.0266\n",
      "[500]\ttraining's multi_logloss: 0.991524\tvalid_1's multi_logloss: 1.02108\n",
      "[600]\ttraining's multi_logloss: 0.977787\tvalid_1's multi_logloss: 1.01847\n",
      "[700]\ttraining's multi_logloss: 0.966196\tvalid_1's multi_logloss: 1.01777\n",
      "[800]\ttraining's multi_logloss: 0.956257\tvalid_1's multi_logloss: 1.01757\n",
      "[900]\ttraining's multi_logloss: 0.947412\tvalid_1's multi_logloss: 1.0171\n",
      "[1000]\ttraining's multi_logloss: 0.939347\tvalid_1's multi_logloss: 1.01689\n",
      "[1100]\ttraining's multi_logloss: 0.932096\tvalid_1's multi_logloss: 1.01714\n",
      "[1200]\ttraining's multi_logloss: 0.925353\tvalid_1's multi_logloss: 1.01777\n",
      "Early stopping, best iteration is:\n",
      "[967]\ttraining's multi_logloss: 0.941902\tvalid_1's multi_logloss: 1.01683\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.10854\tvalid_1's multi_logloss: 1.11218\n",
      "[200]\ttraining's multi_logloss: 1.05756\tvalid_1's multi_logloss: 1.07535\n",
      "[300]\ttraining's multi_logloss: 1.02561\tvalid_1's multi_logloss: 1.05625\n",
      "[400]\ttraining's multi_logloss: 1.00395\tvalid_1's multi_logloss: 1.04752\n",
      "[500]\ttraining's multi_logloss: 0.987259\tvalid_1's multi_logloss: 1.04251\n",
      "[600]\ttraining's multi_logloss: 0.973742\tvalid_1's multi_logloss: 1.03985\n",
      "[700]\ttraining's multi_logloss: 0.962229\tvalid_1's multi_logloss: 1.03862\n",
      "[800]\ttraining's multi_logloss: 0.952085\tvalid_1's multi_logloss: 1.03791\n",
      "[900]\ttraining's multi_logloss: 0.943068\tvalid_1's multi_logloss: 1.03766\n",
      "[1000]\ttraining's multi_logloss: 0.934981\tvalid_1's multi_logloss: 1.03758\n",
      "[1100]\ttraining's multi_logloss: 0.92769\tvalid_1's multi_logloss: 1.03797\n",
      "[1200]\ttraining's multi_logloss: 0.920961\tvalid_1's multi_logloss: 1.0382\n",
      "Early stopping, best iteration is:\n",
      "[949]\ttraining's multi_logloss: 0.938956\tvalid_1's multi_logloss: 1.03747\n"
     ]
    }
   ],
   "source": [
    "predicts=cross_validate(train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3071532214638171,\n",
       " [0.2375982917000612,\n",
       "  0.2817551273901412,\n",
       "  0.2884058957825951,\n",
       "  0.37506980052225725,\n",
       "  0.327665424307657,\n",
       "  0.31855081202573343,\n",
       "  0.3268631029814445,\n",
       "  0.29580476447634674,\n",
       "  0.27366115354439946,\n",
       "  0.3461578419075352])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([quad_kappa(true, pred) for pred, true in predicts]), [quad_kappa(true, pred) for pred, true in predicts]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
