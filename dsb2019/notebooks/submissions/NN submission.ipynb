{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "class NN:\n",
    "    def __init__(self, **params):\n",
    "        self.params = params\n",
    "        self.learning_rate = params[\"learning_rate\"]\n",
    "        self.file_path = str(params[\"file_path\"])\n",
    "        self.scaler = params[\"scaler\"]\n",
    "        dense_size = params[\"dense_size\"]\n",
    "        n_layers = params[\"n_layers\"]\n",
    "        dropout_prob = params[\"dropout_prob\"]\n",
    "        input_size = params[\"input_size\"]\n",
    "        \n",
    "        dense_sizes = np.linspace(dense_size, 1, num=n_layers+1, dtype=int)[:-1]\n",
    "        \n",
    "        def layer(size, dropout_prob):\n",
    "            return [tf.keras.layers.Dense(dense_size, activation='relu'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dropout(dropout_prob)]\n",
    "\n",
    "        layers = [tf.keras.layers.Input(shape=(input_size,))]\n",
    "        for dense_size in dense_sizes:\n",
    "            layers.extend(layer(dense_size, dropout_prob))\n",
    "        layers.append(tf.keras.layers.Dense(1, activation='relu'))\n",
    "        self.model = tf.keras.models.Sequential(layers)\n",
    "\n",
    "    def fit(self, x_train, y_train, epochs=1000, patience=200): #yo shall be used just like lgb guess ya?\n",
    "        x_train_all, x_val_all,y_train_all,y_val_all = train_test_split(\n",
    "            x_train,y_train,\n",
    "            test_size=0.15,\n",
    "            random_state=2019,\n",
    "        )\n",
    "        self.scaler.fit(x_train_all.values)\n",
    "\n",
    "        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=self.learning_rate), loss='mse')\n",
    "        \n",
    "        save_best = tf.keras.callbacks.ModelCheckpoint(self.file_path, save_weights_only=True, save_best_only=True, verbose=0)\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(patience=patience)\n",
    "        reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                                    patience=100, min_lr=0.0001)\n",
    "\n",
    "        base_learning_rate = self.learning_rate\n",
    "        divisor = np.linspace(2, 8, num=epochs)\n",
    "        period = 100\n",
    "        _2pi = np.pi * 2\n",
    "        all_epochs = np.arange(0, epochs)\n",
    "        schedule = np.sin(_2pi * all_epochs / period) * base_learning_rate/divisor + base_learning_rate\n",
    "\n",
    "        #plt.plot(all_epochs, schedule)\n",
    "\n",
    "        def get_learning_rate(epoch):\n",
    "            return schedule[epoch]\n",
    "\n",
    "\n",
    "        scheduler = tf.keras.callbacks.LearningRateScheduler(get_learning_rate)\n",
    "        class Metrics(tf.keras.callbacks.Callback):\n",
    "            def on_epoch_end(self, epoch, logs={}):\n",
    "                if epoch % 50 == 0:\n",
    "                    print(f\"Epoch {epoch} loss={logs['loss']} val_loss={logs['val_loss']}\")\n",
    "\n",
    "        reporter=Metrics()\n",
    "        self.model.fit(self.scaler.transform(x_train_all.astype(np.float64)), \n",
    "                y_train_all, \n",
    "                validation_data=(self.scaler.transform(x_val_all.astype(np.float64)), y_val_all),\n",
    "                epochs=epochs,\n",
    "                 callbacks=[save_best, early_stop, reporter, reduce_lr, scheduler], verbose=0, batch_size=x_train_all.shape[0])\n",
    "        self.model.load_weights(self.file_path)\n",
    "\n",
    "    def load_weights(self):\n",
    "        self.model.load_weights(str(self.file_path))\n",
    "\n",
    "    @staticmethod\n",
    "    def load(model_path):\n",
    "        weights_path = str(model_path) + \"_weights\"\n",
    "        with open(model_path, \"rb\") as f:\n",
    "            params = pickle.load(f)\n",
    "            params[\"file_path\"] = weights_path\n",
    "        model = NN(**params)    \n",
    "        model.load_weights()\n",
    "        return model\n",
    "\n",
    "    def save_model(self, model_path):\n",
    "        weights_name = Path(model_path).name + \"_weights\"\n",
    "        model_dir = Path(model_path).parent\n",
    "        self.model.save_weights(str(model_dir / weights_name))\n",
    "        with open(str(model_path), \"wb\") as f:\n",
    "            pickle.dump(self.params, f)\n",
    "        \n",
    "    def predict(self, features):\n",
    "        x = self.scaler.transform(features.values.astype(np.float64))\n",
    "        return self.model.predict(x).flatten()\n",
    "\n",
    "\n",
    "def make_nn_trainer(file_path):\n",
    "    def train_nn(x_train, y_train, params=None):\n",
    "        params = params.copy()\n",
    "        params[\"file_path\"] = file_path\n",
    "        params[\"scaler\"] = StandardScaler()\n",
    "        model = NN(**params)\n",
    "        model.fit(x_train, y_train)\n",
    "        return model\n",
    "    return train_nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "tqdm.pandas()\n",
    "\n",
    "test = pd.read_csv('../../data/raw/test.csv')\n",
    "model = NN.load('../../models/nn_regressor.model')\n",
    "coef=[1.1262604125275384, 1.7337092496079027, 2.265498885159253]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\n",
      "nn_model.nn\n",
      "nn_regression.w8.data-00000-of-00002\n",
      "nn_regression.w8.data-00001-of-00002\n",
      "nn_regression.w8.index\n",
      "nn_regressor.model\n",
      "nn_regressor.model.data-00000-of-00002\n",
      "nn_regressor.model.data-00001-of-00002\n",
      "nn_regressor.model.index\n",
      "nn_regressor.model_weights.data-00000-of-00002\n",
      "nn_regressor.model_weights.data-00001-of-00002\n",
      "nn_regressor.model_weights.index\n",
      "regression_baseline_adv2.lgb\n",
      "regression_baseline_adv.lgb\n",
      "regression_baseline_ass.lgb\n",
      "regression_baseline__eventid_bag.lgb\n",
      "regression_baseline_kaggle_features.lgb\n",
      "regression_baseline.lgb\n",
      "regression_baseline_log1p.lgb\n",
      "regression_baseline_misses.lgb\n",
      "regression_baseline_rmse.lgb\n",
      "regression_baseline_round.lgb\n",
      "regression_baseline_splits.lgb\n",
      "regression_baseline_world.lgb\n",
      "regression_norm.lgb\n",
      "time_baseline.lgb\n"
     ]
    }
   ],
   "source": [
    "!ls ../../models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = ['Scrub-A-Dub', 'All Star Sorting',\n",
    "       'Air Show', 'Crystals Rule', \n",
    "       'Dino Drink', 'Bubble Bath', 'Dino Dive', 'Chow Time',\n",
    "       'Pan Balance', 'Happy Camel',\n",
    "       'Leaf Leader']\n",
    "assessments = ['Mushroom Sorter (Assessment)',\n",
    "       'Bird Measurer (Assessment)',\n",
    "       'Cauldron Filler (Assessment)',\n",
    "       'Cart Balancer (Assessment)', 'Chest Sorter (Assessment)']\n",
    "worlds = ['NONE', 'MAGMAPEAK', 'TREETOPCITY', 'CRYSTALCAVES']\n",
    "\n",
    "def unwrap_event_data(df):\n",
    "    unwrapped=pd.DataFrame(data=list(df.event_data.apply(json.loads).values))\n",
    "    unwrapped.drop(\"event_code\", axis=1, inplace=True)\n",
    "    return pd.concat([unwrapped.reset_index(),df.reset_index()],axis=1)\n",
    "\n",
    "\n",
    "event_data_features = [\"duration\", \"round\", \"level\", \"position\", \"total_duration\", \"weight\", \"misses\"]\n",
    "\n",
    "\n",
    "def extract_basic_stats(df):\n",
    "    stats = [\"min\", \"max\", \"mean\", \"std\"]\n",
    "    df = df[[f for f in event_data_features if f in df.columns]].reindex(columns=event_data_features)\n",
    "    result = []\n",
    "    for column, stats in df.agg(stats).to_dict().items():\n",
    "        result.extend([(k+\"_\"+column, v) for k,v in stats.items()])\n",
    "    return result\n",
    "\n",
    "\n",
    "def extract_chow_time(df):\n",
    "    cols = [\"round\", \"event_id\", \"resources\", \"target_weight\", \"game_session\"]\n",
    "    df = df[[c for c in cols if c in df.columns]]\n",
    "    df = df.reindex(columns=cols)\n",
    "    df = df[df[\"round\"]>0]\n",
    "    \n",
    "    def calculate_features(df):\n",
    "        data = df[df.event_id==\"63f13dd7\"]\n",
    "        if len(data):\n",
    "            data=data.iloc[0]\n",
    "        else:\n",
    "            return pd.Series({\"optimum\":None, \"complete\": 0})\n",
    "        resources = data[\"resources\"]\n",
    "        target = data[\"target_weight\"]\n",
    "        optimum = 0\n",
    "        cnt = 0\n",
    "        for v in sorted(resources)[::-1]:\n",
    "            if v+cnt>target:\n",
    "                continue\n",
    "            else:\n",
    "                cnt+=v\n",
    "                optimum+=1\n",
    "                if cnt==target:\n",
    "                    break\n",
    "        n_turns = sum(df.event_id==\"4ef8cdd3\")\n",
    "        complete = sum(df.event_id==\"56817e2b\")\n",
    "        return pd.Series({\"optimum\":n_turns / optimum, \"complete\": complete})\n",
    "    feature =  df.groupby([\"game_session\", \"round\"]).apply(calculate_features).mean()\n",
    "    if len(feature)==0:\n",
    "        return [(\"chowtime_optimum\", None), (\"chowtime_complete\", None)]\n",
    "    return [(\"chowtime_optimum\", feature[\"optimum\"]), (\"chowtime_complete\", feature[\"complete\"])]\n",
    "\n",
    "\n",
    "def extract_leaf_leader(df):\n",
    "    cols = [\"round\", \"event_id\", \"target_weight\", \"game_session\"]\n",
    "    df = df[[c for c in cols if c in df.columns]]\n",
    "    df = df.reindex(columns=cols)\n",
    "    df = df[df[\"round\"]>0]\n",
    "    \n",
    "    def calculate_features(df):\n",
    "        data = df[df.event_id==\"f32856e4\"]\n",
    "        if len(data):\n",
    "            data=data.iloc[0]\n",
    "        else:\n",
    "            return pd.Series({\"optimum\": None, \"complete\": 0})\n",
    "        target = data[\"target_weight\"]\n",
    "        optimum = 0\n",
    "        cnt = 0\n",
    "        for v in [4, 4, 2, 2, 2, 2, 1, 1]:\n",
    "            if v+cnt>target:\n",
    "                continue\n",
    "            else:\n",
    "                cnt+=v\n",
    "                optimum+=1\n",
    "                if cnt==target:\n",
    "                    break\n",
    "        n_turns = sum(df.event_id==\"262136f4\")\n",
    "        complete = sum(df.event_id==\"b012cd7f\")\n",
    "        return pd.Series({\"optimum\": n_turns / optimum, \"complete\": complete})\n",
    "    feature =  df.groupby([\"game_session\", \"round\"]).apply(calculate_features).mean()\n",
    "    if len(feature)==0:\n",
    "        return [(\"leafleader_optimum\", None), (\"leafleader_complete\", None)]\n",
    "    return [(\"leafleader_optimum\", feature[\"optimum\"]), (\"leafleader_complete\", feature[\"complete\"])]\n",
    "\n",
    "\n",
    "def extract_happy_camel(df):\n",
    "    cols = [\"round\", \"event_id\", \"has_toy\", \"bowls\", \"game_session\"]\n",
    "    df = df[[c for c in cols if c in df.columns]]\n",
    "    df = df.reindex(columns=cols)\n",
    "    df = df[df[\"round\"]>0]\n",
    "    \n",
    "    def calculate_features(df):\n",
    "        data = df[df.event_id==\"c2baf0bd\"]\n",
    "        if len(data):\n",
    "            data=data.iloc[0]\n",
    "        else:\n",
    "            return pd.Series({'optimum':None, 'n_toy_detected':None, \"complete\":0})\n",
    "    \n",
    "        optimum = len(data[\"bowls\"])\n",
    "        turns = df[df.event_id==\"6bf9e3e1\"]\n",
    "        n_turns = len(turns)\n",
    "        n_toy_detected = turns[\"has_toy\"].sum()\n",
    "        complete = sum(df.event_id==\"36fa3ebe\")\n",
    "        return pd.Series({'optimum':(n_turns / optimum), 'n_toy_detected':n_toy_detected, \"complete\": complete})\n",
    "    feature =  df.groupby([\"game_session\", \"round\"]).apply(calculate_features).mean()\n",
    "    if len(feature)==0:\n",
    "        return [(\"happycamel_optimum\", None), (\"happycamel_detections\", None), \n",
    "                (\"happycamel_complete\", None)]\n",
    "\n",
    "    return [(\"happycamel_optimum\", feature[\"optimum\"]), (\"happycamel_detections\", feature[\"n_toy_detected\"]), \n",
    "            (\"happycamel_complete\", feature[\"complete\"])]\n",
    "\n",
    "\n",
    "def extract_pan_balance(df):\n",
    "    cols = [\"round\", \"event_id\", \"target_weight\", \"starting_weights\", \"game_session\"]\n",
    "    df = df[[c for c in cols if c in df.columns]]\n",
    "    df = df.reindex(columns=cols)\n",
    "    df = df[df[\"round\"]>0]\n",
    "    \n",
    "    def calculate_features(df):\n",
    "        data = df[df.event_id==\"a592d54e\"]\n",
    "        if len(data):\n",
    "            data=data.iloc[0]\n",
    "        else:\n",
    "            return pd.Series({\"optimum\": None, \"complete\": 0})\n",
    "        target = data[\"target_weight\"]\n",
    "        start = data[\"starting_weights\"]\n",
    "        optimum = max(abs(target - start), 1)\n",
    "        n_turns = sum(df.event_id.isin((\"e7561dd2\", \"804ee27f\")))\n",
    "        complete = sum(df.event_id==\"1c178d24\")\n",
    "        return pd.Series({\"optimum\": n_turns / optimum, \"complete\": complete})\n",
    "    feature =  df.groupby([\"game_session\", \"round\"]).apply(calculate_features).mean()\n",
    "    if len(feature)==0:\n",
    "        return [(\"panbalance_optimum\", None), (\"panbalance_complete\", None)] \n",
    "    return [(\"panbalance_optimum\", feature[\"optimum\"]), (\"panbalance_complete\", feature[\"complete\"])]\n",
    "\n",
    "\n",
    "def extract_scrubadub(df):\n",
    "    cols = [\"round\", \"event_id\", \"game_session\", \"correct\", \"event_code\", \"animals\"]\n",
    "    df = df[[c for c in cols if c in df.columns]]\n",
    "    df = df.reindex(columns=cols)\n",
    "    df = df[df[\"round\"]>0]\n",
    "    \n",
    "    def calculate_features(df):\n",
    "        data = df[df.event_id==\"26fd2d99\"]\n",
    "        if len(data):\n",
    "            data=data.iloc[0]\n",
    "        else:\n",
    "            return pd.Series({\"performance\":None, \"precision\": None, \"complete\": 0})\n",
    "        n_animals = len(data[\"animals\"])\n",
    "        complete = sum(df.event_id==\"08fd73f3\")\n",
    "        df = df[(df.event_id==\"5c3d2b2f\")&(df.event_code==4020)]\n",
    "        return pd.Series({\"performance\": len(df) / n_animals, \"precision\": df[\"correct\"].sum()/n_animals, \"complete\": complete})\n",
    "    feature =  df.groupby([\"game_session\", \"round\"]).apply(calculate_features).mean()\n",
    "    if len(feature)==0:\n",
    "        return [(\"scrubadub_performance\", None), (\"scrubadub_precision\", None), (\"scrubadub_complete\", None)]\n",
    "    return [(\"scrubadub_performance\", feature[\"performance\"]), (\"scrubadub_precision\", feature[\"precision\"]),\n",
    "            (\"scrubadub_complete\", feature[\"complete\"])]    \n",
    "\n",
    "\n",
    "def extract_allstarsorting(df):\n",
    "    cols = [\"round\", \"event_id\", \"game_session\", \"correct\", \"event_code\", \"houses\"]\n",
    "    df = df[[c for c in cols if c in df.columns]]\n",
    "    df = df.reindex(columns=cols)\n",
    "    df = df[df[\"round\"]>0]\n",
    "    \n",
    "    def calculate_features(df):\n",
    "        data = df[df.event_id==\"2c4e6db0\"]\n",
    "        if len(data):\n",
    "            data=data.iloc[0]\n",
    "        else:\n",
    "            return pd.Series({\"performance\":None, \"precision\": None, \"complete\": 0})\n",
    "        n_animals = len(data[\"houses\"])\n",
    "        complete = sum(df.event_id==\"ca11f653\")\n",
    "        df = df[df.event_id==\"2dc29e21\"]\n",
    "        return pd.Series({\"performance\": len(df) / n_animals, \"precision\": df[\"correct\"].sum()/n_animals, \"complete\": complete})\n",
    "    feature =  df.groupby([\"game_session\", \"round\"]).apply(calculate_features).mean()\n",
    "    if len(feature)==0:\n",
    "        return [(\"allstarsorting_performance\", None), (\"allstarsorting_precision\", None), (\"allstarsorting_complete\", None)]\n",
    "    return [(\"allstarsorting_performance\", feature[\"performance\"]), (\"allstarsorting_precision\", feature[\"precision\"]),\n",
    "            (\"allstarsorting_complete\", feature[\"complete\"])]  \n",
    "\n",
    "\n",
    "def extract_dinodrink(df):\n",
    "    cols = [\"round\", \"event_id\", \"game_session\", \"correct\", \"event_code\", \"holes\"]\n",
    "    df = df[[c for c in cols if c in df.columns]]\n",
    "    df = df.reindex(columns=cols)\n",
    "    df = df[df[\"round\"]>0]\n",
    "    \n",
    "    def calculate_features(df):\n",
    "        data = df[df.event_id==\"f806dc10\"]\n",
    "        if len(data):\n",
    "            data=data.iloc[0]\n",
    "        else:\n",
    "            return pd.Series({\"performance\": None, \"precision\": None, \"complete\": 0})\n",
    "        n_animals = len(data[\"holes\"])\n",
    "        complete = sum(df.event_id==\"16dffff1\")\n",
    "        df = df[df.event_id==\"74e5f8a7\"]\n",
    "        return pd.Series({\"performance\": len(df) / n_animals, \"precision\": df[\"correct\"].sum()/n_animals, \"complete\": complete})\n",
    "    feature =  df.groupby([\"game_session\", \"round\"]).apply(calculate_features).mean()\n",
    "    if len(feature)==0:\n",
    "        return [(\"dinodrink_performance\", None), (\"dinodrink_precision\", None), (\"dinodrink_complete\", None)]\n",
    "    return [(\"dinodrink_performance\", feature[\"performance\"]), (\"dinodrink_precision\", feature[\"precision\"]),\n",
    "            (\"dinodrink_complete\", feature[\"complete\"])]  \n",
    "\n",
    "\n",
    "def extract_bubblebath(df):\n",
    "    cols = [\"round\", \"event_id\", \"game_session\", \"containers\", \"target_containers\"]\n",
    "    df = df[[c for c in cols if c in df.columns]]\n",
    "    df = df.reindex(columns=cols)\n",
    "    df = df[df[\"round\"]>0]\n",
    "    \n",
    "    def calculate_features(df):\n",
    "        data = df[df.event_id==\"1beb320a\"]\n",
    "        if len(data):\n",
    "            data=data.iloc[0]\n",
    "        else:\n",
    "            return pd.Series({\"performance\": None, \"complete\": 0})\n",
    "        target = data[\"target_containers\"]\n",
    "        complete = sum(df.event_id==\"895865f3\")\n",
    "        df = df[df.event_id==\"3bb91dda\"]\n",
    "        if len(df):\n",
    "            return pd.Series({\"performance\": abs(target - df.iloc[0][\"containers\"]), \"complete\": complete})\n",
    "        else:\n",
    "            return pd.Series({\"performance\": None, \"complete\": 0})\n",
    "    feature =  df.groupby([\"game_session\", \"round\"]).apply(calculate_features).mean()\n",
    "    if isinstance(feature, pd.Series):\n",
    "        return [(\"bubblebath_performance\", None), (\"bubblebath_complete\", None)]\n",
    "    return [(\"bubblebath_performance\", feature[\"performance\"]), (\"bubblebath_complete\", feature[\"complete\"])] \n",
    "\n",
    "\n",
    "def extract_dinodive(df):\n",
    "    cols = [\"round\", \"event_id\", \"game_session\", \"correct\", \"target_water_level\"]\n",
    "    df = df[[c for c in cols if c in df.columns]]\n",
    "    df = df.reindex(columns=cols)\n",
    "    df = df[df[\"round\"]>0]\n",
    "    \n",
    "    def calculate_features(df):\n",
    "        data = df[df.event_id==\"7961e599\"]\n",
    "        if len(data):\n",
    "            data=data.iloc[0]\n",
    "        else:\n",
    "            return pd.Series({\"performance\": None, \"precision\": None, \"complete\": 0})\n",
    "        target = data[\"target_water_level\"]\n",
    "        dinos = [6, 6, 3, 3, 3, 3, 1, 1]\n",
    "        opt=0\n",
    "        n_animals=0\n",
    "        for d in dinos:\n",
    "            if opt+d>target:\n",
    "                continue\n",
    "            else:\n",
    "                opt+=d\n",
    "                n_animals+=1\n",
    "                if opt==target:\n",
    "                    break\n",
    "        complete = sum(df.event_id==\"00c73085\")\n",
    "        df = df[df.event_id==\"c0415e5c\"]\n",
    "        return pd.Series({\"performance\": len(df) / n_animals, \"precision\": df[\"correct\"].sum()/n_animals, \"complete\": complete})\n",
    "    feature =  df.groupby([\"game_session\", \"round\"]).apply(calculate_features).mean()\n",
    "    if len(feature)==0:\n",
    "        return [(\"dinodive_performance\", None), (\"dinodive_precision\", None), (\"dinodive_complete\", None)]\n",
    "    return [(\"dinodive_performance\", feature[\"performance\"]), (\"dinodive_precision\", feature[\"precision\"]),\n",
    "            (\"dinodive_complete\", feature[\"complete\"])]\n",
    "\n",
    "\n",
    "def extract_airshow(df):\n",
    "    cols = [\"round\", \"event_id\", \"game_session\", \"correct\"]\n",
    "    df = df[[c for c in cols if c in df.columns]]\n",
    "    df = df.reindex(columns=cols)\n",
    "    df = df[df[\"round\"]>0]\n",
    "    \n",
    "    def calculate_features(df):\n",
    "        complete =sum(df.event_id==\"f5b8c21a\")\n",
    "        df = df[df.event_id==\"28f975ea\"]\n",
    "        return pd.Series({\"performance\": len(df), \"precision\": df[\"correct\"].sum(), \"complete\": complete})\n",
    "    feature =  df.groupby([\"game_session\", \"round\"]).apply(calculate_features).mean()\n",
    "    if len(feature)==0:\n",
    "        return [(\"airshow_performance\", None), (\"airshow_precision\", None), (\"airshow_complete\", None)]\n",
    "    return [(\"airshow_performance\", feature[\"performance\"]), (\"airshow_precision\", feature[\"precision\"]),\n",
    "            (\"airshow_complete\", feature[\"complete\"])]      \n",
    "\n",
    "\n",
    "def extract_crystalsrule(df):\n",
    "    cols = [\"round\", \"event_id\", \"game_session\", \"correct\"]\n",
    "    df = df[[c for c in cols if c in df.columns]]\n",
    "    df = df.reindex(columns=cols)\n",
    "    df = df[df[\"round\"]>0]\n",
    "    \n",
    "    def calculate_features(df):\n",
    "        complete = sum(df.event_id==\"3323d7e9\")\n",
    "        df = df[df.event_id==\"86c924c4\"]\n",
    "        return pd.Series({\"performance\": len(df), \"precision\": df[\"correct\"].sum(), \"complete\": complete})\n",
    "    feature =  df.groupby([\"game_session\", \"round\"]).apply(calculate_features).mean()\n",
    "    if len(feature)==0:\n",
    "        return [(\"crystalsrule_performance\", None), (\"crystalsrule_precision\", None), (\"crystalsrule_complete\", None)]\n",
    "    return [(\"crystalsrule_performance\", feature[\"performance\"]), (\"crystalsrule_precision\", feature[\"precision\"]),\n",
    "            (\"crystalsrule_complete\", feature[\"complete\"])]          \n",
    "\n",
    "\n",
    "game_funcs={\n",
    "    \"Chow Time\": extract_chow_time,\n",
    "    \"Leaf Leader\": extract_leaf_leader,\n",
    "    \"Happy Camel\": extract_happy_camel,\n",
    "    \"Pan Balance\": extract_pan_balance,\n",
    "    \"Scrub-A-Dub\": extract_scrubadub,\n",
    "    \"All Star Sorting\": extract_allstarsorting,\n",
    "    \"Dino Drink\": extract_dinodrink,\n",
    "    \"Bubble Bath\": extract_bubblebath,\n",
    "    \"Dino Dive\": extract_dinodive,\n",
    "    \"Air Show\": extract_airshow,\n",
    "    \"Crystals Rule\": extract_crystalsrule,\n",
    "}\n",
    "\n",
    "\n",
    "def extract_game_stats(df, title):\n",
    "    return game_funcs[title](df)\n",
    "\n",
    "\n",
    "def make_counters(df, column):\n",
    "    return {k: v for k, v in df.groupby(column)[column].count().to_dict().items()}\n",
    "\n",
    "    \n",
    "def process_log(df):\n",
    "    assessment_title=df.title.iloc[-1]   \n",
    "    world=df.world.iloc[-1]\n",
    "\n",
    "    history = df.iloc[:-1]\n",
    "    history = history[history.type.isin([\"Game\", \"Assessment\"])].copy()\n",
    "\n",
    "    def calculate_ratios(df):\n",
    "        n_correct=df.correct_move.sum()\n",
    "        n_incorrect=df.wrong_move.sum()\n",
    "        ratio=n_correct/(n_correct+n_incorrect)\n",
    "        return n_correct, n_incorrect, ratio\n",
    "    \n",
    "    def make_move_stats(df, title,n_lags=2):\n",
    "        df=df.copy()\n",
    "        if len(df):\n",
    "            df = unwrap_event_data(df)\n",
    "        if \"correct\" in df.columns:\n",
    "            df[\"correct_move\"] = df.correct == True\n",
    "            df[\"wrong_move\"] = df.correct == False\n",
    "        else:\n",
    "            df[\"correct_move\"]=False\n",
    "            df[\"wrong_move\"]=False\n",
    "        result = []\n",
    "        result.extend(zip([f\"n_correct_{title}\", f\"n_incorrect_{title}\", f\"global_ratio_{title}\"], calculate_ratios(df)))\n",
    "        result.extend(extract_game_stats(df, title))\n",
    "        #result.extend(extract_basic_stats(df))\n",
    "        if n_lags:\n",
    "            last_sessions = df.game_session.unique()[-n_lags:]\n",
    "            for i in range(n_lags):\n",
    "                if i < len(last_sessions): \n",
    "                    result.extend(zip([f\"n_correct_{title}_{i}\", f\"n_incorrect_{title} {i}\",f\"ratio_{title}_{i}\"], \n",
    "                                      calculate_ratios(df[df.game_session==last_sessions[i]])))\n",
    "                else:\n",
    "                    result.extend(zip([f\"n_correct_{title}_{i}\", f\"n_incorrect_{title}_{i}\",f\"ratio_{title}_{i}\"], [None, None, None]))\n",
    "        return {k: v for k, v in result}\n",
    "    \n",
    "    \n",
    "    result = {\"title\": assessments.index(assessment_title),\n",
    "              \"world\": worlds.index(world),\n",
    "              \"n_activities\": df[df.type==\"Activity\"].game_session.nunique(),\n",
    "              \"n_games\": df[df.type==\"Game\"].game_session.nunique(),\n",
    "              \"event_code_count\": df.event_code.nunique(),\n",
    "              \"event_id_count\": df.event_id.nunique(),\n",
    "              \"title_count\": df.title.nunique(),\n",
    "              \"n_actions\": len(df),\n",
    "              \"world_title_count\": df[df.world==world].title.nunique(),\n",
    "             }\n",
    "    \n",
    "    def make_game_features(game):\n",
    "        result = {}\n",
    "        stats=history[history.title==game]\n",
    "        stats_features=make_move_stats(stats, game)\n",
    "        stats_features[f\"{game}_event_code_count\"] = stats.event_code.nunique()\n",
    "        stats_features[f\"{game}_event_id_count\"] = stats.event_id.nunique()\n",
    "        stats_features[f\"{game}_session_id_count\"] = stats.game_session.nunique()\n",
    "        stats_features[f\"{game}_n_actions\"] = len(stats)\n",
    "        result.update(stats_features)\n",
    "        result.update({f\"{game}_{k}\": v for k, v in make_counters(stats, \"event_id\").items()})\n",
    "        result.update({f\"{game}_{k}\": v for k, v in make_counters(stats, \"event_code\").items()})\n",
    "        return result\n",
    "    \n",
    "    #for f in Parallel(n_jobs=cpu_count())(delayed(make_game_features)(game) for game in games):\n",
    "    #    result.update(f)\n",
    "    for game in games:\n",
    "        result.update(make_game_features(game))\n",
    "    world_games = history[history.world==world]\n",
    "    \n",
    "    def make_world_features(game):\n",
    "        result = {}\n",
    "        stats=world_games[world_games.title==game]\n",
    "        stats_features=make_move_stats(stats, game)\n",
    "        stats_features = {f\"world_{k}\": v for k, v in stats_features.items()}\n",
    "        stats_features[f\"world_{game}_event_code_count\"] = stats.event_code.nunique()\n",
    "        stats_features[f\"world_{game}_event_id_count\"] = stats.event_id.nunique()\n",
    "        stats_features[f\"world_{game}_session_id_count\"] = stats.game_session.nunique()\n",
    "        stats_features[f\"world_{game}_n_actions\"] = len(stats)\n",
    "        result.update(stats_features)\n",
    "        result.update({f\"world_{game}_{k}\": v for k, v in make_counters(stats, \"event_id\").items()})\n",
    "        result.update({f\"world_{game}_{k}\": v for k, v in make_counters(stats, \"event_code\").items()})\n",
    "        return result\n",
    "    \n",
    "    #for f in Parallel(n_jobs=cpu_count())(delayed(make_world_features)(game) for game in games):\n",
    "    #    result.update(f)\n",
    "    for game in games:\n",
    "        result.update(make_world_features(game))\n",
    "    make_history_counters = partial(make_counters, history)\n",
    "    result.update(make_counters(history, \"event_id\"))\n",
    "    result.update(make_counters(history, \"event_code\"))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dummy_features(*feature_list):\n",
    "    dummy_features = []\n",
    "    encoded_features = [\"title\", \"world\"]\n",
    "    for i, title in enumerate(assessments):\n",
    "        fname = f\"title_{i}\"\n",
    "        for features in feature_list:\n",
    "            features[fname] = features[\"title\"]==i\n",
    "        dummy_features.append(fname)\n",
    "    for i, world in enumerate(worlds):\n",
    "        fname = f\"world_{i}\"\n",
    "        for features in feature_list:\n",
    "            features[fname] = features[\"world\"]==i\n",
    "        dummy_features.append(fname)\n",
    "    return dummy_features, encoded_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<02:04,  8.03it/s]/home/bfilippov/anaconda3/envs/dsb2019_docker/lib/python3.6/site-packages/ipykernel_launcher.py:342: RuntimeWarning: invalid value encountered in long_scalars\n",
      "100%|██████████| 1000/1000 [04:44<00:00,  3.52it/s]\n"
     ]
    }
   ],
   "source": [
    "def process_test_installations(test):\n",
    "    test = test.sort_values(\"timestamp\")\n",
    "    test=test.groupby(\"installation_id\").progress_apply(process_log).reset_index()\n",
    "    test.columns = [\"installation_id\", \"features\"]\n",
    "    result = []\n",
    "    for i, installation_id, feature in test.itertuples():\n",
    "        result.append(feature)\n",
    "        feature[\"installation_id\"]=installation_id\n",
    "    return pd.DataFrame(result).fillna(-1)\n",
    "test_features=process_test_installations(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_features=['title', 'world', 'n_games', 'event_code_count', 'title_count', 'world_title_count', 'n_correct_Scrub-A-Dub', 'n_incorrect_Scrub-A-Dub', 'global_ratio_Scrub-A-Dub', 'scrubadub_performance', 'scrubadub_complete', 'n_correct_Scrub-A-Dub_0', 'n_incorrect_Scrub-A-Dub 0', 'ratio_Scrub-A-Dub_0', 'n_correct_Scrub-A-Dub_1', 'n_incorrect_Scrub-A-Dub_1', 'ratio_Scrub-A-Dub_1', 'Scrub-A-Dub_session_id_count', 'Scrub-A-Dub_n_actions', 'Scrub-A-Dub_4a09ace1', 'Scrub-A-Dub_5a848010', 'Scrub-A-Dub_5c3d2b2f', 'Scrub-A-Dub_6d90d394', 'Scrub-A-Dub_7040c096', 'Scrub-A-Dub_c1cac9a2', 'Scrub-A-Dub_cf82af56', 'Scrub-A-Dub_f71c4741', 'n_correct_All Star Sorting', 'n_incorrect_All Star Sorting', 'global_ratio_All Star Sorting', 'allstarsorting_performance', 'allstarsorting_precision', 'n_correct_All Star Sorting_0', 'n_incorrect_All Star Sorting 0', 'ratio_All Star Sorting_0', 'n_correct_All Star Sorting_1', 'n_incorrect_All Star Sorting 1', 'ratio_All Star Sorting_1', 'All Star Sorting_event_code_count', 'All Star Sorting_session_id_count', 'All Star Sorting_n_actions', 'All Star Sorting_1cc7cfca', 'All Star Sorting_2c4e6db0', 'All Star Sorting_2dc29e21', 'All Star Sorting_363d3849', 'All Star Sorting_4b5efe37', 'All Star Sorting_587b5989', 'All Star Sorting_6043a2b4', 'All Star Sorting_b120f2ac', 'All Star Sorting_d02b7a8e', 'n_correct_Air Show', 'n_incorrect_Air Show', 'global_ratio_Air Show', 'airshow_performance', 'airshow_precision', 'airshow_complete', 'n_correct_Air Show_0', 'n_incorrect_Air Show 0', 'ratio_Air Show_0', 'n_correct_Air Show_1', 'n_incorrect_Air Show_1', 'ratio_Air Show_1', 'Air Show_event_code_count', 'Air Show_session_id_count', 'Air Show_n_actions', 'Air Show_06372577', 'Air Show_14de4c5d', 'Air Show_1575e76c', 'Air Show_15ba1109', 'Air Show_28f975ea', 'Air Show_58a0de5c', 'Air Show_65abac75', 'Air Show_7423acbc', 'Air Show_a1bbe385', 'Air Show_bcceccc6', 'Air Show_d88ca108', 'Air Show_dcb55a27', 'n_correct_Crystals Rule', 'n_incorrect_Crystals Rule', 'global_ratio_Crystals Rule', 'crystalsrule_performance', 'crystalsrule_precision', 'n_correct_Crystals Rule_0', 'n_incorrect_Crystals Rule 0', 'ratio_Crystals Rule_0', 'n_correct_Crystals Rule_1', 'n_incorrect_Crystals Rule_1', 'ratio_Crystals Rule_1', 'Crystals Rule_event_code_count', 'Crystals Rule_session_id_count', 'Crystals Rule_n_actions', 'Crystals Rule_44cb4907', 'Crystals Rule_48349b14', 'Crystals Rule_5e3ea25a', 'Crystals Rule_86c924c4', 'Crystals Rule_cc5087a3', 'n_correct_Dino Drink', 'n_incorrect_Dino Drink', 'global_ratio_Dino Drink', 'dinodrink_performance', 'dinodrink_precision', 'dinodrink_complete', 'n_correct_Dino Drink_0', 'n_incorrect_Dino Drink_0', 'ratio_Dino Drink_0', 'n_correct_Dino Drink_1', 'n_incorrect_Dino Drink_1', 'ratio_Dino Drink_1', 'Dino Drink_event_code_count', 'Dino Drink_session_id_count', 'Dino Drink_n_actions', 'n_correct_Bubble Bath', 'n_incorrect_Bubble Bath', 'global_ratio_Bubble Bath', 'bubblebath_performance', 'bubblebath_complete', 'n_correct_Bubble Bath_0', 'n_incorrect_Bubble Bath_0', 'ratio_Bubble Bath_0', 'n_correct_Bubble Bath_1', 'n_incorrect_Bubble Bath_1', 'ratio_Bubble Bath_1', 'Bubble Bath_event_code_count', 'Bubble Bath_session_id_count', 'Bubble Bath_n_actions', 'n_correct_Dino Dive', 'n_incorrect_Dino Dive', 'global_ratio_Dino Dive', 'dinodive_performance', 'dinodive_precision', 'dinodive_complete', 'n_correct_Dino Dive_0', 'n_incorrect_Dino Dive_0', 'ratio_Dino Dive_0', 'n_correct_Dino Dive_1', 'n_incorrect_Dino Dive_1', 'ratio_Dino Dive_1', 'Dino Dive_event_code_count', 'Dino Dive_session_id_count', 'Dino Dive_n_actions', 'n_correct_Chow Time', 'n_incorrect_Chow Time', 'global_ratio_Chow Time', 'chowtime_optimum', 'chowtime_complete', 'n_correct_Chow Time_0', 'n_incorrect_Chow Time_0', 'ratio_Chow Time_0', 'n_correct_Chow Time_1', 'n_incorrect_Chow Time_1', 'ratio_Chow Time_1', 'Chow Time_event_code_count', 'Chow Time_session_id_count', 'Chow Time_n_actions', 'n_correct_Pan Balance', 'n_incorrect_Pan Balance', 'global_ratio_Pan Balance', 'panbalance_optimum', 'panbalance_complete', 'n_correct_Pan Balance_0', 'n_incorrect_Pan Balance_0', 'ratio_Pan Balance_0', 'n_correct_Pan Balance_1', 'n_incorrect_Pan Balance_1', 'ratio_Pan Balance_1', 'Pan Balance_event_code_count', 'Pan Balance_session_id_count', 'Pan Balance_n_actions', 'n_correct_Happy Camel', 'n_incorrect_Happy Camel', 'global_ratio_Happy Camel', 'happycamel_optimum', 'happycamel_detections', 'happycamel_complete', 'n_correct_Happy Camel_0', 'n_incorrect_Happy Camel_0', 'ratio_Happy Camel_0', 'n_correct_Happy Camel_1', 'n_incorrect_Happy Camel_1', 'ratio_Happy Camel_1', 'Happy Camel_event_code_count', 'Happy Camel_session_id_count', 'Happy Camel_n_actions', 'n_correct_Leaf Leader', 'n_incorrect_Leaf Leader', 'global_ratio_Leaf Leader', 'leafleader_optimum', 'leafleader_complete', 'n_correct_Leaf Leader_0', 'n_incorrect_Leaf Leader_0', 'ratio_Leaf Leader_0', 'n_correct_Leaf Leader_1', 'n_incorrect_Leaf Leader_1', 'ratio_Leaf Leader_1', 'Leaf Leader_event_code_count', 'Leaf Leader_session_id_count', 'Leaf Leader_n_actions', 'world_n_correct_Scrub-A-Dub', 'world_n_incorrect_Scrub-A-Dub', 'world_global_ratio_Scrub-A-Dub', 'world_scrubadub_performance', 'world_n_correct_Scrub-A-Dub_0', 'world_n_incorrect_Scrub-A-Dub_0', 'world_ratio_Scrub-A-Dub_0', 'world_n_correct_Scrub-A-Dub_1', 'world_n_incorrect_Scrub-A-Dub_1', 'world_ratio_Scrub-A-Dub_1', 'world_Scrub-A-Dub_event_code_count', 'world_Scrub-A-Dub_session_id_count', 'world_Scrub-A-Dub_n_actions', 'world_n_correct_All Star Sorting', 'world_n_incorrect_All Star Sorting', 'world_global_ratio_All Star Sorting', 'world_allstarsorting_performance', 'world_allstarsorting_precision', 'world_n_correct_All Star Sorting_0', 'world_n_incorrect_All Star Sorting 0', 'world_ratio_All Star Sorting_0', 'world_n_correct_All Star Sorting_1', 'world_n_incorrect_All Star Sorting 1', 'world_ratio_All Star Sorting_1', 'world_All Star Sorting_event_code_count', 'world_All Star Sorting_session_id_count', 'world_All Star Sorting_n_actions', 'world_All Star Sorting_1cc7cfca', 'world_All Star Sorting_2c4e6db0', 'world_All Star Sorting_2dc29e21', 'world_All Star Sorting_363d3849', 'world_All Star Sorting_4b5efe37', 'world_All Star Sorting_587b5989', 'world_All Star Sorting_6043a2b4', 'world_All Star Sorting_b120f2ac', 'world_All Star Sorting_d02b7a8e', 'world_n_correct_Air Show', 'world_n_incorrect_Air Show', 'world_global_ratio_Air Show', 'world_airshow_performance', 'world_airshow_precision', 'world_airshow_complete', 'world_n_correct_Air Show_0', 'world_n_incorrect_Air Show 0', 'world_ratio_Air Show_0', 'world_n_correct_Air Show_1', 'world_n_incorrect_Air Show_1', 'world_ratio_Air Show_1', 'world_Air Show_event_code_count', 'world_Air Show_session_id_count', 'world_Air Show_n_actions', 'world_Air Show_06372577', 'world_Air Show_14de4c5d', 'world_Air Show_1575e76c', 'world_Air Show_15ba1109', 'world_Air Show_28f975ea', 'world_Air Show_58a0de5c', 'world_Air Show_65abac75', 'world_Air Show_7423acbc', 'world_Air Show_a1bbe385', 'world_Air Show_bcceccc6', 'world_Air Show_d88ca108', 'world_Air Show_dcb55a27', 'world_n_correct_Crystals Rule', 'world_n_incorrect_Crystals Rule', 'world_global_ratio_Crystals Rule', 'world_crystalsrule_performance', 'world_crystalsrule_precision', 'world_n_correct_Crystals Rule_0', 'world_n_incorrect_Crystals Rule 0', 'world_ratio_Crystals Rule_0', 'world_n_correct_Crystals Rule_1', 'world_n_incorrect_Crystals Rule_1', 'world_ratio_Crystals Rule_1', 'world_Crystals Rule_event_code_count', 'world_Crystals Rule_session_id_count', 'world_Crystals Rule_n_actions', 'world_Crystals Rule_44cb4907', 'world_Crystals Rule_48349b14', 'world_Crystals Rule_5e3ea25a', 'world_Crystals Rule_86c924c4', 'world_Crystals Rule_cc5087a3', 'world_n_correct_Dino Drink', 'world_n_incorrect_Dino Drink', 'world_global_ratio_Dino Drink', 'world_dinodrink_performance', 'world_dinodrink_precision', 'world_n_correct_Dino Drink_0', 'world_n_incorrect_Dino Drink_0', 'world_ratio_Dino Drink_0', 'world_n_correct_Dino Drink_1', 'world_n_incorrect_Dino Drink_1', 'world_ratio_Dino Drink_1', 'world_Dino Drink_event_code_count', 'world_Dino Drink_session_id_count', 'world_Dino Drink_n_actions', 'world_n_correct_Bubble Bath', 'world_n_incorrect_Bubble Bath', 'world_global_ratio_Bubble Bath', 'world_bubblebath_performance', 'world_bubblebath_complete', 'world_n_correct_Bubble Bath_0', 'world_n_incorrect_Bubble Bath_0', 'world_ratio_Bubble Bath_0', 'world_n_correct_Bubble Bath_1', 'world_n_incorrect_Bubble Bath_1', 'world_ratio_Bubble Bath_1', 'world_Bubble Bath_event_code_count', 'world_Bubble Bath_session_id_count', 'world_Bubble Bath_n_actions', 'world_n_correct_Dino Dive', 'world_n_incorrect_Dino Dive', 'world_global_ratio_Dino Dive', 'world_dinodive_performance', 'world_dinodive_precision', 'world_dinodive_complete', 'world_n_correct_Dino Dive_0', 'world_n_incorrect_Dino Dive_0', 'world_ratio_Dino Dive_0', 'world_n_correct_Dino Dive_1', 'world_n_incorrect_Dino Dive_1', 'world_ratio_Dino Dive_1', 'world_Dino Dive_event_code_count', 'world_Dino Dive_session_id_count', 'world_Dino Dive_n_actions', 'world_n_correct_Chow Time', 'world_n_incorrect_Chow Time', 'world_global_ratio_Chow Time', 'world_chowtime_optimum', 'world_chowtime_complete', 'world_n_correct_Chow Time_0', 'world_n_incorrect_Chow Time_0', 'world_ratio_Chow Time_0', 'world_n_correct_Chow Time_1', 'world_n_incorrect_Chow Time_1', 'world_ratio_Chow Time_1', 'world_Chow Time_event_code_count', 'world_Chow Time_session_id_count', 'world_Chow Time_n_actions', 'world_n_correct_Pan Balance', 'world_n_incorrect_Pan Balance', 'world_global_ratio_Pan Balance', 'world_panbalance_optimum', 'world_panbalance_complete', 'world_n_correct_Pan Balance_0', 'world_n_incorrect_Pan Balance_0', 'world_ratio_Pan Balance_0', 'world_n_correct_Pan Balance_1', 'world_n_incorrect_Pan Balance_1', 'world_ratio_Pan Balance_1', 'world_Pan Balance_event_code_count', 'world_Pan Balance_session_id_count', 'world_Pan Balance_n_actions', 'world_n_correct_Happy Camel', 'world_n_incorrect_Happy Camel', 'world_global_ratio_Happy Camel', 'world_happycamel_optimum', 'world_happycamel_detections', 'world_happycamel_complete', 'world_n_correct_Happy Camel_0', 'world_n_incorrect_Happy Camel_0', 'world_ratio_Happy Camel_0', 'world_n_correct_Happy Camel_1', 'world_n_incorrect_Happy Camel_1', 'world_ratio_Happy Camel_1', 'world_Happy Camel_event_code_count', 'world_Happy Camel_session_id_count', 'world_Happy Camel_n_actions', 'world_n_correct_Leaf Leader', 'world_n_incorrect_Leaf Leader', 'world_global_ratio_Leaf Leader', 'world_leafleader_optimum', 'world_leafleader_complete', 'world_n_correct_Leaf Leader_0', 'world_n_incorrect_Leaf Leader_0', 'world_ratio_Leaf Leader_0', 'world_n_correct_Leaf Leader_1', 'world_n_incorrect_Leaf Leader_1', 'world_ratio_Leaf Leader_1', 'world_Leaf Leader_event_code_count', 'world_Leaf Leader_session_id_count', 'world_Leaf Leader_n_actions', '1375ccb7', '17113b36', '25fa8af4', '28ed704e', '3bfd1a65', '4a4c3d21', '51102b85', '5f0eb72c', '6c930e6e', '7da34a02', 'a16a373e', 'a1e4395d', 'a5be6304', 'c7128948', 'ec138c1c', 'f56e0afc', 'fbaf3456', '2000', '2010', '2020', '2025', '2035', '2060', '2070', '2080', '2081', '2083', '3010', '3020', '3021', '4010', '4020', '4025', '4030', '4035', '4040', '4070', '4090', '4100', '4110', 'installation_id', 'accuracy_group', 'n_incorrect_Air Show_0', 'n_incorrect_Crystals Rule_0', 'world_n_incorrect_Air Show_0', 'world_n_incorrect_Crystals Rule_0', 'n_incorrect_Scrub-A-Dub 1', 'n_incorrect_Dino Drink 0', 'Dino Drink_1996c610', 'Dino Drink_4d6737eb', 'Dino Drink_51311d7a', 'Dino Drink_5be391b5', 'Dino Drink_6c517a88', 'Dino Drink_74e5f8a7', 'Dino Drink_792530f8', 'Dino Drink_7f0836bf', 'Dino Drink_c6971acf', 'Dino Drink_f806dc10', 'n_incorrect_Bubble Bath 0', 'Bubble Bath_0413e89d', 'Bubble Bath_1340b8d7', 'Bubble Bath_1beb320a', 'Bubble Bath_1cf54632', 'Bubble Bath_3bb91dda', 'Bubble Bath_55115cbd', 'Bubble Bath_5859dfb6', 'Bubble Bath_857f21c0', 'Bubble Bath_8d84fa81', 'Bubble Bath_99abe2bb', 'Bubble Bath_99ea62f3', 'Bubble Bath_a0faea5d', 'Bubble Bath_ecc36b7f', '4045', '4095', 'n_incorrect_Air Show 1', 'Air Show_d2659ab4', 'n_incorrect_Crystals Rule 1', 'world_n_incorrect_Air Show 1', 'world_Air Show_d2659ab4', 'world_n_incorrect_Crystals Rule 1', '160654fd', '2075', 'n_incorrect_All Star Sorting_0', 'n_incorrect_All Star Sorting_1', 'Bubble Bath_85de926c', 'n_incorrect_Dino Dive 0', 'Dino Dive_00c73085', 'Dino Dive_28a4eb9a', 'Dino Dive_29bdd9ba', 'Dino Dive_6088b756', 'Dino Dive_709b1251', 'Dino Dive_76babcde', 'Dino Dive_7d5c30a2', 'Dino Dive_832735e1', 'Dino Dive_87d743c1', 'Dino Dive_c0415e5c', 'n_incorrect_Chow Time 0', 'Chow Time_0330ab6a', 'Chow Time_0d1da71f', 'Chow Time_47026d5f', 'Chow Time_4ef8cdd3', 'Chow Time_63f13dd7', 'Chow Time_7372e1a5', 'Chow Time_7ec0c298', 'Chow Time_cfbd47c8', 'Chow Time_d185d3ea', 'Chow Time_f93fc684', 'world_n_incorrect_Scrub-A-Dub 0', 'world_Scrub-A-Dub_2b9272f4', 'world_Scrub-A-Dub_4a09ace1', 'world_Scrub-A-Dub_5a848010', 'world_Scrub-A-Dub_5c3d2b2f', 'world_Scrub-A-Dub_6d90d394', 'world_Scrub-A-Dub_7040c096', 'world_Scrub-A-Dub_ac92046e', 'world_Scrub-A-Dub_c1cac9a2', 'world_Scrub-A-Dub_cf82af56', 'world_Scrub-A-Dub_f71c4741', 'world_n_incorrect_All Star Sorting_0', 'world_n_incorrect_All Star Sorting_1', 'world_n_incorrect_Bubble Bath 0', 'world_Bubble Bath_0413e89d', 'world_Bubble Bath_1340b8d7', 'world_Bubble Bath_1beb320a', 'world_Bubble Bath_1cf54632', 'world_Bubble Bath_3bb91dda', 'world_Bubble Bath_55115cbd', 'world_Bubble Bath_857f21c0', 'world_Bubble Bath_85de926c', 'world_Bubble Bath_8d84fa81', 'world_Bubble Bath_99abe2bb', 'world_Bubble Bath_99ea62f3', 'world_Bubble Bath_a0faea5d', 'world_Bubble Bath_ecc36b7f', 'world_n_incorrect_Dino Dive 0', 'world_Dino Dive_00c73085', 'world_Dino Dive_28a4eb9a', 'world_Dino Dive_29bdd9ba', 'world_Dino Dive_6088b756', 'world_Dino Dive_709b1251', 'world_Dino Dive_76babcde', 'world_Dino Dive_7d5c30a2', 'world_Dino Dive_832735e1', 'world_Dino Dive_87d743c1', 'world_Dino Dive_c0415e5c', 'n_incorrect_Pan Balance 0', 'Pan Balance_0086365d', 'Pan Balance_6cf7d25c', 'Pan Balance_9c5ef70c', 'Pan Balance_a592d54e', '28520915', '2dcad279', '30614231', '392e14df', '3ee399c3', '532a2afb', '90d848e0', 'n_incorrect_Scrub-A-Dub_0', '0d18d96c', 'Pan Balance_2a444e03', 'Pan Balance_804ee27f', 'Pan Balance_907a054b', 'Pan Balance_a5e9da97', 'Pan Balance_bc8f2793', 'Pan Balance_e7561dd2', 'Pan Balance_f3cd5473', 'n_incorrect_Happy Camel 0', 'Happy Camel_1af8be29', 'Happy Camel_3bb91ced', 'Happy Camel_3d8c61b0', 'Happy Camel_69fdac0a', 'Happy Camel_6bf9e3e1', 'Happy Camel_8af75982', 'Happy Camel_a7640a16', 'Happy Camel_a8a78786', 'Happy Camel_abc5811c', 'Happy Camel_c2baf0bd', 'Happy Camel_d51b1749', 'Happy Camel_d9c005dd', 'world_n_incorrect_Chow Time 0', 'world_Chow Time_0330ab6a', 'world_Chow Time_0d1da71f', 'world_Chow Time_4ef8cdd3', 'world_Chow Time_63f13dd7', 'world_Chow Time_7372e1a5', 'world_Chow Time_7d093bf9', 'world_Chow Time_7ec0c298', 'world_Chow Time_cfbd47c8', 'world_Chow Time_d185d3ea', 'world_Chow Time_f93fc684', 'world_n_incorrect_Pan Balance 0', 'world_Pan Balance_0086365d', 'world_Pan Balance_15f99afc', 'world_Pan Balance_2a444e03', 'world_Pan Balance_907a054b', 'world_Pan Balance_9c5ef70c', 'world_Pan Balance_a592d54e', 'world_Pan Balance_a5e9da97', 'world_Pan Balance_bc8f2793', 'world_Pan Balance_e7561dd2', 'world_Pan Balance_f3cd5473', 'world_n_incorrect_Happy Camel 0', 'world_Happy Camel_1af8be29', 'world_Happy Camel_3bb91ced', 'world_Happy Camel_3d8c61b0', 'world_Happy Camel_69fdac0a', 'world_Happy Camel_6bf9e3e1', 'world_Happy Camel_8af75982', 'world_Happy Camel_a7640a16', 'world_Happy Camel_a8a78786', 'world_Happy Camel_abc5811c', 'world_Happy Camel_c2baf0bd', 'world_Happy Camel_d51b1749', 'world_Happy Camel_d9c005dd', '5c2f29ca', '5e109ec3', '65a38bf7', '795e4a37', '828e68f9', 'a8876db3', 'b2e5b0f1', 'd122731b', 'All Star Sorting_b1d5101d', 'Crystals Rule_a1192f43', 'world_All Star Sorting_b1d5101d', 'world_Crystals Rule_a1192f43', 'Air Show_6f4bd64e', 'n_incorrect_Chow Time 1', 'Chow Time_9e6b7fb5', 'Happy Camel_37db1c2f', 'Happy Camel_c189aaf2', 'n_incorrect_Leaf Leader 0', 'Leaf Leader_262136f4', 'Leaf Leader_29f54413', 'Leaf Leader_2a512369', 'Leaf Leader_3afde5dd', 'Leaf Leader_67aa2ada', 'Leaf Leader_763fc34e', 'Leaf Leader_7dfe6d8a', 'Leaf Leader_86ba578b', 'Leaf Leader_8ac7cce4', 'Leaf Leader_f32856e4', 'Leaf Leader_fd20ea40', 'world_n_incorrect_Chow Time 1', 'world_Chow Time_47026d5f', 'world_Chow Time_9e6b7fb5', 'world_Happy Camel_37db1c2f', 'world_Happy Camel_c189aaf2', 'world_n_incorrect_Leaf Leader 0', 'world_Leaf Leader_262136f4', 'world_Leaf Leader_29f54413', 'world_Leaf Leader_2a512369', 'world_Leaf Leader_3afde5dd', 'world_Leaf Leader_67aa2ada', 'world_Leaf Leader_763fc34e', 'world_Leaf Leader_7dfe6d8a', 'world_Leaf Leader_86ba578b', 'world_Leaf Leader_8ac7cce4', 'world_Leaf Leader_f32856e4', 'world_Leaf Leader_fd20ea40', 'Pan Balance_e080a381', '0db6d71d', '155f62a4', '3ccd3f02', '3d0b9317', '562cec5f', '93b353f2', 'a8efe47b', 'bd612267', 'df4fe8b6', 'world_Pan Balance_e080a381', '070a5291', '3393b68b', '45d01abe', '8fee50e2', 'f6947f54', '2b058fe3', '91561152', '9ce586dd', '9d4e7b25', 'acf5c23f', 'cb1178ad', 'world_n_incorrect_Dino Drink 0', 'world_Dino Drink_1996c610', 'world_Dino Drink_4d6737eb', 'world_Dino Drink_51311d7a', 'world_Dino Drink_5be391b5', 'world_Dino Drink_6c517a88', 'world_Dino Drink_74e5f8a7', 'world_Dino Drink_792530f8', 'world_Dino Drink_7f0836bf', 'world_Dino Drink_c6971acf', 'world_Dino Drink_f806dc10', 'world_Bubble Bath_5859dfb6', 'n_incorrect_Dino Dive 1', '3d63345e', 'Leaf Leader_53c6e11a', 'Scrub-A-Dub_92687c59', 'n_incorrect_Dino Drink 1', 'Dino Drink_6f8106d9', 'Dino Drink_9ed8f6da', 'n_incorrect_Happy Camel 1', 'Happy Camel_a2df0760', '04df9b66', '3edf6747', 'a76029ee', 'world_n_incorrect_Dino Drink 1', 'world_Dino Drink_6f8106d9', 'world_Dino Drink_9ed8f6da', 'world_n_incorrect_Happy Camel 1', 'world_Happy Camel_a2df0760', 'world_n_incorrect_Scrub-A-Dub 1', '31973d56', '4e5fc6f5', 'n_incorrect_Leaf Leader 1', 'Leaf Leader_3b2048ee', 'world_n_incorrect_Leaf Leader 1', 'world_Leaf Leader_3b2048ee', 'world_Leaf Leader_53c6e11a', '222660ff', '3afb49e6', '5348fd84', 'd38c2fd7', '731c0cbe', 'n_incorrect_Pan Balance 1', 'world_n_incorrect_Pan Balance 1', 'n_incorrect_Bubble Bath 1', 'world_n_incorrect_Bubble Bath 1', 'world_n_incorrect_Dino Dive 1', 'Happy Camel_46b50ba8', 'Chow Time_19967db1', 'world_Chow Time_19967db1', 'Happy Camel_05ad839b', 'world_Happy Camel_05ad839b', 'world_Happy Camel_46b50ba8', 'world_Air Show_6f4bd64e', 'eb2c19cd', 'Crystals Rule_93edfe2e', 'world_Crystals Rule_93edfe2e', 'Dino Dive_d3640339', 'world_Dino Dive_d3640339', '77c76bc5', 'Bubble Bath_29a42aea', '4080', 'Chow Time_6f445b57', 'world_Chow Time_6f445b57', 'All Star Sorting_26a5a3dd', 'world_All Star Sorting_26a5a3dd', 'Bubble Bath_6aeafed4', 'world_Bubble Bath_6aeafed4', '13f56524', 'world_Scrub-A-Dub_92687c59', 'bfc77bd6', 'world_Bubble Bath_29a42aea', 'Dino Drink_ab4ec3a4', 'world_Dino Drink_ab4ec3a4', 'Happy Camel_0ce40006', '9554a50b', 'Dino Dive_119b5b02', 'world_Dino Dive_119b5b02', 'ecc6157f', '6077cc36', 'Pan Balance_e4d32835', 'world_Pan Balance_e4d32835', 'Leaf Leader_01ca3a3c', 'world_Leaf Leader_01ca3a3c', 'world_Happy Camel_0ce40006']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing feature 2000\n",
      "Missing feature 2010\n",
      "Missing feature 2020\n",
      "Missing feature 2025\n",
      "Missing feature 2035\n",
      "Missing feature 2060\n",
      "Missing feature 2070\n",
      "Missing feature 2080\n",
      "Missing feature 2081\n",
      "Missing feature 2083\n",
      "Missing feature 3010\n",
      "Missing feature 3020\n",
      "Missing feature 3021\n",
      "Missing feature 4010\n",
      "Missing feature 4020\n",
      "Missing feature 4025\n",
      "Missing feature 4030\n",
      "Missing feature 4035\n",
      "Missing feature 4040\n",
      "Missing feature 4070\n",
      "Missing feature 4090\n",
      "Missing feature 4100\n",
      "Missing feature 4110\n",
      "Missing feature accuracy_group\n",
      "Missing feature 4045\n",
      "Missing feature 4095\n",
      "Missing feature 2075\n",
      "Missing feature Bubble Bath_29a42aea\n",
      "Missing feature 4080\n",
      "Missing feature 13f56524\n",
      "Missing feature bfc77bd6\n",
      "Missing feature world_Bubble Bath_29a42aea\n",
      "Missing feature Dino Drink_ab4ec3a4\n",
      "Missing feature world_Dino Drink_ab4ec3a4\n",
      "Missing feature Happy Camel_0ce40006\n",
      "Missing feature Dino Dive_119b5b02\n",
      "Missing feature world_Dino Dive_119b5b02\n",
      "Missing feature ecc6157f\n",
      "Missing feature Pan Balance_e4d32835\n",
      "Missing feature world_Pan Balance_e4d32835\n",
      "Missing feature Leaf Leader_01ca3a3c\n",
      "Missing feature world_Leaf Leader_01ca3a3c\n",
      "Missing feature world_Happy Camel_0ce40006\n"
     ]
    }
   ],
   "source": [
    "for useful_feature in useful_features:\n",
    "    if useful_feature not in test_features.columns:\n",
    "        test_features[useful_feature]=-1\n",
    "        print(\"Missing feature\", useful_feature)\n",
    "        \n",
    "test_features=test_features[[c for c in useful_features if c != \"accuracy_group\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_features, encoded_features = make_dummy_features(test_features)\n",
    "nn_features = [f for f in (useful_features + dummy_features) if f not in encoded_features and f !=\"accuracy_group\"]\n",
    "test_features = test_features[nn_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__validation.py__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold, KFold\n",
    "from sklearn.utils import shuffle\n",
    "from typing import NamedTuple\n",
    "from functools import partial\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "\n",
    "class Predict(NamedTuple):\n",
    "    true: np.array\n",
    "    pred: np.array\n",
    "\n",
    "\n",
    "class InstallationFold(GroupKFold):\n",
    "    def __init__(self, n_splits=5, installation_ids=None):\n",
    "        super().__init__(n_splits=n_splits)\n",
    "        self.installation_ids = installation_ids\n",
    "\n",
    "    def split(self, X, y, installation_ids=None):\n",
    "        if installation_ids is None:\n",
    "            installation_ids = self.installation_ids\n",
    "        orig_indices = np.arange(len(X))\n",
    "        shuffled_indices, installation_ids = shuffle(orig_indices, installation_ids, random_state=2019)\n",
    "        for train, test in super().split(shuffled_indices, shuffled_indices, installation_ids):\n",
    "            yield shuffled_indices[train], shuffled_indices[test]\n",
    "\n",
    "\n",
    "def fit_fold(df, train_ix, test_ix, make_features, train_model, make_predictions):\n",
    "    train = df.iloc[train_ix].copy()\n",
    "    test = df.iloc[test_ix].copy()\n",
    "    train_features, test_features = make_features(train, test)\n",
    "    model = train_model(*train_features)\n",
    "    test_pred, test_true = make_predictions(model, *test_features)\n",
    "    return Predict(test_true, test_pred)\n",
    "\n",
    "\n",
    "def cross_validate(train, labels, make_features, train_model, make_predictions, cv=None):\n",
    "    predicts = []\n",
    "    np.random.seed(2019)\n",
    "    cv = InstallationFold() if cv is None else cv\n",
    "    for ix_train, ix_test in cv.split(train, labels, train.installation_id.values):\n",
    "        predicts.append(fit_fold(train, ix_train, ix_test, make_features, train_model, make_predictions))\n",
    "    return predicts\n",
    "\n",
    "\n",
    "quad_kappa = partial(cohen_kappa_score, weights=\"quadratic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__coeff.py__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from functools import partial\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "#from dsb2019.data.validation import quad_kappa\n",
    "\n",
    "\n",
    "class ThresholdClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_iter=1000, random_state=2019):\n",
    "        self.n_iter=n_iter\n",
    "        self.random_state=random_state\n",
    "\n",
    "    def _run_trial(self, X, y, params):\n",
    "        threshold1 = params[\"threshold1\"]\n",
    "        threshold2 = threshold1 + abs(params[\"threshold2_delta\"])\n",
    "        threshold3 = threshold2 + abs(params[\"threshold3_delta\"]) \n",
    "        pred = pd.cut(X, [-np.inf, threshold1, threshold2, threshold3, np.inf], labels = [0, 1, 2, 3])\n",
    "        return {\n",
    "           \"loss\": -quad_kappa(y, pred),\n",
    "           \"status\": STATUS_OK,\n",
    "           \"coef\": [threshold1, threshold2, threshold3]\n",
    "        }\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        class1_percentile = sum(y<1) / len(y) * 100\n",
    "        class2_percentile = sum(y<2) / len(y) * 100\n",
    "        class3_percentile = sum(y<3) / len(y) * 100\n",
    "        threshold1_prior = np.percentile(X, class1_percentile)\n",
    "        threshold2_prior = np.percentile(X, class2_percentile)\n",
    "        threshold3_prior = np.percentile(X, class3_percentile)\n",
    "        threshold2_delta_prior = threshold2_prior - threshold1_prior\n",
    "        threshold3_delta_prior = threshold3_prior - threshold2_prior\n",
    "        prior_std = (np.percentile(X, 99) - np.percentile(X, 1)) / 3\n",
    "        space = {\n",
    "            \"threshold1\": hp.normal(\"threshold1\", threshold1_prior, prior_std),\n",
    "            \"threshold2_delta\": hp.normal(\"threshold2_delta\", threshold2_delta_prior, prior_std),\n",
    "            \"threshold3_delta\": hp.normal(\"threshold3_delta\", threshold3_delta_prior, prior_std)\n",
    "        }\n",
    "\n",
    "        partial_run = partial(self._run_trial, X, y)\n",
    "\n",
    "        trials = Trials()\n",
    "        fmin(partial_run, space=space,\n",
    "             algo=tpe.suggest,\n",
    "             max_evals=self.n_iter, rstate=np.random.RandomState(self.random_state), trials=trials)\n",
    "        \n",
    "        self.coef_ = trials.best_trial[\"result\"][\"coef\"]\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return pd.cut(X, [-np.inf] + self.coef_ + [np.inf], labels = [0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(test_features, model):\n",
    "    installations = test_features.installation_id.values\n",
    "    test = test_features.drop(\"installation_id\", axis=1)\n",
    "    predictions = model.predict(test)\n",
    "    clf = ThresholdClassifier()\n",
    "    clf.coef_=coef\n",
    "    predictions = clf.predict(predictions)\n",
    "    return pd.DataFrame(data={\"installation_id\": installations, \"accuracy_group\": predictions})\n",
    "\n",
    "submission = make_submission(test_features, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"../../data/submissions/nn_regression.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    425\n",
       "2    311\n",
       "0    157\n",
       "1    107\n",
       "Name: accuracy_group, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.accuracy_group.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
