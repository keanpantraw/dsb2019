{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "test = pd.read_csv('../../data/raw/test.csv')\n",
    "model = lgb.Booster(model_file='../../models/regression_baseline_rmse.lgb')\n",
    "coef=[1.1652705553319513, 1.7983061293534481, 2.2127169630913537]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<02:10,  7.67it/s]/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in long_scalars\n",
      "100%|██████████| 1000/1000 [01:31<00:00, 10.92it/s]\n"
     ]
    }
   ],
   "source": [
    "games = ['Scrub-A-Dub', 'All Star Sorting', 'Mushroom Sorter (Assessment)',\n",
    "       'Air Show', 'Crystals Rule', 'Bird Measurer (Assessment)',\n",
    "       'Dino Drink', 'Bubble Bath', 'Dino Dive', 'Chow Time',\n",
    "       'Cauldron Filler (Assessment)', 'Pan Balance', 'Happy Camel',\n",
    "       'Cart Balancer (Assessment)', 'Chest Sorter (Assessment)',\n",
    "       'Leaf Leader']\n",
    "\n",
    "\n",
    "def unwrap_event_data(df):\n",
    "    unwrapped=pd.DataFrame(data=list(df.event_data.apply(json.loads).values))\n",
    "    return pd.concat([unwrapped.reset_index(),df.reset_index()],axis=1)\n",
    "\n",
    "\n",
    "def process_log(df):\n",
    "    assessment_title=df.title.iloc[-1]    \n",
    "\n",
    "    history = df.iloc[:-1]\n",
    "    history = history[history.type.isin([\"Game\", \"Assessment\"])].copy()\n",
    "\n",
    "    def calculate_ratios(df):\n",
    "        n_correct=df.correct_move.sum()\n",
    "        n_incorrect=df.wrong_move.sum()\n",
    "        ratio=n_correct/(n_correct+n_incorrect)\n",
    "        return n_correct, n_incorrect, ratio\n",
    "    \n",
    "    def make_move_stats(df, title,n_lags=2):\n",
    "        df=df.copy()\n",
    "        if len(df):\n",
    "            df = unwrap_event_data(df)\n",
    "        if \"correct\" in df.columns:\n",
    "            df[\"correct_move\"] = df.correct == True\n",
    "            df[\"wrong_move\"] = df.correct == False\n",
    "        else:\n",
    "            df[\"correct_move\"]=False\n",
    "            df[\"wrong_move\"]=False\n",
    "        result = []\n",
    "        result.extend(zip([f\"n_correct {title}\", f\"n_incorrect {title}\", f\"global_ratio {title}\"], calculate_ratios(df)))\n",
    "        if n_lags:\n",
    "            last_sessions = df.game_session.unique()[-n_lags:]\n",
    "            for i in range(n_lags):\n",
    "                if i < len(last_sessions): \n",
    "                    result.extend(zip([f\"n_correct {title} {i}\", f\"n_incorrect {title} {i}\",f\"ratio {title} {i}\"], \n",
    "                                      calculate_ratios(df[df.game_session==last_sessions[i]])))\n",
    "                else:\n",
    "                    result.extend(zip([f\"n_correct {title} {i}\", f\"n_incorrect {title} {i}\",f\"ratio {title} {i}\"], [None, None, None]))\n",
    "        return {k: v for k, v in result}\n",
    "    result = {\"title\": games.index(assessment_title)}\n",
    "    for game in games:\n",
    "        stats=history[history.title==game]\n",
    "        stats=make_move_stats(stats, game)\n",
    "        result.update(stats)\n",
    "    return result\n",
    "\n",
    "\n",
    "def process_test_installations(test):\n",
    "    test = test.sort_values(\"timestamp\")\n",
    "    test=test.groupby(\"installation_id\").progress_apply(process_log).reset_index()\n",
    "    test.columns = [\"installation_id\", \"features\"]\n",
    "    result = []\n",
    "    for i, installation_id, feature in test.itertuples():\n",
    "        result.append(feature)\n",
    "        feature[\"installation_id\"]=installation_id\n",
    "    return pd.DataFrame(result).fillna(-1)\n",
    "\n",
    "test_features=process_test_installations(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__validation.py__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold, KFold\n",
    "from sklearn.utils import shuffle\n",
    "from typing import NamedTuple\n",
    "from functools import partial\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "\n",
    "class Predict(NamedTuple):\n",
    "    true: np.array\n",
    "    pred: np.array\n",
    "\n",
    "\n",
    "class InstallationFold(GroupKFold):\n",
    "    def __init__(self, n_splits=5, installation_ids=None):\n",
    "        super().__init__(n_splits=n_splits)\n",
    "        self.installation_ids = installation_ids\n",
    "\n",
    "    def split(self, X, y, installation_ids=None):\n",
    "        if installation_ids is None:\n",
    "            installation_ids = self.installation_ids\n",
    "        orig_indices = np.arange(len(X))\n",
    "        shuffled_indices, installation_ids = shuffle(orig_indices, installation_ids, random_state=2019)\n",
    "        for train, test in super().split(shuffled_indices, shuffled_indices, installation_ids):\n",
    "            yield shuffled_indices[train], shuffled_indices[test]\n",
    "\n",
    "\n",
    "def fit_fold(df, train_ix, test_ix, make_features, train_model, make_predictions):\n",
    "    train = df.iloc[train_ix].reset_index().copy()\n",
    "    test = df.iloc[test_ix].reset_index().copy()\n",
    "    train_features, test_features = make_features(train, test)\n",
    "    model = train_model(*train_features)\n",
    "    test_pred, test_true = make_predictions(model, *test_features)\n",
    "    return Predict(test_true, test_pred)\n",
    "\n",
    "\n",
    "def cross_validate(train, labels, make_features, train_model, make_predictions, cv=None):\n",
    "    predicts = []\n",
    "    np.random.seed(2019)\n",
    "    cv = InstallationFold() if cv is None else cv\n",
    "    for ix_train, ix_test in cv.split(train, labels, train.installation_id.values):\n",
    "        predicts.append(fit_fold(train, ix_train, ix_test, make_features, train_model, make_predictions))\n",
    "    return predicts\n",
    "\n",
    "\n",
    "quad_kappa = partial(cohen_kappa_score, weights=\"quadratic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__coeff.py__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from functools import partial\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "#from dsb2019.data.validation import quad_kappa\n",
    "\n",
    "\n",
    "class ThresholdClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_iter=1000, random_state=2019):\n",
    "        self.n_iter=n_iter\n",
    "        self.random_state=random_state\n",
    "\n",
    "    def _run_trial(self, X, y, params):\n",
    "        threshold1 = params[\"threshold1\"]\n",
    "        threshold2 = threshold1 + abs(params[\"threshold2_delta\"])\n",
    "        threshold3 = threshold2 + abs(params[\"threshold3_delta\"]) \n",
    "        pred = pd.cut(X, [-np.inf, threshold1, threshold2, threshold3, np.inf], labels = [0, 1, 2, 3])\n",
    "        return {\n",
    "           \"loss\": -quad_kappa(y, pred),\n",
    "           \"status\": STATUS_OK,\n",
    "           \"coef\": [threshold1, threshold2, threshold3]\n",
    "        }\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        class1_percentile = sum(y<1) / len(y) * 100\n",
    "        class2_percentile = sum(y<2) / len(y) * 100\n",
    "        class3_percentile = sum(y<3) / len(y) * 100\n",
    "        threshold1_prior = np.percentile(X, class1_percentile)\n",
    "        threshold2_prior = np.percentile(X, class2_percentile)\n",
    "        threshold3_prior = np.percentile(X, class3_percentile)\n",
    "        threshold2_delta_prior = threshold2_prior - threshold1_prior\n",
    "        threshold3_delta_prior = threshold3_prior - threshold2_prior\n",
    "        prior_std = (np.percentile(X, 99) - np.percentile(X, 1)) / 3\n",
    "        space = {\n",
    "            \"threshold1\": hp.normal(\"threshold1\", threshold1_prior, prior_std),\n",
    "            \"threshold2_delta\": hp.normal(\"threshold2_delta\", threshold2_delta_prior, prior_std),\n",
    "            \"threshold3_delta\": hp.normal(\"threshold3_delta\", threshold3_delta_prior, prior_std)\n",
    "        }\n",
    "\n",
    "        partial_run = partial(self._run_trial, X, y)\n",
    "\n",
    "        trials = Trials()\n",
    "        fmin(partial_run, space=space,\n",
    "             algo=tpe.suggest,\n",
    "             max_evals=self.n_iter, rstate=np.random.RandomState(self.random_state), trials=trials)\n",
    "        \n",
    "        self.coef_ = trials.best_trial[\"result\"][\"coef\"]\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return pd.cut(X, [-np.inf] + self.coef_ + [np.inf], labels = [0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(test_features, model):\n",
    "    installations = test_features.installation_id.values\n",
    "    test = test_features.drop(\"installation_id\", axis=1)\n",
    "    predictions = model.predict(test)\n",
    "    clf = ThresholdClassifier()\n",
    "    clf.coef_=coef\n",
    "    predictions = clf.predict(predictions)\n",
    "    return pd.DataFrame(data={\"installation_id\": installations, \"accuracy_group\": predictions})\n",
    "\n",
    "submission = make_submission(test_features, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"../../data/submissions/regression_baseline_rmse.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    391\n",
       "2    320\n",
       "0    159\n",
       "1    130\n",
       "Name: accuracy_group, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.accuracy_group.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
