{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/code/dsb2019/notebooks\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "test = pd.read_csv('../data/raw/test.csv')\n",
    "model = lgb.Booster(model_file='/code/dsb2019/models/time_baseline.lgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = ['Scrub-A-Dub', 'All Star Sorting', 'Mushroom Sorter (Assessment)',\n",
    "       'Air Show', 'Crystals Rule', 'Bird Measurer (Assessment)',\n",
    "       'Dino Drink', 'Bubble Bath', 'Dino Dive', 'Chow Time',\n",
    "       'Cauldron Filler (Assessment)', 'Pan Balance', 'Happy Camel',\n",
    "       'Cart Balancer (Assessment)', 'Chest Sorter (Assessment)',\n",
    "       'Leaf Leader']\n",
    "\n",
    "\n",
    "def unwrap_event_data(df):\n",
    "    unwrapped = json_normalize(df.event_data.apply(json.loads))\n",
    "    return pd.concat([unwrapped.reset_index(),df.reset_index()],axis=1)\n",
    "\n",
    "\n",
    "def process_installations_parallel(process_installations, process_log, df, *dataframes):\n",
    "    installations = df.installation_id.unique()\n",
    "    jobs = []\n",
    "    n_jobs=cpu_count()\n",
    "    with joblib.Parallel(n_jobs=n_jobs) as workers:\n",
    "        chunk_size = len(installations) // n_jobs\n",
    "        for pos, i in enumerate(range(0, len(installations), chunk_size)):\n",
    "            inst_chunk = installations[i:min(i + chunk_size, len(installations))]\n",
    "            df_chunk = df[df.installation_id.isin(inst_chunk)].copy()\n",
    "            dataframes_chunk = [d[d.installation_id.isin(inst_chunk)].copy() for d in dataframes]\n",
    "            jobs.append(joblib.delayed(process_installations)(process_log, df_chunk, *dataframes_chunk, position=pos))\n",
    "        result = []\n",
    "        for result_df in workers(jobs):\n",
    "            result.append(result_df.reset_index())\n",
    "    return pd.concat(result).drop(\"index\", axis=1)\n",
    "\n",
    "\n",
    "def process_installations(process_log, train_labels, train, position=0):\n",
    "    result = []\n",
    "    train[\"timestamp\"] = pd.to_datetime(train.timestamp)\n",
    "    train = train.drop([\"event_count\"], axis=1)\n",
    "    train=train.sort_values(\"timestamp\")\n",
    "    installations = train.groupby(\"installation_id\")\n",
    "    for i, game_session, title, installation_id, accuracy_group in tqdm(train_labels[[\"game_session\", \"title\", \"installation_id\", \"accuracy_group\"]].itertuples(), \n",
    "                                                              total=len(train_labels), position=position):\n",
    "        player_log = installations.get_group(installation_id).reset_index()\n",
    "        log_length = player_log[(player_log.game_session==game_session) & (player_log.title==title)].index[0]\n",
    "        player_log = player_log.iloc[:(log_length + 1)]\n",
    "        player_log[\"accuracy_group\"] = accuracy_group\n",
    "        player_log[\"target_game_session\"] = game_session\n",
    "        features = process_log(player_log)\n",
    "        features[\"installation_id\"] = installation_id\n",
    "        features[\"accuracy_group\"] = accuracy_group\n",
    "        result.append(features)\n",
    "    result = pd.DataFrame(data=result).fillna(-1)\n",
    "    return result[sorted(result.columns)].copy()\n",
    "\n",
    "\n",
    "def calculate_ratios(df):\n",
    "    if len(df)==0:\n",
    "        return 0, 0, None\n",
    "\n",
    "    n_correct=df.correct_move.sum()\n",
    "    n_incorrect=df.wrong_move.sum()\n",
    "    ratio=n_correct/(n_correct+n_incorrect)\n",
    "    return n_correct, n_incorrect, ratio\n",
    "\n",
    "\n",
    "def make_move_stats(assessment, df, title):\n",
    "    result = []\n",
    "    result.extend(zip([\"n_correct \" + title, \"n_incorrect \" + title, \"global_ratio \" + title], calculate_ratios(df)))\n",
    "    return {k: v for k,v in result}\n",
    "\n",
    "\n",
    "def shrink_session(group):\n",
    "    group = populate_correct_moves(group)\n",
    "    correct_moves = group[group.correct_move]\n",
    "    correct_timestamps = correct_moves.timestamp\n",
    "    correct_turns = correct_moves.event_count\n",
    "    time_between_correct_moves = (correct_timestamps - correct_timestamps.shift(1)).dropna() / np.timedelta64(1, \"m\")\n",
    "    turns_between_correct_moves = (correct_turns - correct_turns.shift(1)).dropna()\n",
    "    result = {\n",
    "        \"mean_turns_between_correct_moves\": turns_between_correct_moves.median()\n",
    "    } \n",
    "    result[\"start_time\"] = group.timestamp.min()\n",
    "    result[\"end_time\"] = group.timestamp.max()\n",
    "    result[\"duration\"] = result[\"end_time\"] - result[\"start_time\"]\n",
    "    result[\"correct_move\"] = group.correct_move.sum()\n",
    "    result[\"wrong_move\"] = group.wrong_move.sum()\n",
    "    result[\"title\"] = group.title.iloc[0]\n",
    "    result[\"installation_id\"] = group.installation_id.iloc[0]\n",
    "    result[\"game_session\"] = group.game_session.iloc[0]\n",
    "    return result\n",
    "\n",
    "\n",
    "def populate_correct_moves(history: pd.DataFrame) -> pd.DataFrame:\n",
    "    if \"correct\" in history.columns:\n",
    "        history[\"correct_move\"] = history.correct == True\n",
    "        history[\"wrong_move\"] = history.correct == False\n",
    "    else:\n",
    "        history[\"correct_move\"]=False\n",
    "        history[\"wrong_move\"]=False\n",
    "    return history\n",
    "\n",
    "    \n",
    "def make_base_time_features(assessment, history):\n",
    "    start_end_times = history\n",
    "    duration_minutes = start_end_times.duration / np.timedelta64(1, \"m\")\n",
    "    result = {\n",
    "        \"mean_session_time_minutes\": round(duration_minutes.mean(), 0), \n",
    "        #\"mean_turns_between_correct_moves\": history.mean_turns_between_correct_moves.median(),\n",
    "        #\"mean_time_between_correct_moves\": history.mean_time_between_correct_moves.mean(),\n",
    "        #\"mean_time_before_first_correct_move\": history.time_before_first_correct_move.mean(),\n",
    "        #\"mean_turns_before_first_correct_move\": history.turns_before_first_correct_move.median(),\n",
    "    }\n",
    "    last_event_time = assessment.timestamp\n",
    "    first_event_time = start_end_times.start_time.min()\n",
    "    \n",
    "    days_active = round((last_event_time - first_event_time) / np.timedelta64(1, \"D\"), 0) + 1\n",
    "    result[\"games_per_day\"] = round(history.game_session.nunique() / days_active, 2)\n",
    "    \n",
    "    minutes_between_games = ((start_end_times.start_time - start_end_times.start_time.shift(1)).dropna() / np.timedelta64(1, \"m\")).round(0)\n",
    "    #result[\"mean_minutes_between_games\"] = round(minutes_between_games.mean(), 2)\n",
    "    return result\n",
    "\n",
    "\n",
    "def make_game_time_features(assessment, history, title):\n",
    "    _1day=history[history.start_time>=(assessment.timestamp-pd.Timedelta(1,'D'))]\n",
    "    _7days=history[history.start_time>=(assessment.timestamp-pd.Timedelta(7,'D'))]\n",
    "    result = {\n",
    "    #    \"hours_played\": round(history.duration.sum() / np.timedelta64(1, \"h\"), 0),\n",
    "        \"games_played\": history.game_session.nunique(),\n",
    "    }\n",
    "    #for suffix, df in [(\"1d\", _1day), (\"7d\", _7days)]:\n",
    "    #    n_correct, n_incorrect, ratio=calculate_ratios(df)\n",
    "    #    result[\"n_correct_\"+suffix]=n_correct\n",
    "    #    result[\"n_incorrect_\"+suffix]=n_incorrect\n",
    "    #    result[\"game_ratio_\"+suffix]=ratio\n",
    "    return result\n",
    "\n",
    "    \n",
    "def apply_on_sessions(assessment, history, n_lags, func_list, title):\n",
    "    result = {}\n",
    "    empty = history.head(0)\n",
    "    if n_lags:\n",
    "        last_sessions = history.game_session.unique()[-n_lags:]\n",
    "        for i in range(n_lags):\n",
    "            for get_features in func_list:\n",
    "                if i < len(last_sessions):\n",
    "                    lag_features = get_features(assessment, history[history.game_session==last_sessions[i]], title)\n",
    "                else:\n",
    "                    lag_features = get_features(assessment, empty, title)\n",
    "                features = {}\n",
    "                for k, v in lag_features.items():\n",
    "                    features[\"%s %d\" % (k, i)] = v\n",
    "                result.update(features)\n",
    "    return result\n",
    "\n",
    "\n",
    "def make_calendar_features(assessment, history):\n",
    "    ts = assessment.timestamp\n",
    "    year = ts.year\n",
    "    month = ts.month\n",
    "    dayofweek = ts.dayofweek\n",
    "    time = ts.time()\n",
    "    return {\n",
    "        \"month\": month,\n",
    "        \"dayofweek\": dayofweek,\n",
    "        \"hour\": time.hour,\n",
    "    }\n",
    "\n",
    "\n",
    "def make_base_features(assessment, history):\n",
    "    return  {\n",
    "        \"title\": games.index(assessment.title)\n",
    "    }\n",
    "\n",
    "base_stats = [populate_correct_moves]\n",
    "base_features = [make_base_features, make_calendar_features, make_base_time_features]\n",
    "game_features = [make_move_stats, make_game_time_features]\n",
    "lag_features = [make_move_stats]\n",
    "\n",
    "\n",
    "\n",
    "def get_base_features(assessment, history):\n",
    "    result = {}\n",
    "    for f in base_features:\n",
    "        result.update(f(assessment, history))\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_game_features(assessment, stats, game):\n",
    "    result = {}\n",
    "    for f in game_features:\n",
    "        result.update({game + \" \" + k: v for k, v in f(assessment, stats, game).items()})\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_lag_features(assessment, stats, game, n_lags):\n",
    "    res = {}\n",
    "    result = apply_on_sessions(assessment, stats, n_lags, lag_features, game)\n",
    "    for k, v in result.items():\n",
    "        res[game + \" \" + k] = v\n",
    "    return res       \n",
    "\n",
    "\n",
    "def process_log(df):\n",
    "    assessment = df.iloc[-1]\n",
    "    history = df.iloc[:-1]\n",
    "    history = history[history.type.isin([\"Game\", \"Assessment\"])]\n",
    "    \n",
    "    if len(history):\n",
    "        history = unwrap_event_data(history)\n",
    "    else:\n",
    "        return {}\n",
    "    history.sort_values(\"timestamp\", inplace=True)\n",
    "    \n",
    "    for f in base_stats:\n",
    "        history = f(history)\n",
    "    \n",
    "    history = json_normalize(history.groupby(\"game_session\").apply(shrink_session))\n",
    "    history.sort_values(\"start_time\", inplace=True)\n",
    "    result = {}\n",
    "    result.update(get_base_features(assessment, history))\n",
    "    for game in games:\n",
    "        stats=history[history.title==game]\n",
    "        result.update(get_game_features(assessment, stats, game))\n",
    "        result.update(get_lag_features(assessment, stats, game, 2))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_installations(test):\n",
    "    test = test.drop([\"event_count\"], axis=1)\n",
    "    test[\"timestamp\"]=pd.to_datetime(test.timestamp)\n",
    "    test = test.sort_values(\"timestamp\")\n",
    "    result = []\n",
    "    for installation_id, group in tqdm(test.groupby(\"installation_id\")):\n",
    "        group = group.reset_index().copy()\n",
    "        feature = process_log(group)\n",
    "        feature[\"installation_id\"] = installation_id\n",
    "        result.append(feature)\n",
    "    result = pd.DataFrame(result).fillna(-1)\n",
    "    result = result[sorted(result.columns)].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [00:00<03:22,  4.91it/s]/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:58: RuntimeWarning: invalid value encountered in long_scalars\n",
      "100%|██████████| 1000/1000 [02:54<00:00,  5.73it/s]\n"
     ]
    }
   ],
   "source": [
    "test_features = process_test_installations(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(test_features, model):\n",
    "    installations = test_features.installation_id.values\n",
    "    test = test_features.drop(\"installation_id\", axis=1)\n",
    "    predictions = model.predict(test).argmax(axis=1).astype(int)\n",
    "    return pd.DataFrame(data={\"installation_id\": installations, \"accuracy_group\": predictions})\n",
    "\n",
    "submission = make_submission(test_features, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"../data/submissions/time_baseline.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
