{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from functools import reduce\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import json\n",
    "import numba\n",
    "from functools import partial\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "from dsb2019.models.tracking import track_experiment, track_submission_info\n",
    "from dsb2019.data.validation import InstallationFold, cross_validate, quad_kappa\n",
    "from dsb2019.visualization import session_browser\n",
    "from dsb2019.data import DATA_DIR\n",
    "from dsb2019.models import MODELS_DIR\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, Trials, tpe, STATUS_OK\n",
    "tqdm.pandas()\n",
    "pd.options.display.max_rows=999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_DIR / 'raw/train.csv')\n",
    "test = pd.read_csv(DATA_DIR / 'raw/test.csv')\n",
    "train_labels = pd.read_csv(DATA_DIR / 'raw/train_labels.csv')\n",
    "submission = pd.read_csv(DATA_DIR / 'raw/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = ['Scrub-A-Dub', 'All Star Sorting', 'Mushroom Sorter (Assessment)',\n",
    "       'Air Show', 'Crystals Rule', 'Bird Measurer (Assessment)',\n",
    "       'Dino Drink', 'Bubble Bath', 'Dino Dive', 'Chow Time',\n",
    "       'Cauldron Filler (Assessment)', 'Pan Balance', 'Happy Camel',\n",
    "       'Cart Balancer (Assessment)', 'Chest Sorter (Assessment)',\n",
    "       'Leaf Leader']\n",
    "\n",
    "\n",
    "def unwrap_event_data(df):\n",
    "    unwrapped = json_normalize(df.event_data.apply(json.loads))\n",
    "    return pd.concat([unwrapped.reset_index(),df.reset_index()],axis=1)\n",
    "\n",
    "\n",
    "def process_installations(train_labels, train, process_log):\n",
    "    result = []\n",
    "    train[\"timestamp\"] = pd.to_datetime(train.timestamp)\n",
    "    train = train.drop([\"event_count\"], axis=1)\n",
    "    train=train.sort_values(\"timestamp\")\n",
    "    installations = train.groupby(\"installation_id\")\n",
    "    for i, game_session, title, installation_id, accuracy_group in tqdm(train_labels[[\"game_session\", \"title\", \"installation_id\", \"accuracy_group\"]].itertuples(), \n",
    "                                                              total=len(train_labels)):\n",
    "        player_log = installations.get_group(installation_id).reset_index()\n",
    "        log_length = player_log[(player_log.game_session==game_session) & (player_log.title==title)].index[0]\n",
    "        player_log = player_log.iloc[:(log_length + 1)]\n",
    "        player_log[\"accuracy_group\"] = accuracy_group\n",
    "        player_log[\"target_game_session\"] = game_session\n",
    "        features = process_log(player_log)\n",
    "        features[\"installation_id\"] = installation_id\n",
    "        features[\"accuracy_group\"] = accuracy_group\n",
    "        result.append(features)\n",
    "    return result\n",
    "\n",
    "\n",
    "def calculate_ratios(df):\n",
    "    n_correct=df.correct_move.sum()\n",
    "    n_incorrect=df.wrong_move.sum()\n",
    "    ratio=n_correct/(n_correct+n_incorrect)\n",
    "    return n_correct, n_incorrect, ratio\n",
    "\n",
    "\n",
    "def make_move_stats(df, title,n_lags=2):\n",
    "    result = []\n",
    "    result.extend(zip([\"n_correct \" + title, \"n_incorrect \" + title, \"global_ratio \" + title], calculate_ratios(df)))\n",
    "    if n_lags:\n",
    "        last_sessions = df.game_session.unique()[-n_lags:]\n",
    "        for i in range(n_lags):\n",
    "            if i < len(last_sessions): \n",
    "                result.extend(zip([\"n_correct {} {}\".format(title,i), \"n_incorrect {} {}\".format(title,i),\"ratio {} {}\".format(title,i)], \n",
    "                                  calculate_ratios(df[df.game_session==last_sessions[i]])))\n",
    "            else:\n",
    "                result.extend(zip([\"n_correct {} {}\".format(title,i), \"n_incorrect {} {}\".format(title,i),\n",
    "                                   \"ratio {} {}\".format(title,i)], [None, None, None]))\n",
    "    \n",
    "    return {k: v for k,v in result}\n",
    "\n",
    "\n",
    "def shrink_session(group):\n",
    "    group = populate_correct_moves(group)\n",
    "    correct_moves = group[group.correct_move]\n",
    "    correct_timestamps = correct_moves.timestamp\n",
    "    correct_turns = correct_moves.event_count\n",
    "    time_between_correct_moves = (correct_timestamps - correct_timestamps.shift(1)).dropna() / np.timedelta64(1, \"m\")\n",
    "    turns_between_correct_moves = (correct_turns - correct_turns.shift(1)).dropna()\n",
    "    result = {\n",
    "        \"mean_time_between_correct_moves\": time_between_correct_moves.mean(),\n",
    "        \"mean_turns_between_correct_moves\": turns_between_correct_moves.mean()\n",
    "    }\n",
    "    if len(correct_timestamps):\n",
    "        result[\"time_before_first_correct_move\"] = (correct_timestamps.iloc[0] - group.timestamp.iloc[0]) / np.timedelta64(1, \"m\")\n",
    "        result[\"turns_before_first_correct_move\"] = correct_turns.iloc[0]\n",
    "    else:\n",
    "        result[\"time_before_first_correct_move\"] = None\n",
    "        result[\"turns_before_first_correct_move\"] = None\n",
    "    result[\"start_time\"] = group.timestamp.min()\n",
    "    result[\"end_time\"] = group.timestamp.max()\n",
    "    result[\"duration\"] = result[\"end_time\"] - result[\"start_time\"]\n",
    "    result[\"correct_move\"] = group.correct_move.sum()\n",
    "    result[\"wrong_move\"] = group.wrong_move.sum()\n",
    "    result[\"title\"] = group.title.iloc[0]\n",
    "    result[\"installation_id\"] = group.installation_id.iloc[0]\n",
    "    result[\"game_session\"] = group.game_session.iloc[0]\n",
    "    return result\n",
    "\n",
    "\n",
    "def populate_correct_moves(history: pd.DataFrame) -> pd.DataFrame:\n",
    "    if \"correct\" in history.columns:\n",
    "        history[\"correct_move\"] = history.correct == True\n",
    "        history[\"wrong_move\"] = history.correct == False\n",
    "    else:\n",
    "        history[\"correct_move\"]=False\n",
    "        history[\"wrong_move\"]=False\n",
    "    return history\n",
    "\n",
    "    \n",
    "def make_base_time_features(assessment, history):\n",
    "    start_end_times = history\n",
    "    duration_minutes = start_end_times.duration / np.timedelta64(1, \"m\")\n",
    "    result = {\n",
    "        \"minutes_played\": round(duration_minutes.sum(), 0),\n",
    "        \"mean_session_time_minutes\": duration_minutes.mean(), \n",
    "    }\n",
    "    last_event_time = start_end_times.end_time.max()\n",
    "    first_event_time = start_end_times.start_time.min()\n",
    "    if assessment is not None:\n",
    "        result[\"minutes_since_last_game\"] = round((assessment.timestamp - last_event_time) / np.timedelta64(1, \"m\"), 0)\n",
    "    \n",
    "    days_active = round((last_event_time - first_event_time) / np.timedelta64(1, \"D\"), 0) + 1\n",
    "    result[\"games_per_day\"] = history.game_session.nunique() / days_active\n",
    "    \n",
    "    minutes_between_games = ((start_end_times.start_time - start_end_times.start_time.shift(1)).dropna() / np.timedelta64(1, \"m\")).round(0)\n",
    "    result[\"mean_minutes_between_games\"] = minutes_between_games.mean()\n",
    "    return result\n",
    "    \n",
    "    \n",
    "def apply_on_sessions(history, n_lags, get_features):\n",
    "    result = {}\n",
    "    empty = history.head(0)\n",
    "    if n_lags:\n",
    "        last_sessions = history.game_session.unique()[-n_lags:]\n",
    "        for i in range(n_lags):\n",
    "            if i < len(last_sessions):\n",
    "                lag_features = get_features(history[history.game_session==last_sessions[i]])\n",
    "            else:\n",
    "                lag_features = get_features(empty)\n",
    "            features = {}\n",
    "            for k, v in lag_features.items():\n",
    "                features[\"%s %d\" % (k, i)] = v\n",
    "            result.update(features)\n",
    "    return result\n",
    "\n",
    "\n",
    "def make_session_time_features(df):\n",
    "    return make_base_time_features(None, df)\n",
    "\n",
    "\n",
    "def make_game_time_features(df, title, n_lags=2):\n",
    "    result = apply_on_sessions(df, n_lags, make_session_time_features)\n",
    "    res = {}\n",
    "    for k, v in result.items():\n",
    "        res[title + \" \" + k] = v\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "def make_calendar_features(assessment, history):\n",
    "    ts = assessment.timestamp\n",
    "    year = ts.year\n",
    "    month = ts.month\n",
    "    dayofweek = ts.dayofweek\n",
    "    time = ts.time()\n",
    "    return {\n",
    "        \"year\": year,\n",
    "        \"month\": month,\n",
    "        \"dayofweek\": dayofweek,\n",
    "        \"hour\": time.hour,\n",
    "    }\n",
    "\n",
    "\n",
    "def make_base_features(assessment, history):\n",
    "    return  {\n",
    "        \"title\": games.index(assessment.title)\n",
    "    }\n",
    "\n",
    "base_stats = [populate_correct_moves]\n",
    "base_features = [make_base_features, make_calendar_features, make_base_time_features]\n",
    "game_features = [make_move_stats, make_game_time_features]\n",
    "\n",
    "def process_log(df):\n",
    "    assessment = df.iloc[-1]\n",
    "    history = df.iloc[:-1]\n",
    "    history = history[history.type.isin([\"Game\", \"Assessment\"])].copy()\n",
    "    \n",
    "    if len(history):\n",
    "        history = unwrap_event_data(history)\n",
    "    else:\n",
    "        return {}\n",
    "    history = json_normalize(history.groupby(\"game_session\").apply(shrink_session))\n",
    "    for f in base_stats:\n",
    "        history = f(history)\n",
    "    result = {}\n",
    "    for f in base_features:\n",
    "        result.update(f(assessment, history))\n",
    "    for game in games:\n",
    "        stats=history[history.title==game]\n",
    "        for f in game_features:\n",
    "            result.update(f(stats, game))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17690 [00:00<?, ?it/s]/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  1%|          | 111/17690 [00:29<1:11:35,  4.09it/s]"
     ]
    }
   ],
   "source": [
    "train_features= process_installations(train_labels, train, process_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.to_csv(DATA_DIR / \"interim/train_features_time_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features=train_features.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'n_correct Scrub-A-Dub', 'n_incorrect Scrub-A-Dub',\n",
       "       'global_ratio Scrub-A-Dub', 'n_correct Scrub-A-Dub 0',\n",
       "       'n_incorrect Scrub-A-Dub 0', 'ratio Scrub-A-Dub 0',\n",
       "       'n_correct Scrub-A-Dub 1', 'n_incorrect Scrub-A-Dub 1',\n",
       "       'ratio Scrub-A-Dub 1',\n",
       "       ...\n",
       "       'n_incorrect Leaf Leader', 'global_ratio Leaf Leader',\n",
       "       'n_correct Leaf Leader 0', 'n_incorrect Leaf Leader 0',\n",
       "       'ratio Leaf Leader 0', 'n_correct Leaf Leader 1',\n",
       "       'n_incorrect Leaf Leader 1', 'ratio Leaf Leader 1', 'installation_id',\n",
       "       'accuracy_group'],\n",
       "      dtype='object', length=147)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_quad_kappa(preds, true):\n",
    "    true = true.get_label()\n",
    "    preds = preds.reshape((4, -1)).argmax(axis=0)\n",
    "    return \"quad_kappa\", quad_kappa(true, preds), True\n",
    "    \n",
    "    \n",
    "def train_baseline(x_train,y_train, params=None):\n",
    "    x_train_all, x_val_all,y_train_all,y_val_all = train_test_split(\n",
    "        x_train,y_train,\n",
    "        test_size=0.15,\n",
    "        random_state=2019,\n",
    "    )\n",
    "    train_set = lgb.Dataset(x_train_all, y_train_all)\n",
    "    val_set = lgb.Dataset(x_val_all, y_val_all)\n",
    "\n",
    "    return lgb.train(params, train_set, num_boost_round=10000, early_stopping_rounds=2000, valid_sets=[train_set, val_set], verbose_eval=100,\n",
    "                    feval=lgb_quad_kappa)\n",
    "\n",
    "\n",
    "def make_features_wrapper(train, test):\n",
    "    def make_features(df):\n",
    "        return df.drop([\"installation_id\", \"accuracy_group\"], axis=1), df.accuracy_group.values\n",
    "    \n",
    "    return make_features(train), make_features(test) \n",
    "\n",
    "\n",
    "def make_predictions(model,x_test_all,y_test):\n",
    "    pred=model.predict(x_test_all).argmax(axis=1)\n",
    "    return pred,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.07328\tvalid_1's multi_logloss: 1.07759\n",
      "[200]\ttraining's multi_logloss: 1.01715\tvalid_1's multi_logloss: 1.03323\n",
      "[300]\ttraining's multi_logloss: 0.984614\tvalid_1's multi_logloss: 1.01267\n",
      "[400]\ttraining's multi_logloss: 0.96036\tvalid_1's multi_logloss: 1.00071\n",
      "[500]\ttraining's multi_logloss: 0.941326\tvalid_1's multi_logloss: 0.992596\n",
      "[600]\ttraining's multi_logloss: 0.925133\tvalid_1's multi_logloss: 0.987378\n",
      "[700]\ttraining's multi_logloss: 0.911415\tvalid_1's multi_logloss: 0.983922\n",
      "[800]\ttraining's multi_logloss: 0.898807\tvalid_1's multi_logloss: 0.981824\n",
      "[900]\ttraining's multi_logloss: 0.887318\tvalid_1's multi_logloss: 0.980442\n",
      "[1000]\ttraining's multi_logloss: 0.876624\tvalid_1's multi_logloss: 0.979759\n",
      "[1100]\ttraining's multi_logloss: 0.866517\tvalid_1's multi_logloss: 0.979412\n",
      "[1200]\ttraining's multi_logloss: 0.856904\tvalid_1's multi_logloss: 0.979122\n",
      "[1300]\ttraining's multi_logloss: 0.847715\tvalid_1's multi_logloss: 0.97909\n",
      "[1400]\ttraining's multi_logloss: 0.83887\tvalid_1's multi_logloss: 0.97901\n",
      "[1500]\ttraining's multi_logloss: 0.83025\tvalid_1's multi_logloss: 0.97896\n",
      "[1600]\ttraining's multi_logloss: 0.821988\tvalid_1's multi_logloss: 0.979189\n",
      "[1700]\ttraining's multi_logloss: 0.814059\tvalid_1's multi_logloss: 0.979535\n",
      "Early stopping, best iteration is:\n",
      "[1439]\ttraining's multi_logloss: 0.835437\tvalid_1's multi_logloss: 0.978891\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.06932\tvalid_1's multi_logloss: 1.10294\n",
      "[200]\ttraining's multi_logloss: 1.0113\tvalid_1's multi_logloss: 1.05476\n",
      "[300]\ttraining's multi_logloss: 0.978526\tvalid_1's multi_logloss: 1.03462\n",
      "[400]\ttraining's multi_logloss: 0.954979\tvalid_1's multi_logloss: 1.0227\n",
      "[500]\ttraining's multi_logloss: 0.935756\tvalid_1's multi_logloss: 1.01439\n",
      "[600]\ttraining's multi_logloss: 0.919501\tvalid_1's multi_logloss: 1.00875\n",
      "[700]\ttraining's multi_logloss: 0.905189\tvalid_1's multi_logloss: 1.00557\n",
      "[800]\ttraining's multi_logloss: 0.892816\tvalid_1's multi_logloss: 1.00394\n",
      "[900]\ttraining's multi_logloss: 0.881538\tvalid_1's multi_logloss: 1.00281\n",
      "[1000]\ttraining's multi_logloss: 0.871119\tvalid_1's multi_logloss: 1.00165\n",
      "[1100]\ttraining's multi_logloss: 0.860906\tvalid_1's multi_logloss: 1.00053\n",
      "[1200]\ttraining's multi_logloss: 0.851421\tvalid_1's multi_logloss: 0.999679\n",
      "[1300]\ttraining's multi_logloss: 0.8422\tvalid_1's multi_logloss: 0.999007\n",
      "[1400]\ttraining's multi_logloss: 0.833055\tvalid_1's multi_logloss: 0.997913\n",
      "[1500]\ttraining's multi_logloss: 0.824378\tvalid_1's multi_logloss: 0.99724\n",
      "[1600]\ttraining's multi_logloss: 0.816194\tvalid_1's multi_logloss: 0.997121\n",
      "[1700]\ttraining's multi_logloss: 0.808469\tvalid_1's multi_logloss: 0.997346\n",
      "[1800]\ttraining's multi_logloss: 0.800856\tvalid_1's multi_logloss: 0.997872\n",
      "[1900]\ttraining's multi_logloss: 0.793161\tvalid_1's multi_logloss: 0.998365\n",
      "Early stopping, best iteration is:\n",
      "[1652]\ttraining's multi_logloss: 0.812108\tvalid_1's multi_logloss: 0.997084\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.06902\tvalid_1's multi_logloss: 1.08315\n",
      "[200]\ttraining's multi_logloss: 1.01018\tvalid_1's multi_logloss: 1.03649\n",
      "[300]\ttraining's multi_logloss: 0.975932\tvalid_1's multi_logloss: 1.01508\n",
      "[400]\ttraining's multi_logloss: 0.951862\tvalid_1's multi_logloss: 1.00365\n",
      "[500]\ttraining's multi_logloss: 0.932292\tvalid_1's multi_logloss: 0.996146\n",
      "[600]\ttraining's multi_logloss: 0.915908\tvalid_1's multi_logloss: 0.991547\n",
      "[700]\ttraining's multi_logloss: 0.901665\tvalid_1's multi_logloss: 0.988317\n",
      "[800]\ttraining's multi_logloss: 0.889073\tvalid_1's multi_logloss: 0.986108\n",
      "[900]\ttraining's multi_logloss: 0.877555\tvalid_1's multi_logloss: 0.98464\n",
      "[1000]\ttraining's multi_logloss: 0.867342\tvalid_1's multi_logloss: 0.983376\n",
      "[1100]\ttraining's multi_logloss: 0.857589\tvalid_1's multi_logloss: 0.982404\n",
      "[1200]\ttraining's multi_logloss: 0.848022\tvalid_1's multi_logloss: 0.981397\n",
      "[1300]\ttraining's multi_logloss: 0.838842\tvalid_1's multi_logloss: 0.980229\n",
      "[1400]\ttraining's multi_logloss: 0.830185\tvalid_1's multi_logloss: 0.979169\n",
      "[1500]\ttraining's multi_logloss: 0.821768\tvalid_1's multi_logloss: 0.978632\n",
      "[1600]\ttraining's multi_logloss: 0.813807\tvalid_1's multi_logloss: 0.978095\n",
      "[1700]\ttraining's multi_logloss: 0.806102\tvalid_1's multi_logloss: 0.977874\n",
      "[1800]\ttraining's multi_logloss: 0.798736\tvalid_1's multi_logloss: 0.977729\n",
      "[1900]\ttraining's multi_logloss: 0.79147\tvalid_1's multi_logloss: 0.977815\n",
      "[2000]\ttraining's multi_logloss: 0.784346\tvalid_1's multi_logloss: 0.977674\n",
      "[2100]\ttraining's multi_logloss: 0.777469\tvalid_1's multi_logloss: 0.977891\n",
      "[2200]\ttraining's multi_logloss: 0.770788\tvalid_1's multi_logloss: 0.97828\n",
      "Early stopping, best iteration is:\n",
      "[1960]\ttraining's multi_logloss: 0.78713\tvalid_1's multi_logloss: 0.977528\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.07189\tvalid_1's multi_logloss: 1.08454\n",
      "[200]\ttraining's multi_logloss: 1.01417\tvalid_1's multi_logloss: 1.03954\n",
      "[300]\ttraining's multi_logloss: 0.981921\tvalid_1's multi_logloss: 1.01933\n",
      "[400]\ttraining's multi_logloss: 0.958461\tvalid_1's multi_logloss: 1.00686\n",
      "[500]\ttraining's multi_logloss: 0.939064\tvalid_1's multi_logloss: 0.998199\n",
      "[600]\ttraining's multi_logloss: 0.922703\tvalid_1's multi_logloss: 0.992505\n",
      "[700]\ttraining's multi_logloss: 0.908359\tvalid_1's multi_logloss: 0.988126\n",
      "[800]\ttraining's multi_logloss: 0.895838\tvalid_1's multi_logloss: 0.985542\n",
      "[900]\ttraining's multi_logloss: 0.88426\tvalid_1's multi_logloss: 0.983306\n",
      "[1000]\ttraining's multi_logloss: 0.873773\tvalid_1's multi_logloss: 0.981828\n",
      "[1100]\ttraining's multi_logloss: 0.863606\tvalid_1's multi_logloss: 0.980869\n",
      "[1200]\ttraining's multi_logloss: 0.853977\tvalid_1's multi_logloss: 0.979937\n",
      "[1300]\ttraining's multi_logloss: 0.844927\tvalid_1's multi_logloss: 0.97936\n",
      "[1400]\ttraining's multi_logloss: 0.836485\tvalid_1's multi_logloss: 0.978803\n",
      "[1500]\ttraining's multi_logloss: 0.828105\tvalid_1's multi_logloss: 0.978386\n",
      "[1600]\ttraining's multi_logloss: 0.820056\tvalid_1's multi_logloss: 0.978296\n",
      "[1700]\ttraining's multi_logloss: 0.812274\tvalid_1's multi_logloss: 0.977961\n",
      "[1800]\ttraining's multi_logloss: 0.804795\tvalid_1's multi_logloss: 0.977975\n",
      "[1900]\ttraining's multi_logloss: 0.797549\tvalid_1's multi_logloss: 0.977897\n",
      "[2000]\ttraining's multi_logloss: 0.79037\tvalid_1's multi_logloss: 0.978083\n",
      "[2100]\ttraining's multi_logloss: 0.78333\tvalid_1's multi_logloss: 0.978019\n",
      "Early stopping, best iteration is:\n",
      "[1834]\ttraining's multi_logloss: 0.802252\tvalid_1's multi_logloss: 0.977884\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.07148\tvalid_1's multi_logloss: 1.09532\n",
      "[200]\ttraining's multi_logloss: 1.01253\tvalid_1's multi_logloss: 1.05309\n",
      "[300]\ttraining's multi_logloss: 0.979038\tvalid_1's multi_logloss: 1.03416\n",
      "[400]\ttraining's multi_logloss: 0.954742\tvalid_1's multi_logloss: 1.02279\n",
      "[500]\ttraining's multi_logloss: 0.935545\tvalid_1's multi_logloss: 1.0159\n",
      "[600]\ttraining's multi_logloss: 0.919342\tvalid_1's multi_logloss: 1.01128\n",
      "[700]\ttraining's multi_logloss: 0.905407\tvalid_1's multi_logloss: 1.00776\n",
      "[800]\ttraining's multi_logloss: 0.892945\tvalid_1's multi_logloss: 1.00521\n",
      "[900]\ttraining's multi_logloss: 0.881479\tvalid_1's multi_logloss: 1.00338\n",
      "[1000]\ttraining's multi_logloss: 0.870758\tvalid_1's multi_logloss: 1.00228\n",
      "[1100]\ttraining's multi_logloss: 0.860679\tvalid_1's multi_logloss: 1.00167\n",
      "[1200]\ttraining's multi_logloss: 0.85105\tvalid_1's multi_logloss: 1.00118\n",
      "[1300]\ttraining's multi_logloss: 0.841713\tvalid_1's multi_logloss: 1.00014\n",
      "[1400]\ttraining's multi_logloss: 0.832825\tvalid_1's multi_logloss: 0.999194\n",
      "[1500]\ttraining's multi_logloss: 0.824154\tvalid_1's multi_logloss: 0.998787\n",
      "[1600]\ttraining's multi_logloss: 0.81584\tvalid_1's multi_logloss: 0.998578\n",
      "[1700]\ttraining's multi_logloss: 0.807869\tvalid_1's multi_logloss: 0.99824\n",
      "[1800]\ttraining's multi_logloss: 0.800205\tvalid_1's multi_logloss: 0.998604\n",
      "[1900]\ttraining's multi_logloss: 0.792763\tvalid_1's multi_logloss: 0.999088\n",
      "Early stopping, best iteration is:\n",
      "[1690]\ttraining's multi_logloss: 0.808661\tvalid_1's multi_logloss: 0.998187\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.07167\tvalid_1's multi_logloss: 1.09987\n",
      "[200]\ttraining's multi_logloss: 1.01368\tvalid_1's multi_logloss: 1.05525\n",
      "[300]\ttraining's multi_logloss: 0.980709\tvalid_1's multi_logloss: 1.03626\n",
      "[400]\ttraining's multi_logloss: 0.956592\tvalid_1's multi_logloss: 1.02599\n",
      "[500]\ttraining's multi_logloss: 0.937374\tvalid_1's multi_logloss: 1.01954\n",
      "[600]\ttraining's multi_logloss: 0.921329\tvalid_1's multi_logloss: 1.01546\n",
      "[700]\ttraining's multi_logloss: 0.907272\tvalid_1's multi_logloss: 1.01267\n",
      "[800]\ttraining's multi_logloss: 0.894821\tvalid_1's multi_logloss: 1.01114\n",
      "[900]\ttraining's multi_logloss: 0.883537\tvalid_1's multi_logloss: 1.01046\n",
      "[1000]\ttraining's multi_logloss: 0.873103\tvalid_1's multi_logloss: 1.01017\n",
      "[1100]\ttraining's multi_logloss: 0.863341\tvalid_1's multi_logloss: 1.00994\n",
      "[1200]\ttraining's multi_logloss: 0.85376\tvalid_1's multi_logloss: 1.00983\n",
      "[1300]\ttraining's multi_logloss: 0.844605\tvalid_1's multi_logloss: 1.00969\n",
      "[1400]\ttraining's multi_logloss: 0.835811\tvalid_1's multi_logloss: 1.00956\n",
      "[1500]\ttraining's multi_logloss: 0.827399\tvalid_1's multi_logloss: 1.00952\n",
      "[1600]\ttraining's multi_logloss: 0.819073\tvalid_1's multi_logloss: 1.00962\n",
      "[1700]\ttraining's multi_logloss: 0.811029\tvalid_1's multi_logloss: 1.00998\n",
      "[1800]\ttraining's multi_logloss: 0.803418\tvalid_1's multi_logloss: 1.01017\n",
      "Early stopping, best iteration is:\n",
      "[1508]\ttraining's multi_logloss: 0.826742\tvalid_1's multi_logloss: 1.00946\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.07489\tvalid_1's multi_logloss: 1.09055\n",
      "[200]\ttraining's multi_logloss: 1.01702\tvalid_1's multi_logloss: 1.04641\n",
      "[300]\ttraining's multi_logloss: 0.983885\tvalid_1's multi_logloss: 1.02606\n",
      "[400]\ttraining's multi_logloss: 0.959481\tvalid_1's multi_logloss: 1.01397\n",
      "[500]\ttraining's multi_logloss: 0.940005\tvalid_1's multi_logloss: 1.00566\n",
      "[600]\ttraining's multi_logloss: 0.923888\tvalid_1's multi_logloss: 1.0004\n",
      "[700]\ttraining's multi_logloss: 0.909921\tvalid_1's multi_logloss: 0.997009\n",
      "[800]\ttraining's multi_logloss: 0.897336\tvalid_1's multi_logloss: 0.994774\n",
      "[900]\ttraining's multi_logloss: 0.885911\tvalid_1's multi_logloss: 0.993468\n",
      "[1000]\ttraining's multi_logloss: 0.875305\tvalid_1's multi_logloss: 0.992662\n",
      "[1100]\ttraining's multi_logloss: 0.865495\tvalid_1's multi_logloss: 0.992024\n",
      "[1200]\ttraining's multi_logloss: 0.85582\tvalid_1's multi_logloss: 0.991241\n",
      "[1300]\ttraining's multi_logloss: 0.846656\tvalid_1's multi_logloss: 0.990909\n",
      "[1400]\ttraining's multi_logloss: 0.837724\tvalid_1's multi_logloss: 0.99043\n",
      "[1500]\ttraining's multi_logloss: 0.829302\tvalid_1's multi_logloss: 0.990287\n",
      "[1600]\ttraining's multi_logloss: 0.821148\tvalid_1's multi_logloss: 0.99039\n",
      "[1700]\ttraining's multi_logloss: 0.81342\tvalid_1's multi_logloss: 0.990518\n",
      "Early stopping, best iteration is:\n",
      "[1479]\ttraining's multi_logloss: 0.831048\tvalid_1's multi_logloss: 0.990196\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.0713\tvalid_1's multi_logloss: 1.07711\n",
      "[200]\ttraining's multi_logloss: 1.01257\tvalid_1's multi_logloss: 1.03606\n",
      "[300]\ttraining's multi_logloss: 0.979202\tvalid_1's multi_logloss: 1.01866\n",
      "[400]\ttraining's multi_logloss: 0.954781\tvalid_1's multi_logloss: 1.00789\n",
      "[500]\ttraining's multi_logloss: 0.935305\tvalid_1's multi_logloss: 1.00124\n",
      "[600]\ttraining's multi_logloss: 0.919358\tvalid_1's multi_logloss: 0.997258\n",
      "[700]\ttraining's multi_logloss: 0.905522\tvalid_1's multi_logloss: 0.99496\n",
      "[800]\ttraining's multi_logloss: 0.893242\tvalid_1's multi_logloss: 0.99322\n",
      "[900]\ttraining's multi_logloss: 0.882145\tvalid_1's multi_logloss: 0.992318\n",
      "[1000]\ttraining's multi_logloss: 0.871805\tvalid_1's multi_logloss: 0.991657\n",
      "[1100]\ttraining's multi_logloss: 0.86186\tvalid_1's multi_logloss: 0.991477\n",
      "[1200]\ttraining's multi_logloss: 0.85249\tvalid_1's multi_logloss: 0.991536\n",
      "[1300]\ttraining's multi_logloss: 0.84351\tvalid_1's multi_logloss: 0.991602\n",
      "[1400]\ttraining's multi_logloss: 0.834989\tvalid_1's multi_logloss: 0.991804\n",
      "Early stopping, best iteration is:\n",
      "[1126]\ttraining's multi_logloss: 0.859334\tvalid_1's multi_logloss: 0.991351\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.08004\tvalid_1's multi_logloss: 1.07027\n",
      "[200]\ttraining's multi_logloss: 1.02218\tvalid_1's multi_logloss: 1.02336\n",
      "[300]\ttraining's multi_logloss: 0.98935\tvalid_1's multi_logloss: 1.00247\n",
      "[400]\ttraining's multi_logloss: 0.965559\tvalid_1's multi_logloss: 0.99198\n",
      "[500]\ttraining's multi_logloss: 0.946249\tvalid_1's multi_logloss: 0.983708\n",
      "[600]\ttraining's multi_logloss: 0.9299\tvalid_1's multi_logloss: 0.978399\n",
      "[700]\ttraining's multi_logloss: 0.915961\tvalid_1's multi_logloss: 0.975015\n",
      "[800]\ttraining's multi_logloss: 0.903566\tvalid_1's multi_logloss: 0.972849\n",
      "[900]\ttraining's multi_logloss: 0.892015\tvalid_1's multi_logloss: 0.971226\n",
      "[1000]\ttraining's multi_logloss: 0.881085\tvalid_1's multi_logloss: 0.96959\n",
      "[1100]\ttraining's multi_logloss: 0.870903\tvalid_1's multi_logloss: 0.968767\n",
      "[1200]\ttraining's multi_logloss: 0.861222\tvalid_1's multi_logloss: 0.967879\n",
      "[1300]\ttraining's multi_logloss: 0.852093\tvalid_1's multi_logloss: 0.96739\n",
      "[1400]\ttraining's multi_logloss: 0.843339\tvalid_1's multi_logloss: 0.967011\n",
      "[1500]\ttraining's multi_logloss: 0.834934\tvalid_1's multi_logloss: 0.966985\n",
      "[1600]\ttraining's multi_logloss: 0.826937\tvalid_1's multi_logloss: 0.96684\n",
      "[1700]\ttraining's multi_logloss: 0.819002\tvalid_1's multi_logloss: 0.967043\n",
      "[1800]\ttraining's multi_logloss: 0.811479\tvalid_1's multi_logloss: 0.967442\n",
      "[1900]\ttraining's multi_logloss: 0.804229\tvalid_1's multi_logloss: 0.967871\n",
      "Early stopping, best iteration is:\n",
      "[1611]\ttraining's multi_logloss: 0.826031\tvalid_1's multi_logloss: 0.966781\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.07221\tvalid_1's multi_logloss: 1.08889\n",
      "[200]\ttraining's multi_logloss: 1.01378\tvalid_1's multi_logloss: 1.04399\n",
      "[300]\ttraining's multi_logloss: 0.980207\tvalid_1's multi_logloss: 1.02546\n",
      "[400]\ttraining's multi_logloss: 0.955771\tvalid_1's multi_logloss: 1.01482\n",
      "[500]\ttraining's multi_logloss: 0.9364\tvalid_1's multi_logloss: 1.00709\n",
      "[600]\ttraining's multi_logloss: 0.920112\tvalid_1's multi_logloss: 1.00215\n",
      "[700]\ttraining's multi_logloss: 0.90599\tvalid_1's multi_logloss: 0.999285\n",
      "[800]\ttraining's multi_logloss: 0.893351\tvalid_1's multi_logloss: 0.997108\n",
      "[900]\ttraining's multi_logloss: 0.881906\tvalid_1's multi_logloss: 0.996074\n",
      "[1000]\ttraining's multi_logloss: 0.871288\tvalid_1's multi_logloss: 0.995467\n",
      "[1100]\ttraining's multi_logloss: 0.861309\tvalid_1's multi_logloss: 0.995003\n",
      "[1200]\ttraining's multi_logloss: 0.851779\tvalid_1's multi_logloss: 0.994686\n",
      "[1300]\ttraining's multi_logloss: 0.84281\tvalid_1's multi_logloss: 0.994298\n",
      "[1400]\ttraining's multi_logloss: 0.834013\tvalid_1's multi_logloss: 0.994308\n",
      "[1500]\ttraining's multi_logloss: 0.825492\tvalid_1's multi_logloss: 0.994343\n",
      "[1600]\ttraining's multi_logloss: 0.817328\tvalid_1's multi_logloss: 0.995141\n",
      "Early stopping, best iteration is:\n",
      "[1352]\ttraining's multi_logloss: 0.838261\tvalid_1's multi_logloss: 0.994202\n"
     ]
    }
   ],
   "source": [
    "predictions = cross_validate(train_features, train_features.accuracy_group, make_features_wrapper, train_baseline, make_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5157051296362365,\n",
       " [0.5472283470243167,\n",
       "  0.4797202169826231,\n",
       "  0.47854404188486,\n",
       "  0.5041272227182371,\n",
       "  0.5055032393246791,\n",
       "  0.5232401248520073,\n",
       "  0.5510630168932551,\n",
       "  0.5215215852330887,\n",
       "  0.5147618813899562,\n",
       "  0.531341620059342])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([quad_kappa(true, pred) for pred, true in predictions]), [quad_kappa(true, pred) for pred, true in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<02:06,  7.91it/s]/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:41: RuntimeWarning: invalid value encountered in long_scalars\n",
      "100%|██████████| 1000/1000 [01:29<00:00, 11.22it/s]\n"
     ]
    }
   ],
   "source": [
    "def process_test_installations(test):\n",
    "    test = test.sort_values(\"timestamp\")\n",
    "    test=test.groupby(\"installation_id\").progress_apply(process_log).reset_index()\n",
    "    test.columns = [\"installation_id\", \"features\"]\n",
    "    result = []\n",
    "    for i, installation_id, feature in test.itertuples():\n",
    "        result.append(feature)\n",
    "        feature[\"installation_id\"]=installation_id\n",
    "    return pd.DataFrame(result).fillna(-1)\n",
    "test_features=process_test_installations(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>n_correct Scrub-A-Dub</th>\n",
       "      <th>n_incorrect Scrub-A-Dub</th>\n",
       "      <th>global_ratio Scrub-A-Dub</th>\n",
       "      <th>n_correct Scrub-A-Dub 0</th>\n",
       "      <th>n_incorrect Scrub-A-Dub 0</th>\n",
       "      <th>ratio Scrub-A-Dub 0</th>\n",
       "      <th>n_correct Scrub-A-Dub 1</th>\n",
       "      <th>n_incorrect Scrub-A-Dub 1</th>\n",
       "      <th>ratio Scrub-A-Dub 1</th>\n",
       "      <th>...</th>\n",
       "      <th>n_correct Leaf Leader</th>\n",
       "      <th>n_incorrect Leaf Leader</th>\n",
       "      <th>global_ratio Leaf Leader</th>\n",
       "      <th>n_correct Leaf Leader 0</th>\n",
       "      <th>n_incorrect Leaf Leader 0</th>\n",
       "      <th>ratio Leaf Leader 0</th>\n",
       "      <th>n_correct Leaf Leader 1</th>\n",
       "      <th>n_incorrect Leaf Leader 1</th>\n",
       "      <th>ratio Leaf Leader 1</th>\n",
       "      <th>installation_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>00abaee7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>01242218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>017c5718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>01a44906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>01bc6cb6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>fee254cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ff57e602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ffc73fb2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ffe00ca8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ffe774cc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     title  n_correct Scrub-A-Dub  n_incorrect Scrub-A-Dub  \\\n",
       "0       10                      0                        0   \n",
       "1       13                     15                        0   \n",
       "2        2                      0                        0   \n",
       "3        2                      0                        0   \n",
       "4       13                      0                        0   \n",
       "..     ...                    ...                      ...   \n",
       "995     10                      0                        0   \n",
       "996     14                      0                        0   \n",
       "997     13                      0                        0   \n",
       "998     13                      0                        0   \n",
       "999      5                      0                        0   \n",
       "\n",
       "     global_ratio Scrub-A-Dub  n_correct Scrub-A-Dub 0  \\\n",
       "0                        -1.0                     -1.0   \n",
       "1                         1.0                     15.0   \n",
       "2                        -1.0                     -1.0   \n",
       "3                        -1.0                     -1.0   \n",
       "4                        -1.0                     -1.0   \n",
       "..                        ...                      ...   \n",
       "995                      -1.0                     -1.0   \n",
       "996                      -1.0                     -1.0   \n",
       "997                      -1.0                     -1.0   \n",
       "998                      -1.0                     -1.0   \n",
       "999                      -1.0                     -1.0   \n",
       "\n",
       "     n_incorrect Scrub-A-Dub 0  ratio Scrub-A-Dub 0  n_correct Scrub-A-Dub 1  \\\n",
       "0                         -1.0                 -1.0                     -1.0   \n",
       "1                          0.0                  1.0                     -1.0   \n",
       "2                         -1.0                 -1.0                     -1.0   \n",
       "3                         -1.0                 -1.0                     -1.0   \n",
       "4                         -1.0                 -1.0                     -1.0   \n",
       "..                         ...                  ...                      ...   \n",
       "995                       -1.0                 -1.0                     -1.0   \n",
       "996                       -1.0                 -1.0                     -1.0   \n",
       "997                       -1.0                 -1.0                     -1.0   \n",
       "998                       -1.0                 -1.0                     -1.0   \n",
       "999                       -1.0                 -1.0                     -1.0   \n",
       "\n",
       "     n_incorrect Scrub-A-Dub 1  ratio Scrub-A-Dub 1  ...  \\\n",
       "0                         -1.0                 -1.0  ...   \n",
       "1                         -1.0                 -1.0  ...   \n",
       "2                         -1.0                 -1.0  ...   \n",
       "3                         -1.0                 -1.0  ...   \n",
       "4                         -1.0                 -1.0  ...   \n",
       "..                         ...                  ...  ...   \n",
       "995                       -1.0                 -1.0  ...   \n",
       "996                       -1.0                 -1.0  ...   \n",
       "997                       -1.0                 -1.0  ...   \n",
       "998                       -1.0                 -1.0  ...   \n",
       "999                       -1.0                 -1.0  ...   \n",
       "\n",
       "     n_correct Leaf Leader  n_incorrect Leaf Leader  global_ratio Leaf Leader  \\\n",
       "0                        0                        0                 -1.000000   \n",
       "1                       11                        0                  1.000000   \n",
       "2                        0                        0                 -1.000000   \n",
       "3                        0                        0                 -1.000000   \n",
       "4                        0                        0                 -1.000000   \n",
       "..                     ...                      ...                       ...   \n",
       "995                      0                        0                 -1.000000   \n",
       "996                     16                        7                  0.695652   \n",
       "997                      0                        0                 -1.000000   \n",
       "998                      0                        0                 -1.000000   \n",
       "999                      0                        0                 -1.000000   \n",
       "\n",
       "     n_correct Leaf Leader 0  n_incorrect Leaf Leader 0  ratio Leaf Leader 0  \\\n",
       "0                       -1.0                       -1.0            -1.000000   \n",
       "1                       11.0                        0.0             1.000000   \n",
       "2                       -1.0                       -1.0            -1.000000   \n",
       "3                       -1.0                       -1.0            -1.000000   \n",
       "4                       -1.0                       -1.0            -1.000000   \n",
       "..                       ...                        ...                  ...   \n",
       "995                     -1.0                       -1.0            -1.000000   \n",
       "996                     16.0                        7.0             0.695652   \n",
       "997                     -1.0                       -1.0            -1.000000   \n",
       "998                     -1.0                       -1.0            -1.000000   \n",
       "999                     -1.0                       -1.0            -1.000000   \n",
       "\n",
       "     n_correct Leaf Leader 1  n_incorrect Leaf Leader 1  ratio Leaf Leader 1  \\\n",
       "0                       -1.0                       -1.0                 -1.0   \n",
       "1                       -1.0                       -1.0                 -1.0   \n",
       "2                       -1.0                       -1.0                 -1.0   \n",
       "3                       -1.0                       -1.0                 -1.0   \n",
       "4                       -1.0                       -1.0                 -1.0   \n",
       "..                       ...                        ...                  ...   \n",
       "995                     -1.0                       -1.0                 -1.0   \n",
       "996                     -1.0                       -1.0                 -1.0   \n",
       "997                     -1.0                       -1.0                 -1.0   \n",
       "998                     -1.0                       -1.0                 -1.0   \n",
       "999                     -1.0                       -1.0                 -1.0   \n",
       "\n",
       "     installation_id  \n",
       "0           00abaee7  \n",
       "1           01242218  \n",
       "2           017c5718  \n",
       "3           01a44906  \n",
       "4           01bc6cb6  \n",
       "..               ...  \n",
       "995         fee254cf  \n",
       "996         ff57e602  \n",
       "997         ffc73fb2  \n",
       "998         ffe00ca8  \n",
       "999         ffe774cc  \n",
       "\n",
       "[1000 rows x 146 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtrain_installations=pd.Series(train_features.installation_id.unique()).sample(frac=1., random_state=2019)\n",
    "subtrain_features=train_features[train_features.installation_id.isin(subtrain_installations.values)].copy()\n",
    "def check_hyperparams(params):\n",
    "    print(params)\n",
    "    if \"max_depth\" in params:\n",
    "        params[\"max_depth\"] = int(params[\"max_depth\"])\n",
    "    if \"num_leaves\" in params:\n",
    "        params[\"num_leaves\"] = int(params[\"num_leaves\"])\n",
    "\n",
    "    train_baseline_with_params = partial(train_baseline, params=params)\n",
    "    cv=InstallationFold(n_splits=3)\n",
    "    predictions = cross_validate(subtrain_features, subtrain_features.accuracy_group, make_features_wrapper, train_baseline_with_params, make_predictions,\n",
    "                                cv=cv)\n",
    "    return {\n",
    "        \"loss\": -np.mean([quad_kappa(true, pred) for pred, true in predictions]),\n",
    "        \"status\": STATUS_OK,\n",
    "        \"params\": params\n",
    "    }\n",
    "\n",
    "\n",
    "def tune(check_params, n_tries=25, n_learning_rate_tries=15, learning_rate=None, n_estimators=10_000):        \n",
    "    if learning_rate is None:\n",
    "        learning_rate_space = {\n",
    "            'learning_rate': hp.loguniform(\"learning_rate\", np.log(0.005), np.log(0.3)),\n",
    "            'metric': 'multiclass',\n",
    "            'objective': 'multiclass',\n",
    "            'num_classes': 4,\n",
    "            'random_state': 2019,\n",
    "            \"n_estimators\": n_estimators,\n",
    "\n",
    "        }\n",
    "        trials = Trials()\n",
    "        result = fmin(check_params,\n",
    "                      learning_rate_space, tpe.suggest, n_learning_rate_tries, trials=trials)\n",
    "        print(result)\n",
    "        learning_rate = round(trials.best_trial[\"result\"][\"params\"][\"learning_rate\"], 3)\n",
    "\n",
    "    param_space = {\n",
    "        'metric': 'multiclass',\n",
    "        'objective': 'multiclass',\n",
    "        'num_classes': 4,\n",
    "        'lambda_l1': hp.uniform(\"lamba_l1\", 1e-10, 1),\n",
    "        'lambda_l2': hp.uniform(\"lambda_l2\", 1e-10, 1),\n",
    "        'random_state': 2019,\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"max_depth\": hp.quniform(\"max_depth\", 2, 16, 1),\n",
    "        \"num_leaves\": hp.choice(\"num_leaves\", [3, 7, 15, 31, 63, 127, 255, 511, 1023, 2047, 4095]),\n",
    "        \"subsample\": hp.quniform(\"subsample\", 0.01, 1, 0.01),\n",
    "        \"feature_fraction\": hp.quniform(\"feature_fraction\", 0.01, 1, 0.01),\n",
    "    }\n",
    "\n",
    "    trials = Trials()\n",
    "    fmin(check_params,\n",
    "         param_space, tpe.suggest, n_tries, trials=trials)\n",
    "    best_params = trials.best_trial[\"result\"][\"params\"]\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.11570871281185176, 'metric': 'multiclass', 'n_estimators': 10000, 'num_classes': 4, 'objective': 'multiclass', 'random_state': 2019}\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 0.661067\ttraining's quad_kappa: 0.707905\tvalid_1's multi_logloss: 1.01324\tvalid_1's quad_kappa: 0.506578\n",
      "[200]\ttraining's multi_logloss: 0.502574\ttraining's quad_kappa: 0.798993\tvalid_1's multi_logloss: 1.04839\tvalid_1's quad_kappa: 0.516114\n",
      "[300]\ttraining's multi_logloss: 0.399462\ttraining's quad_kappa: 0.851942\tvalid_1's multi_logloss: 1.10065\tvalid_1's quad_kappa: 0.508758\n",
      "[400]\ttraining's multi_logloss: 0.3256\ttraining's quad_kappa: 0.88062\tvalid_1's multi_logloss: 1.15282\tvalid_1's quad_kappa: 0.498978\n",
      "[500]\ttraining's multi_logloss: 0.270233\ttraining's quad_kappa: 0.90667\tvalid_1's multi_logloss: 1.19725\tvalid_1's quad_kappa: 0.497703\n",
      "[600]\ttraining's multi_logloss: 0.22533\ttraining's quad_kappa: 0.924775\tvalid_1's multi_logloss: 1.24463\tvalid_1's quad_kappa: 0.485013\n",
      "[700]\ttraining's multi_logloss: 0.189667\ttraining's quad_kappa: 0.938541\tvalid_1's multi_logloss: 1.29599\tvalid_1's quad_kappa: 0.478301\n",
      "[800]\ttraining's multi_logloss: 0.158597\ttraining's quad_kappa: 0.951071\tvalid_1's multi_logloss: 1.34688\tvalid_1's quad_kappa: 0.475463\n",
      "[900]\ttraining's multi_logloss: 0.134206\ttraining's quad_kappa: 0.960067\tvalid_1's multi_logloss: 1.38997\tvalid_1's quad_kappa: 0.477448\n",
      "[1000]\ttraining's multi_logloss: 0.112856\ttraining's quad_kappa: 0.967804\tvalid_1's multi_logloss: 1.43728\tvalid_1's quad_kappa: 0.479562\n",
      "[1100]\ttraining's multi_logloss: 0.0952385\ttraining's quad_kappa: 0.974691\tvalid_1's multi_logloss: 1.48266\tvalid_1's quad_kappa: 0.470509\n",
      "[1200]\ttraining's multi_logloss: 0.0802569\ttraining's quad_kappa: 0.978583\tvalid_1's multi_logloss: 1.5332\tvalid_1's quad_kappa: 0.469686\n",
      "[1300]\ttraining's multi_logloss: 0.0686922\ttraining's quad_kappa: 0.981254\tvalid_1's multi_logloss: 1.58705\tvalid_1's quad_kappa: 0.466302\n",
      "[1400]\ttraining's multi_logloss: 0.058895\ttraining's quad_kappa: 0.984061\tvalid_1's multi_logloss: 1.63733\tvalid_1's quad_kappa: 0.465037\n",
      "[1500]\ttraining's multi_logloss: 0.0504434\ttraining's quad_kappa: 0.986965\tvalid_1's multi_logloss: 1.69215\tvalid_1's quad_kappa: 0.464185\n",
      "[1600]\ttraining's multi_logloss: 0.0437024\ttraining's quad_kappa: 0.988693\tvalid_1's multi_logloss: 1.74323\tvalid_1's quad_kappa: 0.466468\n",
      "[1700]\ttraining's multi_logloss: 0.0379749\ttraining's quad_kappa: 0.990164\tvalid_1's multi_logloss: 1.79179\tvalid_1's quad_kappa: 0.464747\n",
      "[1800]\ttraining's multi_logloss: 0.0328083\ttraining's quad_kappa: 0.990865\tvalid_1's multi_logloss: 1.84393\tvalid_1's quad_kappa: 0.458558\n",
      "[1900]\ttraining's multi_logloss: 0.0283036\ttraining's quad_kappa: 0.991954\tvalid_1's multi_logloss: 1.89239\tvalid_1's quad_kappa: 0.458681\n",
      "[2000]\ttraining's multi_logloss: 0.0248273\ttraining's quad_kappa: 0.992848\tvalid_1's multi_logloss: 1.93878\tvalid_1's quad_kappa: 0.459931\n",
      "Early stopping, best iteration is:                  \n",
      "[49]\ttraining's multi_logloss: 0.79001\ttraining's quad_kappa: 0.631853\tvalid_1's multi_logloss: 1.00015\tvalid_1's quad_kappa: 0.486069\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[100]\ttraining's multi_logloss: 0.640892\ttraining's quad_kappa: 0.722907\tvalid_1's multi_logloss: 0.998858\tvalid_1's quad_kappa: 0.522918\n",
      "[200]\ttraining's multi_logloss: 0.486526\ttraining's quad_kappa: 0.807762\tvalid_1's multi_logloss: 1.03369\tvalid_1's quad_kappa: 0.518039\n",
      "[300]\ttraining's multi_logloss: 0.382934\ttraining's quad_kappa: 0.863803\tvalid_1's multi_logloss: 1.08145\tvalid_1's quad_kappa: 0.529859\n",
      "[400]\ttraining's multi_logloss: 0.307738\ttraining's quad_kappa: 0.893742\tvalid_1's multi_logloss: 1.12686\tvalid_1's quad_kappa: 0.521682\n",
      "[500]\ttraining's multi_logloss: 0.253194\ttraining's quad_kappa: 0.914162\tvalid_1's multi_logloss: 1.1739\tvalid_1's quad_kappa: 0.511494\n",
      "[600]\ttraining's multi_logloss: 0.210783\ttraining's quad_kappa: 0.930834\tvalid_1's multi_logloss: 1.22032\tvalid_1's quad_kappa: 0.513685\n",
      "[700]\ttraining's multi_logloss: 0.175188\ttraining's quad_kappa: 0.94458\tvalid_1's multi_logloss: 1.26181\tvalid_1's quad_kappa: 0.515169\n",
      "[800]\ttraining's multi_logloss: 0.147502\ttraining's quad_kappa: 0.95419\tvalid_1's multi_logloss: 1.31175\tvalid_1's quad_kappa: 0.505441\n",
      "[900]\ttraining's multi_logloss: 0.123517\ttraining's quad_kappa: 0.960823\tvalid_1's multi_logloss: 1.3537\tvalid_1's quad_kappa: 0.509067\n",
      "[1000]\ttraining's multi_logloss: 0.104213\ttraining's quad_kappa: 0.967463\tvalid_1's multi_logloss: 1.40031\tvalid_1's quad_kappa: 0.505625\n",
      "[1100]\ttraining's multi_logloss: 0.0881007\ttraining's quad_kappa: 0.970821\tvalid_1's multi_logloss: 1.44928\tvalid_1's quad_kappa: 0.512235\n",
      "[1200]\ttraining's multi_logloss: 0.0752879\ttraining's quad_kappa: 0.975735\tvalid_1's multi_logloss: 1.4973\tvalid_1's quad_kappa: 0.510107\n",
      "[1300]\ttraining's multi_logloss: 0.0639349\ttraining's quad_kappa: 0.980729\tvalid_1's multi_logloss: 1.54491\tvalid_1's quad_kappa: 0.503509\n",
      "[1400]\ttraining's multi_logloss: 0.0546285\ttraining's quad_kappa: 0.98459\tvalid_1's multi_logloss: 1.5907\tvalid_1's quad_kappa: 0.50273\n",
      "[1500]\ttraining's multi_logloss: 0.0470203\ttraining's quad_kappa: 0.986791\tvalid_1's multi_logloss: 1.64028\tvalid_1's quad_kappa: 0.50261\n",
      "[1600]\ttraining's multi_logloss: 0.0408577\ttraining's quad_kappa: 0.988608\tvalid_1's multi_logloss: 1.68495\tvalid_1's quad_kappa: 0.501279\n",
      "[1700]\ttraining's multi_logloss: 0.0353292\ttraining's quad_kappa: 0.989017\tvalid_1's multi_logloss: 1.733\tvalid_1's quad_kappa: 0.505384\n",
      "[1800]\ttraining's multi_logloss: 0.0305953\ttraining's quad_kappa: 0.99037\tvalid_1's multi_logloss: 1.78284\tvalid_1's quad_kappa: 0.499737\n",
      "[1900]\ttraining's multi_logloss: 0.0267482\ttraining's quad_kappa: 0.990371\tvalid_1's multi_logloss: 1.83212\tvalid_1's quad_kappa: 0.494307\n",
      "[2000]\ttraining's multi_logloss: 0.0236412\ttraining's quad_kappa: 0.990433\tvalid_1's multi_logloss: 1.88259\tvalid_1's quad_kappa: 0.500132\n",
      "Early stopping, best iteration is:                  \n",
      "[52]\ttraining's multi_logloss: 0.760391\ttraining's quad_kappa: 0.659222\tvalid_1's multi_logloss: 0.993304\tvalid_1's quad_kappa: 0.517381\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[100]\ttraining's multi_logloss: 0.657763\ttraining's quad_kappa: 0.716956\tvalid_1's multi_logloss: 1.00752\tvalid_1's quad_kappa: 0.538299\n",
      "[200]\ttraining's multi_logloss: 0.503191\ttraining's quad_kappa: 0.799627\tvalid_1's multi_logloss: 1.04783\tvalid_1's quad_kappa: 0.539417\n",
      "[300]\ttraining's multi_logloss: 0.400318\ttraining's quad_kappa: 0.855256\tvalid_1's multi_logloss: 1.09308\tvalid_1's quad_kappa: 0.531267\n",
      "[400]\ttraining's multi_logloss: 0.326096\ttraining's quad_kappa: 0.884193\tvalid_1's multi_logloss: 1.13882\tvalid_1's quad_kappa: 0.536052\n",
      "[500]\ttraining's multi_logloss: 0.269245\ttraining's quad_kappa: 0.903625\tvalid_1's multi_logloss: 1.18839\tvalid_1's quad_kappa: 0.527388\n",
      "[600]\ttraining's multi_logloss: 0.221972\ttraining's quad_kappa: 0.924832\tvalid_1's multi_logloss: 1.23535\tvalid_1's quad_kappa: 0.522382\n",
      "[700]\ttraining's multi_logloss: 0.18611\ttraining's quad_kappa: 0.941325\tvalid_1's multi_logloss: 1.28236\tvalid_1's quad_kappa: 0.528894\n",
      "[800]\ttraining's multi_logloss: 0.155708\ttraining's quad_kappa: 0.95242\tvalid_1's multi_logloss: 1.33054\tvalid_1's quad_kappa: 0.526523\n",
      "[900]\ttraining's multi_logloss: 0.131789\ttraining's quad_kappa: 0.958445\tvalid_1's multi_logloss: 1.37747\tvalid_1's quad_kappa: 0.521962\n",
      "[1000]\ttraining's multi_logloss: 0.112291\ttraining's quad_kappa: 0.964043\tvalid_1's multi_logloss: 1.41838\tvalid_1's quad_kappa: 0.528089\n",
      "[1100]\ttraining's multi_logloss: 0.0961216\ttraining's quad_kappa: 0.970385\tvalid_1's multi_logloss: 1.46123\tvalid_1's quad_kappa: 0.525586\n",
      "[1200]\ttraining's multi_logloss: 0.0827354\ttraining's quad_kappa: 0.973905\tvalid_1's multi_logloss: 1.5033\tvalid_1's quad_kappa: 0.527406\n",
      "[1300]\ttraining's multi_logloss: 0.0710333\ttraining's quad_kappa: 0.978143\tvalid_1's multi_logloss: 1.55428\tvalid_1's quad_kappa: 0.525951\n",
      "[1400]\ttraining's multi_logloss: 0.0612904\ttraining's quad_kappa: 0.980598\tvalid_1's multi_logloss: 1.60177\tvalid_1's quad_kappa: 0.532752\n",
      "[1500]\ttraining's multi_logloss: 0.0531412\ttraining's quad_kappa: 0.982596\tvalid_1's multi_logloss: 1.64692\tvalid_1's quad_kappa: 0.515231\n",
      "[1600]\ttraining's multi_logloss: 0.0465273\ttraining's quad_kappa: 0.985519\tvalid_1's multi_logloss: 1.69639\tvalid_1's quad_kappa: 0.51398\n",
      "[1700]\ttraining's multi_logloss: 0.0406326\ttraining's quad_kappa: 0.986809\tvalid_1's multi_logloss: 1.74923\tvalid_1's quad_kappa: 0.510454\n",
      "[1800]\ttraining's multi_logloss: 0.0355755\ttraining's quad_kappa: 0.988096\tvalid_1's multi_logloss: 1.79648\tvalid_1's quad_kappa: 0.516241\n",
      "[1900]\ttraining's multi_logloss: 0.0313269\ttraining's quad_kappa: 0.988785\tvalid_1's multi_logloss: 1.84853\tvalid_1's quad_kappa: 0.520424\n",
      "[2000]\ttraining's multi_logloss: 0.0281516\ttraining's quad_kappa: 0.989126\tvalid_1's multi_logloss: 1.89775\tvalid_1's quad_kappa: 0.523902\n",
      "Early stopping, best iteration is:                  \n",
      "[62]\ttraining's multi_logloss: 0.745269\ttraining's quad_kappa: 0.666597\tvalid_1's multi_logloss: 0.997162\tvalid_1's quad_kappa: 0.541253\n",
      "{'learning_rate': 0.10689505538414147, 'metric': 'multiclass', 'n_estimators': 10000, 'num_classes': 4, 'objective': 'multiclass', 'random_state': 2019}\n",
      "Training until validation scores don't improve for 2000 rounds                 \n",
      " 10%|█         | 1/10 [06:07<55:01, 366.88s/it, best loss: -0.5126953428902475]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 0.675689\ttraining's quad_kappa: 0.702704\tvalid_1's multi_logloss: 1.01196\tvalid_1's quad_kappa: 0.496554\n",
      "[200]\ttraining's multi_logloss: 0.520898\ttraining's quad_kappa: 0.789366\tvalid_1's multi_logloss: 1.04848\tvalid_1's quad_kappa: 0.508913\n",
      "[300]\ttraining's multi_logloss: 0.420943\ttraining's quad_kappa: 0.838961\tvalid_1's multi_logloss: 1.09075\tvalid_1's quad_kappa: 0.51054\n",
      "[400]\ttraining's multi_logloss: 0.346808\ttraining's quad_kappa: 0.873906\tvalid_1's multi_logloss: 1.13595\tvalid_1's quad_kappa: 0.501068\n",
      "[500]\ttraining's multi_logloss: 0.28909\ttraining's quad_kappa: 0.897132\tvalid_1's multi_logloss: 1.18124\tvalid_1's quad_kappa: 0.506597\n",
      "[600]\ttraining's multi_logloss: 0.243317\ttraining's quad_kappa: 0.916788\tvalid_1's multi_logloss: 1.22112\tvalid_1's quad_kappa: 0.497956\n",
      "[700]\ttraining's multi_logloss: 0.205752\ttraining's quad_kappa: 0.934839\tvalid_1's multi_logloss: 1.26479\tvalid_1's quad_kappa: 0.499423\n",
      "[800]\ttraining's multi_logloss: 0.175802\ttraining's quad_kappa: 0.945205\tvalid_1's multi_logloss: 1.30971\tvalid_1's quad_kappa: 0.494375\n",
      "[900]\ttraining's multi_logloss: 0.150299\ttraining's quad_kappa: 0.953319\tvalid_1's multi_logloss: 1.35729\tvalid_1's quad_kappa: 0.494967\n",
      "[1000]\ttraining's multi_logloss: 0.128491\ttraining's quad_kappa: 0.963078\tvalid_1's multi_logloss: 1.40571\tvalid_1's quad_kappa: 0.500286\n",
      "[1100]\ttraining's multi_logloss: 0.10993\ttraining's quad_kappa: 0.971205\tvalid_1's multi_logloss: 1.44789\tvalid_1's quad_kappa: 0.493746\n",
      "[1200]\ttraining's multi_logloss: 0.0943018\ttraining's quad_kappa: 0.975744\tvalid_1's multi_logloss: 1.48585\tvalid_1's quad_kappa: 0.491644\n",
      "[1300]\ttraining's multi_logloss: 0.0809685\ttraining's quad_kappa: 0.980429\tvalid_1's multi_logloss: 1.53106\tvalid_1's quad_kappa: 0.487538\n",
      "[1400]\ttraining's multi_logloss: 0.0695998\ttraining's quad_kappa: 0.981896\tvalid_1's multi_logloss: 1.57405\tvalid_1's quad_kappa: 0.475288\n",
      "[1500]\ttraining's multi_logloss: 0.0610476\ttraining's quad_kappa: 0.983426\tvalid_1's multi_logloss: 1.61718\tvalid_1's quad_kappa: 0.479403\n",
      "[1600]\ttraining's multi_logloss: 0.0528087\ttraining's quad_kappa: 0.986329\tvalid_1's multi_logloss: 1.66294\tvalid_1's quad_kappa: 0.472633\n",
      "[1700]\ttraining's multi_logloss: 0.0459524\ttraining's quad_kappa: 0.988122\tvalid_1's multi_logloss: 1.70576\tvalid_1's quad_kappa: 0.481377\n",
      "[1800]\ttraining's multi_logloss: 0.0399338\ttraining's quad_kappa: 0.990229\tvalid_1's multi_logloss: 1.75541\tvalid_1's quad_kappa: 0.475383\n",
      "[1900]\ttraining's multi_logloss: 0.0347648\ttraining's quad_kappa: 0.991473\tvalid_1's multi_logloss: 1.80226\tvalid_1's quad_kappa: 0.474221\n",
      "[2000]\ttraining's multi_logloss: 0.0306496\ttraining's quad_kappa: 0.992048\tvalid_1's multi_logloss: 1.85127\tvalid_1's quad_kappa: 0.464494\n",
      "Early stopping, best iteration is:                                             \n",
      "[60]\ttraining's multi_logloss: 0.769408\ttraining's quad_kappa: 0.645556\tvalid_1's multi_logloss: 1.00398\tvalid_1's quad_kappa: 0.484641\n",
      "Training until validation scores don't improve for 2000 rounds                 \n",
      "[100]\ttraining's multi_logloss: 0.656988\ttraining's quad_kappa: 0.713932\tvalid_1's multi_logloss: 1.00038\tvalid_1's quad_kappa: 0.534558\n",
      "[200]\ttraining's multi_logloss: 0.504502\ttraining's quad_kappa: 0.798394\tvalid_1's multi_logloss: 1.03762\tvalid_1's quad_kappa: 0.533884\n",
      "[300]\ttraining's multi_logloss: 0.404523\ttraining's quad_kappa: 0.854746\tvalid_1's multi_logloss: 1.07598\tvalid_1's quad_kappa: 0.524623\n",
      "[400]\ttraining's multi_logloss: 0.330241\ttraining's quad_kappa: 0.888267\tvalid_1's multi_logloss: 1.11702\tvalid_1's quad_kappa: 0.527288\n",
      "[500]\ttraining's multi_logloss: 0.273989\ttraining's quad_kappa: 0.908197\tvalid_1's multi_logloss: 1.16023\tvalid_1's quad_kappa: 0.52367\n",
      "[600]\ttraining's multi_logloss: 0.230112\ttraining's quad_kappa: 0.923316\tvalid_1's multi_logloss: 1.20235\tvalid_1's quad_kappa: 0.522767\n",
      "[700]\ttraining's multi_logloss: 0.194585\ttraining's quad_kappa: 0.936231\tvalid_1's multi_logloss: 1.24359\tvalid_1's quad_kappa: 0.523574\n",
      "[800]\ttraining's multi_logloss: 0.164657\ttraining's quad_kappa: 0.945265\tvalid_1's multi_logloss: 1.28758\tvalid_1's quad_kappa: 0.517258\n",
      "[900]\ttraining's multi_logloss: 0.140351\ttraining's quad_kappa: 0.956185\tvalid_1's multi_logloss: 1.3273\tvalid_1's quad_kappa: 0.510396\n",
      "[1000]\ttraining's multi_logloss: 0.120226\ttraining's quad_kappa: 0.962709\tvalid_1's multi_logloss: 1.36867\tvalid_1's quad_kappa: 0.503275\n",
      "[1100]\ttraining's multi_logloss: 0.102672\ttraining's quad_kappa: 0.968077\tvalid_1's multi_logloss: 1.40962\tvalid_1's quad_kappa: 0.508002\n",
      "[1200]\ttraining's multi_logloss: 0.087559\ttraining's quad_kappa: 0.972379\tvalid_1's multi_logloss: 1.4529\tvalid_1's quad_kappa: 0.508181\n",
      "[1300]\ttraining's multi_logloss: 0.0753755\ttraining's quad_kappa: 0.977246\tvalid_1's multi_logloss: 1.49495\tvalid_1's quad_kappa: 0.515281\n",
      "[1400]\ttraining's multi_logloss: 0.0651463\ttraining's quad_kappa: 0.979912\tvalid_1's multi_logloss: 1.54168\tvalid_1's quad_kappa: 0.504785\n",
      "[1500]\ttraining's multi_logloss: 0.0563286\ttraining's quad_kappa: 0.984118\tvalid_1's multi_logloss: 1.58157\tvalid_1's quad_kappa: 0.504899\n",
      "[1600]\ttraining's multi_logloss: 0.0489041\ttraining's quad_kappa: 0.986348\tvalid_1's multi_logloss: 1.62823\tvalid_1's quad_kappa: 0.505133\n",
      "[1700]\ttraining's multi_logloss: 0.0427668\ttraining's quad_kappa: 0.988071\tvalid_1's multi_logloss: 1.6685\tvalid_1's quad_kappa: 0.502262\n",
      "[1800]\ttraining's multi_logloss: 0.0370089\ttraining's quad_kappa: 0.988953\tvalid_1's multi_logloss: 1.71324\tvalid_1's quad_kappa: 0.505945\n",
      "[1900]\ttraining's multi_logloss: 0.0326562\ttraining's quad_kappa: 0.989864\tvalid_1's multi_logloss: 1.76114\tvalid_1's quad_kappa: 0.499979\n",
      "[2000]\ttraining's multi_logloss: 0.0292473\ttraining's quad_kappa: 0.990148\tvalid_1's multi_logloss: 1.8068\tvalid_1's quad_kappa: 0.501558\n",
      "Early stopping, best iteration is:                                             \n",
      "[66]\ttraining's multi_logloss: 0.733564\ttraining's quad_kappa: 0.673684\tvalid_1's multi_logloss: 0.995654\tvalid_1's quad_kappa: 0.522241\n",
      "Training until validation scores don't improve for 2000 rounds                 \n",
      "[100]\ttraining's multi_logloss: 0.671408\ttraining's quad_kappa: 0.707356\tvalid_1's multi_logloss: 1.01067\tvalid_1's quad_kappa: 0.537227\n",
      "[200]\ttraining's multi_logloss: 0.521533\ttraining's quad_kappa: 0.788436\tvalid_1's multi_logloss: 1.04981\tvalid_1's quad_kappa: 0.54365\n",
      "[300]\ttraining's multi_logloss: 0.418132\ttraining's quad_kappa: 0.844022\tvalid_1's multi_logloss: 1.0904\tvalid_1's quad_kappa: 0.537027\n",
      "[400]\ttraining's multi_logloss: 0.344442\ttraining's quad_kappa: 0.87819\tvalid_1's multi_logloss: 1.13056\tvalid_1's quad_kappa: 0.537115\n",
      "[500]\ttraining's multi_logloss: 0.287397\ttraining's quad_kappa: 0.899134\tvalid_1's multi_logloss: 1.17628\tvalid_1's quad_kappa: 0.544771\n",
      "[600]\ttraining's multi_logloss: 0.24193\ttraining's quad_kappa: 0.915155\tvalid_1's multi_logloss: 1.22406\tvalid_1's quad_kappa: 0.537209\n",
      "[700]\ttraining's multi_logloss: 0.202267\ttraining's quad_kappa: 0.935167\tvalid_1's multi_logloss: 1.26597\tvalid_1's quad_kappa: 0.525058\n",
      "[800]\ttraining's multi_logloss: 0.17119\ttraining's quad_kappa: 0.944887\tvalid_1's multi_logloss: 1.30719\tvalid_1's quad_kappa: 0.521902\n",
      "[900]\ttraining's multi_logloss: 0.146934\ttraining's quad_kappa: 0.956236\tvalid_1's multi_logloss: 1.35171\tvalid_1's quad_kappa: 0.517581\n",
      "[1000]\ttraining's multi_logloss: 0.125708\ttraining's quad_kappa: 0.962239\tvalid_1's multi_logloss: 1.39139\tvalid_1's quad_kappa: 0.515626\n",
      "[1100]\ttraining's multi_logloss: 0.10832\ttraining's quad_kappa: 0.966479\tvalid_1's multi_logloss: 1.4315\tvalid_1's quad_kappa: 0.511285\n",
      "[1200]\ttraining's multi_logloss: 0.0946514\ttraining's quad_kappa: 0.97051\tvalid_1's multi_logloss: 1.47699\tvalid_1's quad_kappa: 0.507027\n",
      "[1300]\ttraining's multi_logloss: 0.0815517\ttraining's quad_kappa: 0.974704\tvalid_1's multi_logloss: 1.52001\tvalid_1's quad_kappa: 0.508116\n",
      "[1400]\ttraining's multi_logloss: 0.0706946\ttraining's quad_kappa: 0.977826\tvalid_1's multi_logloss: 1.56615\tvalid_1's quad_kappa: 0.505392\n",
      "[1500]\ttraining's multi_logloss: 0.0612535\ttraining's quad_kappa: 0.98116\tvalid_1's multi_logloss: 1.60995\tvalid_1's quad_kappa: 0.5073\n",
      "[1600]\ttraining's multi_logloss: 0.0534777\ttraining's quad_kappa: 0.983765\tvalid_1's multi_logloss: 1.65328\tvalid_1's quad_kappa: 0.510088\n",
      "[1700]\ttraining's multi_logloss: 0.0469293\ttraining's quad_kappa: 0.985141\tvalid_1's multi_logloss: 1.69671\tvalid_1's quad_kappa: 0.511486\n",
      "[1800]\ttraining's multi_logloss: 0.0415559\ttraining's quad_kappa: 0.986401\tvalid_1's multi_logloss: 1.74127\tvalid_1's quad_kappa: 0.517591\n",
      "[1900]\ttraining's multi_logloss: 0.0371119\ttraining's quad_kappa: 0.987749\tvalid_1's multi_logloss: 1.78886\tvalid_1's quad_kappa: 0.519298\n",
      "[2000]\ttraining's multi_logloss: 0.0333121\ttraining's quad_kappa: 0.988722\tvalid_1's multi_logloss: 1.83405\tvalid_1's quad_kappa: 0.51628\n",
      "Early stopping, best iteration is:                                             \n",
      "[70]\ttraining's multi_logloss: 0.737367\ttraining's quad_kappa: 0.667118\tvalid_1's multi_logloss: 1.00076\tvalid_1's quad_kappa: 0.535891\n",
      "{'learning_rate': 0.006555303260125819, 'metric': 'multiclass', 'n_estimators': 10000, 'num_classes': 4, 'objective': 'multiclass', 'random_state': 2019}\n",
      " 20%|██        | 2/10 [12:44<50:08, 376.02s/it, best loss: -0.5126953428902475]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2000 rounds                 \n",
      "[100]\ttraining's multi_logloss: 1.0709\ttraining's quad_kappa: 0.380784\tvalid_1's multi_logloss: 1.0928\tvalid_1's quad_kappa: 0.357007\n",
      "[200]\ttraining's multi_logloss: 0.994529\ttraining's quad_kappa: 0.498738\tvalid_1's multi_logloss: 1.04804\tvalid_1's quad_kappa: 0.460832\n",
      "[300]\ttraining's multi_logloss: 0.943823\ttraining's quad_kappa: 0.53147\tvalid_1's multi_logloss: 1.02663\tvalid_1's quad_kappa: 0.47997\n",
      "[400]\ttraining's multi_logloss: 0.906353\ttraining's quad_kappa: 0.555011\tvalid_1's multi_logloss: 1.01441\tvalid_1's quad_kappa: 0.478469\n",
      "[500]\ttraining's multi_logloss: 0.876113\ttraining's quad_kappa: 0.577681\tvalid_1's multi_logloss: 1.00806\tvalid_1's quad_kappa: 0.478885\n",
      "[600]\ttraining's multi_logloss: 0.84995\ttraining's quad_kappa: 0.593899\tvalid_1's multi_logloss: 1.00365\tvalid_1's quad_kappa: 0.481626\n",
      "[700]\ttraining's multi_logloss: 0.827089\ttraining's quad_kappa: 0.610767\tvalid_1's multi_logloss: 1.00139\tvalid_1's quad_kappa: 0.485446\n",
      "[800]\ttraining's multi_logloss: 0.805936\ttraining's quad_kappa: 0.624282\tvalid_1's multi_logloss: 1.00011\tvalid_1's quad_kappa: 0.485262\n",
      "[900]\ttraining's multi_logloss: 0.786467\ttraining's quad_kappa: 0.634353\tvalid_1's multi_logloss: 1\tvalid_1's quad_kappa: 0.482877\n",
      "[1000]\ttraining's multi_logloss: 0.76872\ttraining's quad_kappa: 0.646186\tvalid_1's multi_logloss: 1.00002\tvalid_1's quad_kappa: 0.482506\n",
      "[1100]\ttraining's multi_logloss: 0.752327\ttraining's quad_kappa: 0.655346\tvalid_1's multi_logloss: 1.00113\tvalid_1's quad_kappa: 0.478057\n",
      "[1200]\ttraining's multi_logloss: 0.737445\ttraining's quad_kappa: 0.662979\tvalid_1's multi_logloss: 1.00226\tvalid_1's quad_kappa: 0.479254\n",
      "[1300]\ttraining's multi_logloss: 0.72294\ttraining's quad_kappa: 0.672346\tvalid_1's multi_logloss: 1.00349\tvalid_1's quad_kappa: 0.484003\n",
      "[1400]\ttraining's multi_logloss: 0.709229\ttraining's quad_kappa: 0.680376\tvalid_1's multi_logloss: 1.00523\tvalid_1's quad_kappa: 0.486857\n",
      "[1500]\ttraining's multi_logloss: 0.696036\ttraining's quad_kappa: 0.689268\tvalid_1's multi_logloss: 1.00614\tvalid_1's quad_kappa: 0.492648\n",
      "[1600]\ttraining's multi_logloss: 0.683372\ttraining's quad_kappa: 0.695667\tvalid_1's multi_logloss: 1.00789\tvalid_1's quad_kappa: 0.493612\n",
      "[1700]\ttraining's multi_logloss: 0.671292\ttraining's quad_kappa: 0.702\tvalid_1's multi_logloss: 1.00983\tvalid_1's quad_kappa: 0.494065\n",
      "[1800]\ttraining's multi_logloss: 0.659606\ttraining's quad_kappa: 0.708818\tvalid_1's multi_logloss: 1.01135\tvalid_1's quad_kappa: 0.496607\n",
      "[1900]\ttraining's multi_logloss: 0.648436\ttraining's quad_kappa: 0.715204\tvalid_1's multi_logloss: 1.01291\tvalid_1's quad_kappa: 0.499419\n",
      "[2000]\ttraining's multi_logloss: 0.637575\ttraining's quad_kappa: 0.721472\tvalid_1's multi_logloss: 1.01465\tvalid_1's quad_kappa: 0.49972\n",
      "[2100]\ttraining's multi_logloss: 0.627164\ttraining's quad_kappa: 0.728121\tvalid_1's multi_logloss: 1.01639\tvalid_1's quad_kappa: 0.501231\n",
      "[2200]\ttraining's multi_logloss: 0.616976\ttraining's quad_kappa: 0.73488\tvalid_1's multi_logloss: 1.01758\tvalid_1's quad_kappa: 0.500831\n",
      "[2300]\ttraining's multi_logloss: 0.607128\ttraining's quad_kappa: 0.740855\tvalid_1's multi_logloss: 1.01895\tvalid_1's quad_kappa: 0.502559\n",
      "[2400]\ttraining's multi_logloss: 0.597742\ttraining's quad_kappa: 0.746847\tvalid_1's multi_logloss: 1.02111\tvalid_1's quad_kappa: 0.507251\n",
      "[2500]\ttraining's multi_logloss: 0.588687\ttraining's quad_kappa: 0.752495\tvalid_1's multi_logloss: 1.02339\tvalid_1's quad_kappa: 0.510421\n",
      "[2600]\ttraining's multi_logloss: 0.579915\ttraining's quad_kappa: 0.759822\tvalid_1's multi_logloss: 1.02531\tvalid_1's quad_kappa: 0.514646\n",
      "[2700]\ttraining's multi_logloss: 0.571091\ttraining's quad_kappa: 0.764562\tvalid_1's multi_logloss: 1.02738\tvalid_1's quad_kappa: 0.510239\n",
      "[2800]\ttraining's multi_logloss: 0.562648\ttraining's quad_kappa: 0.770938\tvalid_1's multi_logloss: 1.02965\tvalid_1's quad_kappa: 0.509558\n",
      "[2900]\ttraining's multi_logloss: 0.554371\ttraining's quad_kappa: 0.773642\tvalid_1's multi_logloss: 1.03206\tvalid_1's quad_kappa: 0.509317\n",
      "Early stopping, best iteration is:                                             \n",
      "[948]\ttraining's multi_logloss: 0.77766\ttraining's quad_kappa: 0.640435\tvalid_1's multi_logloss: 0.999685\tvalid_1's quad_kappa: 0.481948\n",
      "Training until validation scores don't improve for 2000 rounds                 \n",
      "[100]\ttraining's multi_logloss: 1.05617\ttraining's quad_kappa: 0.421992\tvalid_1's multi_logloss: 1.09391\tvalid_1's quad_kappa: 0.388951\n",
      "[200]\ttraining's multi_logloss: 0.976885\ttraining's quad_kappa: 0.528236\tvalid_1's multi_logloss: 1.04745\tvalid_1's quad_kappa: 0.464087\n",
      "[300]\ttraining's multi_logloss: 0.925899\ttraining's quad_kappa: 0.558945\tvalid_1's multi_logloss: 1.02599\tvalid_1's quad_kappa: 0.475043\n",
      "[400]\ttraining's multi_logloss: 0.887156\ttraining's quad_kappa: 0.584554\tvalid_1's multi_logloss: 1.01307\tvalid_1's quad_kappa: 0.49972\n",
      "[500]\ttraining's multi_logloss: 0.855803\ttraining's quad_kappa: 0.60491\tvalid_1's multi_logloss: 1.00563\tvalid_1's quad_kappa: 0.505953\n",
      "[600]\ttraining's multi_logloss: 0.82935\ttraining's quad_kappa: 0.618183\tvalid_1's multi_logloss: 1.00199\tvalid_1's quad_kappa: 0.514561\n",
      "[700]\ttraining's multi_logloss: 0.806137\ttraining's quad_kappa: 0.632566\tvalid_1's multi_logloss: 0.998897\tvalid_1's quad_kappa: 0.508021\n",
      "[800]\ttraining's multi_logloss: 0.785376\ttraining's quad_kappa: 0.641943\tvalid_1's multi_logloss: 0.996016\tvalid_1's quad_kappa: 0.510567\n",
      "[900]\ttraining's multi_logloss: 0.766575\ttraining's quad_kappa: 0.655435\tvalid_1's multi_logloss: 0.99487\tvalid_1's quad_kappa: 0.516308\n",
      "[1000]\ttraining's multi_logloss: 0.749325\ttraining's quad_kappa: 0.664088\tvalid_1's multi_logloss: 0.994914\tvalid_1's quad_kappa: 0.522463\n",
      "[1100]\ttraining's multi_logloss: 0.733299\ttraining's quad_kappa: 0.673463\tvalid_1's multi_logloss: 0.994869\tvalid_1's quad_kappa: 0.523992\n",
      "[1200]\ttraining's multi_logloss: 0.718332\ttraining's quad_kappa: 0.683424\tvalid_1's multi_logloss: 0.995536\tvalid_1's quad_kappa: 0.527194\n",
      "[1300]\ttraining's multi_logloss: 0.704171\ttraining's quad_kappa: 0.690839\tvalid_1's multi_logloss: 0.99585\tvalid_1's quad_kappa: 0.527029\n",
      "[1400]\ttraining's multi_logloss: 0.68989\ttraining's quad_kappa: 0.698319\tvalid_1's multi_logloss: 0.996516\tvalid_1's quad_kappa: 0.531736\n",
      "[1500]\ttraining's multi_logloss: 0.676662\ttraining's quad_kappa: 0.705093\tvalid_1's multi_logloss: 0.997411\tvalid_1's quad_kappa: 0.529689\n",
      "[1600]\ttraining's multi_logloss: 0.663639\ttraining's quad_kappa: 0.711458\tvalid_1's multi_logloss: 0.998613\tvalid_1's quad_kappa: 0.530816\n",
      "[1700]\ttraining's multi_logloss: 0.65127\ttraining's quad_kappa: 0.71663\tvalid_1's multi_logloss: 0.999424\tvalid_1's quad_kappa: 0.530204\n",
      "[1800]\ttraining's multi_logloss: 0.640061\ttraining's quad_kappa: 0.723246\tvalid_1's multi_logloss: 1.00117\tvalid_1's quad_kappa: 0.531462\n",
      "[1900]\ttraining's multi_logloss: 0.629144\ttraining's quad_kappa: 0.730426\tvalid_1's multi_logloss: 1.00294\tvalid_1's quad_kappa: 0.531676\n",
      "[2000]\ttraining's multi_logloss: 0.618701\ttraining's quad_kappa: 0.735687\tvalid_1's multi_logloss: 1.00515\tvalid_1's quad_kappa: 0.531957\n",
      "[2100]\ttraining's multi_logloss: 0.608754\ttraining's quad_kappa: 0.742925\tvalid_1's multi_logloss: 1.00722\tvalid_1's quad_kappa: 0.528824\n",
      "[2200]\ttraining's multi_logloss: 0.59865\ttraining's quad_kappa: 0.74623\tvalid_1's multi_logloss: 1.00892\tvalid_1's quad_kappa: 0.526685\n",
      "[2300]\ttraining's multi_logloss: 0.588699\ttraining's quad_kappa: 0.751272\tvalid_1's multi_logloss: 1.01071\tvalid_1's quad_kappa: 0.52185\n",
      "[2400]\ttraining's multi_logloss: 0.579229\ttraining's quad_kappa: 0.756473\tvalid_1's multi_logloss: 1.01277\tvalid_1's quad_kappa: 0.52188\n",
      "[2500]\ttraining's multi_logloss: 0.570308\ttraining's quad_kappa: 0.761215\tvalid_1's multi_logloss: 1.01505\tvalid_1's quad_kappa: 0.523954\n",
      "[2600]\ttraining's multi_logloss: 0.561692\ttraining's quad_kappa: 0.767607\tvalid_1's multi_logloss: 1.01698\tvalid_1's quad_kappa: 0.525377\n",
      "[2700]\ttraining's multi_logloss: 0.553114\ttraining's quad_kappa: 0.770392\tvalid_1's multi_logloss: 1.01876\tvalid_1's quad_kappa: 0.524798\n",
      "[2800]\ttraining's multi_logloss: 0.544705\ttraining's quad_kappa: 0.775986\tvalid_1's multi_logloss: 1.02095\tvalid_1's quad_kappa: 0.525088\n",
      "[2900]\ttraining's multi_logloss: 0.536376\ttraining's quad_kappa: 0.780193\tvalid_1's multi_logloss: 1.02327\tvalid_1's quad_kappa: 0.523152\n",
      "Early stopping, best iteration is:                                             \n",
      "[911]\ttraining's multi_logloss: 0.764583\ttraining's quad_kappa: 0.655427\tvalid_1's multi_logloss: 0.99482\tvalid_1's quad_kappa: 0.517652\n",
      "Training until validation scores don't improve for 2000 rounds                 \n",
      "[100]\ttraining's multi_logloss: 1.07378\ttraining's quad_kappa: 0.384441\tvalid_1's multi_logloss: 1.10947\tvalid_1's quad_kappa: 0.373896\n",
      "[200]\ttraining's multi_logloss: 0.994674\ttraining's quad_kappa: 0.517555\tvalid_1's multi_logloss: 1.05823\tvalid_1's quad_kappa: 0.4845\n",
      "[300]\ttraining's multi_logloss: 0.943317\ttraining's quad_kappa: 0.54609\tvalid_1's multi_logloss: 1.03204\tvalid_1's quad_kappa: 0.506879\n",
      "[400]\ttraining's multi_logloss: 0.903985\ttraining's quad_kappa: 0.570018\tvalid_1's multi_logloss: 1.01721\tvalid_1's quad_kappa: 0.523366\n",
      "[500]\ttraining's multi_logloss: 0.872217\ttraining's quad_kappa: 0.591297\tvalid_1's multi_logloss: 1.00927\tvalid_1's quad_kappa: 0.531941\n",
      "[600]\ttraining's multi_logloss: 0.845564\ttraining's quad_kappa: 0.609182\tvalid_1's multi_logloss: 1.00403\tvalid_1's quad_kappa: 0.533793\n",
      "[700]\ttraining's multi_logloss: 0.821933\ttraining's quad_kappa: 0.621324\tvalid_1's multi_logloss: 1.00004\tvalid_1's quad_kappa: 0.533151\n",
      "[800]\ttraining's multi_logloss: 0.800671\ttraining's quad_kappa: 0.635085\tvalid_1's multi_logloss: 0.998134\tvalid_1's quad_kappa: 0.541659\n",
      "[900]\ttraining's multi_logloss: 0.781657\ttraining's quad_kappa: 0.644982\tvalid_1's multi_logloss: 0.996994\tvalid_1's quad_kappa: 0.541377\n",
      "[1000]\ttraining's multi_logloss: 0.764064\ttraining's quad_kappa: 0.657057\tvalid_1's multi_logloss: 0.996776\tvalid_1's quad_kappa: 0.538901\n",
      "[1100]\ttraining's multi_logloss: 0.747534\ttraining's quad_kappa: 0.664248\tvalid_1's multi_logloss: 0.997054\tvalid_1's quad_kappa: 0.538936\n",
      "[1200]\ttraining's multi_logloss: 0.731866\ttraining's quad_kappa: 0.673856\tvalid_1's multi_logloss: 0.996958\tvalid_1's quad_kappa: 0.540053\n",
      "[1300]\ttraining's multi_logloss: 0.717795\ttraining's quad_kappa: 0.682545\tvalid_1's multi_logloss: 0.997796\tvalid_1's quad_kappa: 0.539886\n",
      "[1400]\ttraining's multi_logloss: 0.70431\ttraining's quad_kappa: 0.689074\tvalid_1's multi_logloss: 0.998821\tvalid_1's quad_kappa: 0.541318\n",
      "[1500]\ttraining's multi_logloss: 0.691191\ttraining's quad_kappa: 0.695901\tvalid_1's multi_logloss: 0.999932\tvalid_1's quad_kappa: 0.541404\n",
      "[1600]\ttraining's multi_logloss: 0.678885\ttraining's quad_kappa: 0.702224\tvalid_1's multi_logloss: 1.00133\tvalid_1's quad_kappa: 0.539691\n",
      "[1700]\ttraining's multi_logloss: 0.667259\ttraining's quad_kappa: 0.708817\tvalid_1's multi_logloss: 1.00284\tvalid_1's quad_kappa: 0.54127\n",
      "[1800]\ttraining's multi_logloss: 0.655729\ttraining's quad_kappa: 0.715951\tvalid_1's multi_logloss: 1.0047\tvalid_1's quad_kappa: 0.538886\n",
      "[1900]\ttraining's multi_logloss: 0.644584\ttraining's quad_kappa: 0.723208\tvalid_1's multi_logloss: 1.0064\tvalid_1's quad_kappa: 0.54017\n",
      "[2000]\ttraining's multi_logloss: 0.633973\ttraining's quad_kappa: 0.729259\tvalid_1's multi_logloss: 1.00804\tvalid_1's quad_kappa: 0.544746\n",
      "[2100]\ttraining's multi_logloss: 0.623587\ttraining's quad_kappa: 0.736001\tvalid_1's multi_logloss: 1.00983\tvalid_1's quad_kappa: 0.54584\n",
      "[2200]\ttraining's multi_logloss: 0.613787\ttraining's quad_kappa: 0.742136\tvalid_1's multi_logloss: 1.01181\tvalid_1's quad_kappa: 0.547534\n",
      "[2300]\ttraining's multi_logloss: 0.604201\ttraining's quad_kappa: 0.746058\tvalid_1's multi_logloss: 1.01434\tvalid_1's quad_kappa: 0.546517\n",
      "[2400]\ttraining's multi_logloss: 0.594766\ttraining's quad_kappa: 0.75185\tvalid_1's multi_logloss: 1.01691\tvalid_1's quad_kappa: 0.547215\n",
      "[2500]\ttraining's multi_logloss: 0.585734\ttraining's quad_kappa: 0.756221\tvalid_1's multi_logloss: 1.0191\tvalid_1's quad_kappa: 0.544196\n",
      "[2600]\ttraining's multi_logloss: 0.57723\ttraining's quad_kappa: 0.759716\tvalid_1's multi_logloss: 1.02154\tvalid_1's quad_kappa: 0.543205\n",
      "[2700]\ttraining's multi_logloss: 0.569058\ttraining's quad_kappa: 0.764082\tvalid_1's multi_logloss: 1.02364\tvalid_1's quad_kappa: 0.541407\n",
      "[2800]\ttraining's multi_logloss: 0.561044\ttraining's quad_kappa: 0.768229\tvalid_1's multi_logloss: 1.02567\tvalid_1's quad_kappa: 0.540169\n",
      "[2900]\ttraining's multi_logloss: 0.55273\ttraining's quad_kappa: 0.77231\tvalid_1's multi_logloss: 1.02819\tvalid_1's quad_kappa: 0.538922\n",
      "Early stopping, best iteration is:                                             \n",
      "[970]\ttraining's multi_logloss: 0.76909\ttraining's quad_kappa: 0.653739\tvalid_1's multi_logloss: 0.996628\tvalid_1's quad_kappa: 0.538902\n",
      "{'learning_rate': 0.12629497693171945, 'metric': 'multiclass', 'n_estimators': 10000, 'num_classes': 4, 'objective': 'multiclass', 'random_state': 2019}\n",
      "Training until validation scores don't improve for 2000 rounds                 \n",
      " 30%|███       | 3/10 [22:05<50:20, 431.44s/it, best loss: -0.5135357478561519]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 0.643647\ttraining's quad_kappa: 0.722662\tvalid_1's multi_logloss: 1.01764\tvalid_1's quad_kappa: 0.505617\n",
      "[200]\ttraining's multi_logloss: 0.482749\ttraining's quad_kappa: 0.810627\tvalid_1's multi_logloss: 1.06159\tvalid_1's quad_kappa: 0.490097\n",
      "[300]\ttraining's multi_logloss: 0.377604\ttraining's quad_kappa: 0.862308\tvalid_1's multi_logloss: 1.11434\tvalid_1's quad_kappa: 0.509368\n",
      "[400]\ttraining's multi_logloss: 0.30398\ttraining's quad_kappa: 0.891711\tvalid_1's multi_logloss: 1.16515\tvalid_1's quad_kappa: 0.511623\n",
      "[500]\ttraining's multi_logloss: 0.248342\ttraining's quad_kappa: 0.912635\tvalid_1's multi_logloss: 1.21691\tvalid_1's quad_kappa: 0.507443\n",
      "[600]\ttraining's multi_logloss: 0.205239\ttraining's quad_kappa: 0.931194\tvalid_1's multi_logloss: 1.26869\tvalid_1's quad_kappa: 0.497563\n",
      "[700]\ttraining's multi_logloss: 0.168512\ttraining's quad_kappa: 0.946094\tvalid_1's multi_logloss: 1.32383\tvalid_1's quad_kappa: 0.485029\n",
      "[800]\ttraining's multi_logloss: 0.140278\ttraining's quad_kappa: 0.956609\tvalid_1's multi_logloss: 1.37816\tvalid_1's quad_kappa: 0.48622\n",
      "[900]\ttraining's multi_logloss: 0.116314\ttraining's quad_kappa: 0.964395\tvalid_1's multi_logloss: 1.42877\tvalid_1's quad_kappa: 0.489094\n",
      "[1000]\ttraining's multi_logloss: 0.0968836\ttraining's quad_kappa: 0.974105\tvalid_1's multi_logloss: 1.48265\tvalid_1's quad_kappa: 0.483934\n",
      "[1100]\ttraining's multi_logloss: 0.0811487\ttraining's quad_kappa: 0.979493\tvalid_1's multi_logloss: 1.53779\tvalid_1's quad_kappa: 0.481868\n",
      "[1200]\ttraining's multi_logloss: 0.0684763\ttraining's quad_kappa: 0.982181\tvalid_1's multi_logloss: 1.59202\tvalid_1's quad_kappa: 0.485983\n",
      "[1300]\ttraining's multi_logloss: 0.0571755\ttraining's quad_kappa: 0.985687\tvalid_1's multi_logloss: 1.64423\tvalid_1's quad_kappa: 0.475909\n",
      "[1400]\ttraining's multi_logloss: 0.0484221\ttraining's quad_kappa: 0.987632\tvalid_1's multi_logloss: 1.70066\tvalid_1's quad_kappa: 0.472767\n",
      "[1500]\ttraining's multi_logloss: 0.040253\ttraining's quad_kappa: 0.99064\tvalid_1's multi_logloss: 1.74975\tvalid_1's quad_kappa: 0.479388\n",
      "[1600]\ttraining's multi_logloss: 0.0340495\ttraining's quad_kappa: 0.991663\tvalid_1's multi_logloss: 1.8025\tvalid_1's quad_kappa: 0.478242\n",
      "[1700]\ttraining's multi_logloss: 0.0294019\ttraining's quad_kappa: 0.992079\tvalid_1's multi_logloss: 1.85541\tvalid_1's quad_kappa: 0.473104\n",
      "[1800]\ttraining's multi_logloss: 0.0257224\ttraining's quad_kappa: 0.992945\tvalid_1's multi_logloss: 1.91184\tvalid_1's quad_kappa: 0.46519\n",
      "[1900]\ttraining's multi_logloss: 0.0225275\ttraining's quad_kappa: 0.993522\tvalid_1's multi_logloss: 1.96758\tvalid_1's quad_kappa: 0.456344\n",
      "[2000]\ttraining's multi_logloss: 0.0200275\ttraining's quad_kappa: 0.993521\tvalid_1's multi_logloss: 2.01873\tvalid_1's quad_kappa: 0.453944\n",
      "Early stopping, best iteration is:                                             \n",
      "[35]\ttraining's multi_logloss: 0.829982\ttraining's quad_kappa: 0.609565\tvalid_1's multi_logloss: 1.00276\tvalid_1's quad_kappa: 0.489697\n",
      "Training until validation scores don't improve for 2000 rounds                 \n",
      "[100]\ttraining's multi_logloss: 0.623648\ttraining's quad_kappa: 0.735852\tvalid_1's multi_logloss: 1.00834\tvalid_1's quad_kappa: 0.528837\n",
      "[200]\ttraining's multi_logloss: 0.463735\ttraining's quad_kappa: 0.827759\tvalid_1's multi_logloss: 1.05004\tvalid_1's quad_kappa: 0.520046\n",
      "[300]\ttraining's multi_logloss: 0.362079\ttraining's quad_kappa: 0.873893\tvalid_1's multi_logloss: 1.10249\tvalid_1's quad_kappa: 0.523695\n",
      "[400]\ttraining's multi_logloss: 0.287224\ttraining's quad_kappa: 0.907107\tvalid_1's multi_logloss: 1.15199\tvalid_1's quad_kappa: 0.52005\n",
      "[500]\ttraining's multi_logloss: 0.234054\ttraining's quad_kappa: 0.923067\tvalid_1's multi_logloss: 1.20402\tvalid_1's quad_kappa: 0.520615\n",
      "[600]\ttraining's multi_logloss: 0.191291\ttraining's quad_kappa: 0.936082\tvalid_1's multi_logloss: 1.25581\tvalid_1's quad_kappa: 0.519406\n",
      "[700]\ttraining's multi_logloss: 0.15767\ttraining's quad_kappa: 0.94896\tvalid_1's multi_logloss: 1.30481\tvalid_1's quad_kappa: 0.514614\n",
      "[800]\ttraining's multi_logloss: 0.129931\ttraining's quad_kappa: 0.958212\tvalid_1's multi_logloss: 1.35442\tvalid_1's quad_kappa: 0.505534\n",
      "[900]\ttraining's multi_logloss: 0.107266\ttraining's quad_kappa: 0.96673\tvalid_1's multi_logloss: 1.40408\tvalid_1's quad_kappa: 0.507159\n",
      "[1000]\ttraining's multi_logloss: 0.0896515\ttraining's quad_kappa: 0.971494\tvalid_1's multi_logloss: 1.45296\tvalid_1's quad_kappa: 0.500679\n",
      "[1100]\ttraining's multi_logloss: 0.074848\ttraining's quad_kappa: 0.976274\tvalid_1's multi_logloss: 1.50103\tvalid_1's quad_kappa: 0.502109\n",
      "[1200]\ttraining's multi_logloss: 0.0625201\ttraining's quad_kappa: 0.98189\tvalid_1's multi_logloss: 1.55501\tvalid_1's quad_kappa: 0.496353\n",
      "[1300]\ttraining's multi_logloss: 0.0533193\ttraining's quad_kappa: 0.984744\tvalid_1's multi_logloss: 1.60961\tvalid_1's quad_kappa: 0.491814\n",
      "[1400]\ttraining's multi_logloss: 0.0452128\ttraining's quad_kappa: 0.98748\tvalid_1's multi_logloss: 1.66496\tvalid_1's quad_kappa: 0.486154\n",
      "[1500]\ttraining's multi_logloss: 0.0385508\ttraining's quad_kappa: 0.98911\tvalid_1's multi_logloss: 1.71276\tvalid_1's quad_kappa: 0.485879\n",
      "[1600]\ttraining's multi_logloss: 0.0334056\ttraining's quad_kappa: 0.989395\tvalid_1's multi_logloss: 1.769\tvalid_1's quad_kappa: 0.493052\n",
      "[1700]\ttraining's multi_logloss: 0.0285217\ttraining's quad_kappa: 0.990182\tvalid_1's multi_logloss: 1.82783\tvalid_1's quad_kappa: 0.482618\n",
      "[1800]\ttraining's multi_logloss: 0.0248321\ttraining's quad_kappa: 0.990432\tvalid_1's multi_logloss: 1.88784\tvalid_1's quad_kappa: 0.489538\n",
      "[1900]\ttraining's multi_logloss: 0.0220354\ttraining's quad_kappa: 0.99075\tvalid_1's multi_logloss: 1.94311\tvalid_1's quad_kappa: 0.485525\n",
      "[2000]\ttraining's multi_logloss: 0.0195298\ttraining's quad_kappa: 0.990751\tvalid_1's multi_logloss: 1.99799\tvalid_1's quad_kappa: 0.474492\n",
      "Early stopping, best iteration is:                                             \n",
      "[57]\ttraining's multi_logloss: 0.730523\ttraining's quad_kappa: 0.677087\tvalid_1's multi_logloss: 0.995126\tvalid_1's quad_kappa: 0.51763\n",
      "Training until validation scores don't improve for 2000 rounds                 \n",
      "[100]\ttraining's multi_logloss: 0.638628\ttraining's quad_kappa: 0.724764\tvalid_1's multi_logloss: 1.01437\tvalid_1's quad_kappa: 0.533787\n",
      "[200]\ttraining's multi_logloss: 0.478399\ttraining's quad_kappa: 0.814575\tvalid_1's multi_logloss: 1.0608\tvalid_1's quad_kappa: 0.540766\n",
      "[300]\ttraining's multi_logloss: 0.374522\ttraining's quad_kappa: 0.867018\tvalid_1's multi_logloss: 1.1105\tvalid_1's quad_kappa: 0.533308\n",
      "[400]\ttraining's multi_logloss: 0.29884\ttraining's quad_kappa: 0.89234\tvalid_1's multi_logloss: 1.16436\tvalid_1's quad_kappa: 0.530744\n",
      "[500]\ttraining's multi_logloss: 0.242316\ttraining's quad_kappa: 0.917128\tvalid_1's multi_logloss: 1.21564\tvalid_1's quad_kappa: 0.527995\n",
      "[600]\ttraining's multi_logloss: 0.197551\ttraining's quad_kappa: 0.938117\tvalid_1's multi_logloss: 1.27152\tvalid_1's quad_kappa: 0.517237\n",
      "[700]\ttraining's multi_logloss: 0.163495\ttraining's quad_kappa: 0.94888\tvalid_1's multi_logloss: 1.3233\tvalid_1's quad_kappa: 0.521759\n",
      "[800]\ttraining's multi_logloss: 0.136819\ttraining's quad_kappa: 0.958253\tvalid_1's multi_logloss: 1.37296\tvalid_1's quad_kappa: 0.524928\n",
      "[900]\ttraining's multi_logloss: 0.115482\ttraining's quad_kappa: 0.964871\tvalid_1's multi_logloss: 1.42506\tvalid_1's quad_kappa: 0.528286\n",
      "[1000]\ttraining's multi_logloss: 0.0971036\ttraining's quad_kappa: 0.969132\tvalid_1's multi_logloss: 1.47614\tvalid_1's quad_kappa: 0.53478\n",
      "[1100]\ttraining's multi_logloss: 0.0822307\ttraining's quad_kappa: 0.974809\tvalid_1's multi_logloss: 1.52586\tvalid_1's quad_kappa: 0.527113\n",
      "[1200]\ttraining's multi_logloss: 0.0700525\ttraining's quad_kappa: 0.977885\tvalid_1's multi_logloss: 1.58229\tvalid_1's quad_kappa: 0.518462\n",
      "[1300]\ttraining's multi_logloss: 0.0596398\ttraining's quad_kappa: 0.981314\tvalid_1's multi_logloss: 1.6301\tvalid_1's quad_kappa: 0.525033\n",
      "[1400]\ttraining's multi_logloss: 0.0511406\ttraining's quad_kappa: 0.982573\tvalid_1's multi_logloss: 1.68796\tvalid_1's quad_kappa: 0.519125\n",
      "[1500]\ttraining's multi_logloss: 0.0440723\ttraining's quad_kappa: 0.986149\tvalid_1's multi_logloss: 1.74353\tvalid_1's quad_kappa: 0.521475\n",
      "[1600]\ttraining's multi_logloss: 0.0381694\ttraining's quad_kappa: 0.9875\tvalid_1's multi_logloss: 1.79959\tvalid_1's quad_kappa: 0.52523\n",
      "[1700]\ttraining's multi_logloss: 0.0328871\ttraining's quad_kappa: 0.98876\tvalid_1's multi_logloss: 1.85229\tvalid_1's quad_kappa: 0.523959\n",
      "[1800]\ttraining's multi_logloss: 0.0291086\ttraining's quad_kappa: 0.989353\tvalid_1's multi_logloss: 1.90634\tvalid_1's quad_kappa: 0.517829\n",
      "[1900]\ttraining's multi_logloss: 0.0256782\ttraining's quad_kappa: 0.989664\tvalid_1's multi_logloss: 1.9561\tvalid_1's quad_kappa: 0.526397\n",
      "[2000]\ttraining's multi_logloss: 0.0230429\ttraining's quad_kappa: 0.989882\tvalid_1's multi_logloss: 2.01087\tvalid_1's quad_kappa: 0.531033\n",
      "Early stopping, best iteration is:                                             \n",
      "[45]\ttraining's multi_logloss: 0.785916\ttraining's quad_kappa: 0.643052\tvalid_1's multi_logloss: 0.99955\tvalid_1's quad_kappa: 0.541865\n",
      "{'learning_rate': 0.15914838100244802, 'metric': 'multiclass', 'n_estimators': 10000, 'num_classes': 4, 'objective': 'multiclass', 'random_state': 2019}\n",
      "Training until validation scores don't improve for 2000 rounds                 \n",
      " 40%|████      | 4/10 [29:28<43:30, 435.04s/it, best loss: -0.5135357478561519]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 0.592434\ttraining's quad_kappa: 0.7499\tvalid_1's multi_logloss: 1.04044\tvalid_1's quad_kappa: 0.511691\n",
      "[200]\ttraining's multi_logloss: 0.422195\ttraining's quad_kappa: 0.837829\tvalid_1's multi_logloss: 1.09791\tvalid_1's quad_kappa: 0.497144\n",
      "[300]\ttraining's multi_logloss: 0.313857\ttraining's quad_kappa: 0.888127\tvalid_1's multi_logloss: 1.16382\tvalid_1's quad_kappa: 0.488642\n",
      "[400]\ttraining's multi_logloss: 0.243158\ttraining's quad_kappa: 0.919652\tvalid_1's multi_logloss: 1.22936\tvalid_1's quad_kappa: 0.491995\n",
      "[500]\ttraining's multi_logloss: 0.190228\ttraining's quad_kappa: 0.939117\tvalid_1's multi_logloss: 1.29917\tvalid_1's quad_kappa: 0.494315\n",
      "[600]\ttraining's multi_logloss: 0.150546\ttraining's quad_kappa: 0.952791\tvalid_1's multi_logloss: 1.37087\tvalid_1's quad_kappa: 0.498202\n",
      "[700]\ttraining's multi_logloss: 0.119731\ttraining's quad_kappa: 0.964606\tvalid_1's multi_logloss: 1.43187\tvalid_1's quad_kappa: 0.496451\n",
      "[800]\ttraining's multi_logloss: 0.0949148\ttraining's quad_kappa: 0.973016\tvalid_1's multi_logloss: 1.49497\tvalid_1's quad_kappa: 0.490901\n",
      "[900]\ttraining's multi_logloss: 0.0757207\ttraining's quad_kappa: 0.979306\tvalid_1's multi_logloss: 1.56422\tvalid_1's quad_kappa: 0.485117\n",
      "[1000]\ttraining's multi_logloss: 0.061291\ttraining's quad_kappa: 0.983671\tvalid_1's multi_logloss: 1.63693\tvalid_1's quad_kappa: 0.476739\n",
      "[1100]\ttraining's multi_logloss: 0.0497194\ttraining's quad_kappa: 0.98735\tvalid_1's multi_logloss: 1.70561\tvalid_1's quad_kappa: 0.476901\n",
      "[1200]\ttraining's multi_logloss: 0.0402675\ttraining's quad_kappa: 0.989141\tvalid_1's multi_logloss: 1.76767\tvalid_1's quad_kappa: 0.474492\n",
      "[1300]\ttraining's multi_logloss: 0.0328755\ttraining's quad_kappa: 0.991665\tvalid_1's multi_logloss: 1.84269\tvalid_1's quad_kappa: 0.464618\n",
      "[1400]\ttraining's multi_logloss: 0.0270059\ttraining's quad_kappa: 0.992658\tvalid_1's multi_logloss: 1.91525\tvalid_1's quad_kappa: 0.459751\n",
      "[1500]\ttraining's multi_logloss: 0.0230004\ttraining's quad_kappa: 0.993234\tvalid_1's multi_logloss: 1.98111\tvalid_1's quad_kappa: 0.456165\n",
      "[1600]\ttraining's multi_logloss: 0.0195657\ttraining's quad_kappa: 0.993521\tvalid_1's multi_logloss: 2.05664\tvalid_1's quad_kappa: 0.456995\n",
      "[1700]\ttraining's multi_logloss: 0.016813\ttraining's quad_kappa: 0.99352\tvalid_1's multi_logloss: 2.13127\tvalid_1's quad_kappa: 0.460881\n",
      "[1800]\ttraining's multi_logloss: 0.014798\ttraining's quad_kappa: 0.99352\tvalid_1's multi_logloss: 2.19888\tvalid_1's quad_kappa: 0.46694\n",
      "[1900]\ttraining's multi_logloss: 0.0133356\ttraining's quad_kappa: 0.993521\tvalid_1's multi_logloss: 2.27549\tvalid_1's quad_kappa: 0.458118\n",
      "[2000]\ttraining's multi_logloss: 0.0122291\ttraining's quad_kappa: 0.993521\tvalid_1's multi_logloss: 2.34546\tvalid_1's quad_kappa: 0.460538\n",
      "Early stopping, best iteration is:                                             \n",
      "[29]\ttraining's multi_logloss: 0.822024\ttraining's quad_kappa: 0.610132\tvalid_1's multi_logloss: 1.00476\tvalid_1's quad_kappa: 0.483535\n",
      "Training until validation scores don't improve for 2000 rounds                 \n",
      "[100]\ttraining's multi_logloss: 0.572143\ttraining's quad_kappa: 0.763039\tvalid_1's multi_logloss: 1.01311\tvalid_1's quad_kappa: 0.527227\n",
      "[200]\ttraining's multi_logloss: 0.405089\ttraining's quad_kappa: 0.855031\tvalid_1's multi_logloss: 1.0766\tvalid_1's quad_kappa: 0.531822\n",
      "[300]\ttraining's multi_logloss: 0.29983\ttraining's quad_kappa: 0.897839\tvalid_1's multi_logloss: 1.14316\tvalid_1's quad_kappa: 0.519802\n",
      "[400]\ttraining's multi_logloss: 0.229223\ttraining's quad_kappa: 0.923757\tvalid_1's multi_logloss: 1.2092\tvalid_1's quad_kappa: 0.521911\n",
      "[500]\ttraining's multi_logloss: 0.178758\ttraining's quad_kappa: 0.938937\tvalid_1's multi_logloss: 1.27029\tvalid_1's quad_kappa: 0.519173\n",
      "[600]\ttraining's multi_logloss: 0.14083\ttraining's quad_kappa: 0.954289\tvalid_1's multi_logloss: 1.33236\tvalid_1's quad_kappa: 0.508099\n",
      "[700]\ttraining's multi_logloss: 0.110546\ttraining's quad_kappa: 0.965267\tvalid_1's multi_logloss: 1.39641\tvalid_1's quad_kappa: 0.50431\n",
      "[800]\ttraining's multi_logloss: 0.0870225\ttraining's quad_kappa: 0.973134\tvalid_1's multi_logloss: 1.46299\tvalid_1's quad_kappa: 0.504125\n",
      "[900]\ttraining's multi_logloss: 0.0691626\ttraining's quad_kappa: 0.979186\tvalid_1's multi_logloss: 1.52827\tvalid_1's quad_kappa: 0.506503\n",
      "[1000]\ttraining's multi_logloss: 0.0554195\ttraining's quad_kappa: 0.984025\tvalid_1's multi_logloss: 1.59061\tvalid_1's quad_kappa: 0.50812\n",
      "[1100]\ttraining's multi_logloss: 0.0451337\ttraining's quad_kappa: 0.98713\tvalid_1's multi_logloss: 1.66106\tvalid_1's quad_kappa: 0.494331\n",
      "[1200]\ttraining's multi_logloss: 0.0367045\ttraining's quad_kappa: 0.989237\tvalid_1's multi_logloss: 1.72809\tvalid_1's quad_kappa: 0.496899\n",
      "[1300]\ttraining's multi_logloss: 0.0307893\ttraining's quad_kappa: 0.990149\tvalid_1's multi_logloss: 1.79971\tvalid_1's quad_kappa: 0.494479\n",
      "[1400]\ttraining's multi_logloss: 0.0260181\ttraining's quad_kappa: 0.990371\tvalid_1's multi_logloss: 1.87292\tvalid_1's quad_kappa: 0.495646\n",
      "[1500]\ttraining's multi_logloss: 0.0219372\ttraining's quad_kappa: 0.990747\tvalid_1's multi_logloss: 1.94053\tvalid_1's quad_kappa: 0.485892\n",
      "[1600]\ttraining's multi_logloss: 0.0189879\ttraining's quad_kappa: 0.990747\tvalid_1's multi_logloss: 2.0143\tvalid_1's quad_kappa: 0.482443\n",
      "[1700]\ttraining's multi_logloss: 0.0165741\ttraining's quad_kappa: 0.990775\tvalid_1's multi_logloss: 2.08657\tvalid_1's quad_kappa: 0.479428\n",
      "[1800]\ttraining's multi_logloss: 0.0148632\ttraining's quad_kappa: 0.990774\tvalid_1's multi_logloss: 2.16017\tvalid_1's quad_kappa: 0.47488\n",
      "[1900]\ttraining's multi_logloss: 0.0137037\ttraining's quad_kappa: 0.990774\tvalid_1's multi_logloss: 2.23687\tvalid_1's quad_kappa: 0.473097\n",
      "[2000]\ttraining's multi_logloss: 0.0128226\ttraining's quad_kappa: 0.990772\tvalid_1's multi_logloss: 2.31446\tvalid_1's quad_kappa: 0.476951\n",
      "Early stopping, best iteration is:                                             \n",
      "[40]\ttraining's multi_logloss: 0.750392\ttraining's quad_kappa: 0.66079\tvalid_1's multi_logloss: 0.995699\tvalid_1's quad_kappa: 0.519199\n",
      "Training until validation scores don't improve for 2000 rounds                 \n",
      "[100]\ttraining's multi_logloss: 0.589674\ttraining's quad_kappa: 0.748885\tvalid_1's multi_logloss: 1.0283\tvalid_1's quad_kappa: 0.540718\n",
      "[200]\ttraining's multi_logloss: 0.41993\ttraining's quad_kappa: 0.843281\tvalid_1's multi_logloss: 1.08728\tvalid_1's quad_kappa: 0.533527\n",
      "[300]\ttraining's multi_logloss: 0.316042\ttraining's quad_kappa: 0.884749\tvalid_1's multi_logloss: 1.15412\tvalid_1's quad_kappa: 0.531664\n",
      "[400]\ttraining's multi_logloss: 0.2417\ttraining's quad_kappa: 0.920374\tvalid_1's multi_logloss: 1.22817\tvalid_1's quad_kappa: 0.513592\n",
      "[500]\ttraining's multi_logloss: 0.188608\ttraining's quad_kappa: 0.939579\tvalid_1's multi_logloss: 1.2923\tvalid_1's quad_kappa: 0.516549\n",
      "[600]\ttraining's multi_logloss: 0.148995\ttraining's quad_kappa: 0.951603\tvalid_1's multi_logloss: 1.35705\tvalid_1's quad_kappa: 0.510094\n",
      "[700]\ttraining's multi_logloss: 0.118793\ttraining's quad_kappa: 0.963102\tvalid_1's multi_logloss: 1.42511\tvalid_1's quad_kappa: 0.513529\n",
      "[800]\ttraining's multi_logloss: 0.0965324\ttraining's quad_kappa: 0.968268\tvalid_1's multi_logloss: 1.4917\tvalid_1's quad_kappa: 0.5187\n",
      "[900]\ttraining's multi_logloss: 0.0781104\ttraining's quad_kappa: 0.975495\tvalid_1's multi_logloss: 1.55814\tvalid_1's quad_kappa: 0.514608\n",
      "[1000]\ttraining's multi_logloss: 0.0632413\ttraining's quad_kappa: 0.979489\tvalid_1's multi_logloss: 1.61651\tvalid_1's quad_kappa: 0.520626\n",
      "[1100]\ttraining's multi_logloss: 0.0512858\ttraining's quad_kappa: 0.985215\tvalid_1's multi_logloss: 1.68199\tvalid_1's quad_kappa: 0.514851\n",
      "[1200]\ttraining's multi_logloss: 0.0421716\ttraining's quad_kappa: 0.986712\tvalid_1's multi_logloss: 1.7521\tvalid_1's quad_kappa: 0.51144\n",
      "[1300]\ttraining's multi_logloss: 0.035578\ttraining's quad_kappa: 0.988\tvalid_1's multi_logloss: 1.81895\tvalid_1's quad_kappa: 0.514192\n",
      "[1400]\ttraining's multi_logloss: 0.0301498\ttraining's quad_kappa: 0.98847\tvalid_1's multi_logloss: 1.88818\tvalid_1's quad_kappa: 0.510361\n",
      "[1500]\ttraining's multi_logloss: 0.0259719\ttraining's quad_kappa: 0.98941\tvalid_1's multi_logloss: 1.95899\tvalid_1's quad_kappa: 0.520413\n",
      "[1600]\ttraining's multi_logloss: 0.0229356\ttraining's quad_kappa: 0.989884\tvalid_1's multi_logloss: 2.02213\tvalid_1's quad_kappa: 0.527086\n",
      "[1700]\ttraining's multi_logloss: 0.0204684\ttraining's quad_kappa: 0.989884\tvalid_1's multi_logloss: 2.08816\tvalid_1's quad_kappa: 0.529698\n",
      "[1800]\ttraining's multi_logloss: 0.0184073\ttraining's quad_kappa: 0.990165\tvalid_1's multi_logloss: 2.15806\tvalid_1's quad_kappa: 0.524733\n",
      "[1900]\ttraining's multi_logloss: 0.0169616\ttraining's quad_kappa: 0.990452\tvalid_1's multi_logloss: 2.23127\tvalid_1's quad_kappa: 0.512181\n",
      "[2000]\ttraining's multi_logloss: 0.0156668\ttraining's quad_kappa: 0.990542\tvalid_1's multi_logloss: 2.30114\tvalid_1's quad_kappa: 0.513634\n",
      "Early stopping, best iteration is:                                             \n",
      "[33]\ttraining's multi_logloss: 0.796696\ttraining's quad_kappa: 0.636267\tvalid_1's multi_logloss: 1.00044\tvalid_1's quad_kappa: 0.533247\n",
      "{'learning_rate': 0.056263969759595946, 'metric': 'multiclass', 'n_estimators': 10000, 'num_classes': 4, 'objective': 'multiclass', 'random_state': 2019}\n",
      "Training until validation scores don't improve for 2000 rounds                 \n",
      " 50%|█████     | 5/10 [35:33<34:29, 413.99s/it, best loss: -0.5135357478561519]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 0.79248\ttraining's quad_kappa: 0.631281\tvalid_1's multi_logloss: 0.999537\tvalid_1's quad_kappa: 0.492369\n",
      "[200]\ttraining's multi_logloss: 0.667234\ttraining's quad_kappa: 0.703744\tvalid_1's multi_logloss: 1.0121\tvalid_1's quad_kappa: 0.504933\n",
      "[300]\ttraining's multi_logloss: 0.58021\ttraining's quad_kappa: 0.755287\tvalid_1's multi_logloss: 1.02869\tvalid_1's quad_kappa: 0.518356\n",
      "[400]\ttraining's multi_logloss: 0.512652\ttraining's quad_kappa: 0.794765\tvalid_1's multi_logloss: 1.04772\tvalid_1's quad_kappa: 0.514111\n",
      "[500]\ttraining's multi_logloss: 0.456801\ttraining's quad_kappa: 0.822291\tvalid_1's multi_logloss: 1.06482\tvalid_1's quad_kappa: 0.519035\n",
      "[600]\ttraining's multi_logloss: 0.409459\ttraining's quad_kappa: 0.847716\tvalid_1's multi_logloss: 1.08946\tvalid_1's quad_kappa: 0.5153\n",
      "[700]\ttraining's multi_logloss: 0.369782\ttraining's quad_kappa: 0.864524\tvalid_1's multi_logloss: 1.11251\tvalid_1's quad_kappa: 0.518365\n",
      "[800]\ttraining's multi_logloss: 0.334682\ttraining's quad_kappa: 0.876768\tvalid_1's multi_logloss: 1.13531\tvalid_1's quad_kappa: 0.516878\n",
      "[900]\ttraining's multi_logloss: 0.304143\ttraining's quad_kappa: 0.890285\tvalid_1's multi_logloss: 1.15823\tvalid_1's quad_kappa: 0.513592\n",
      "[1000]\ttraining's multi_logloss: 0.276781\ttraining's quad_kappa: 0.901558\tvalid_1's multi_logloss: 1.17892\tvalid_1's quad_kappa: 0.517451\n",
      "[1100]\ttraining's multi_logloss: 0.252776\ttraining's quad_kappa: 0.911402\tvalid_1's multi_logloss: 1.19948\tvalid_1's quad_kappa: 0.519923\n",
      "[1200]\ttraining's multi_logloss: 0.231967\ttraining's quad_kappa: 0.922738\tvalid_1's multi_logloss: 1.22378\tvalid_1's quad_kappa: 0.512953\n",
      "[1300]\ttraining's multi_logloss: 0.213056\ttraining's quad_kappa: 0.92904\tvalid_1's multi_logloss: 1.24949\tvalid_1's quad_kappa: 0.508216\n",
      "[1400]\ttraining's multi_logloss: 0.196326\ttraining's quad_kappa: 0.934823\tvalid_1's multi_logloss: 1.27153\tvalid_1's quad_kappa: 0.499225\n",
      "[1500]\ttraining's multi_logloss: 0.181495\ttraining's quad_kappa: 0.941752\tvalid_1's multi_logloss: 1.29617\tvalid_1's quad_kappa: 0.49633\n",
      "[1600]\ttraining's multi_logloss: 0.167335\ttraining's quad_kappa: 0.947524\tvalid_1's multi_logloss: 1.31773\tvalid_1's quad_kappa: 0.496139\n",
      "[1700]\ttraining's multi_logloss: 0.154023\ttraining's quad_kappa: 0.952174\tvalid_1's multi_logloss: 1.33971\tvalid_1's quad_kappa: 0.491548\n",
      "[1800]\ttraining's multi_logloss: 0.142115\ttraining's quad_kappa: 0.956207\tvalid_1's multi_logloss: 1.36156\tvalid_1's quad_kappa: 0.490958\n",
      "[1900]\ttraining's multi_logloss: 0.131471\ttraining's quad_kappa: 0.95837\tvalid_1's multi_logloss: 1.384\tvalid_1's quad_kappa: 0.493712\n",
      "[2000]\ttraining's multi_logloss: 0.121215\ttraining's quad_kappa: 0.963274\tvalid_1's multi_logloss: 1.40675\tvalid_1's quad_kappa: 0.491748\n",
      "Early stopping, best iteration is:                                             \n",
      "[99]\ttraining's multi_logloss: 0.794141\ttraining's quad_kappa: 0.630008\tvalid_1's multi_logloss: 0.99937\tvalid_1's quad_kappa: 0.490302\n",
      "Training until validation scores don't improve for 2000 rounds                 \n",
      "[100]\ttraining's multi_logloss: 0.771858\ttraining's quad_kappa: 0.649467\tvalid_1's multi_logloss: 0.99745\tvalid_1's quad_kappa: 0.515662\n",
      "[200]\ttraining's multi_logloss: 0.647626\ttraining's quad_kappa: 0.720682\tvalid_1's multi_logloss: 0.999334\tvalid_1's quad_kappa: 0.521865\n",
      "[300]\ttraining's multi_logloss: 0.560206\ttraining's quad_kappa: 0.765595\tvalid_1's multi_logloss: 1.01347\tvalid_1's quad_kappa: 0.522662\n",
      "[400]\ttraining's multi_logloss: 0.492401\ttraining's quad_kappa: 0.806137\tvalid_1's multi_logloss: 1.03369\tvalid_1's quad_kappa: 0.524328\n",
      "[500]\ttraining's multi_logloss: 0.437766\ttraining's quad_kappa: 0.839611\tvalid_1's multi_logloss: 1.05491\tvalid_1's quad_kappa: 0.525757\n",
      "[600]\ttraining's multi_logloss: 0.391526\ttraining's quad_kappa: 0.863553\tvalid_1's multi_logloss: 1.07697\tvalid_1's quad_kappa: 0.525578\n",
      "[700]\ttraining's multi_logloss: 0.352887\ttraining's quad_kappa: 0.87815\tvalid_1's multi_logloss: 1.09949\tvalid_1's quad_kappa: 0.519462\n",
      "[800]\ttraining's multi_logloss: 0.317547\ttraining's quad_kappa: 0.890981\tvalid_1's multi_logloss: 1.12113\tvalid_1's quad_kappa: 0.5177\n",
      "[900]\ttraining's multi_logloss: 0.288419\ttraining's quad_kappa: 0.901624\tvalid_1's multi_logloss: 1.14206\tvalid_1's quad_kappa: 0.518129\n",
      "[1000]\ttraining's multi_logloss: 0.263189\ttraining's quad_kappa: 0.91238\tvalid_1's multi_logloss: 1.16515\tvalid_1's quad_kappa: 0.51699\n",
      "[1100]\ttraining's multi_logloss: 0.239718\ttraining's quad_kappa: 0.919978\tvalid_1's multi_logloss: 1.18717\tvalid_1's quad_kappa: 0.524384\n",
      "[1200]\ttraining's multi_logloss: 0.219363\ttraining's quad_kappa: 0.928321\tvalid_1's multi_logloss: 1.21132\tvalid_1's quad_kappa: 0.524654\n",
      "[1300]\ttraining's multi_logloss: 0.200502\ttraining's quad_kappa: 0.936481\tvalid_1's multi_logloss: 1.23367\tvalid_1's quad_kappa: 0.521514\n",
      "[1400]\ttraining's multi_logloss: 0.184096\ttraining's quad_kappa: 0.940482\tvalid_1's multi_logloss: 1.25728\tvalid_1's quad_kappa: 0.519227\n",
      "[1500]\ttraining's multi_logloss: 0.168342\ttraining's quad_kappa: 0.944484\tvalid_1's multi_logloss: 1.27979\tvalid_1's quad_kappa: 0.517717\n",
      "[1600]\ttraining's multi_logloss: 0.154935\ttraining's quad_kappa: 0.949729\tvalid_1's multi_logloss: 1.3035\tvalid_1's quad_kappa: 0.510251\n",
      "[1700]\ttraining's multi_logloss: 0.14244\ttraining's quad_kappa: 0.953897\tvalid_1's multi_logloss: 1.32439\tvalid_1's quad_kappa: 0.509396\n",
      "[1800]\ttraining's multi_logloss: 0.130894\ttraining's quad_kappa: 0.959607\tvalid_1's multi_logloss: 1.34508\tvalid_1's quad_kappa: 0.512966\n",
      "[1900]\ttraining's multi_logloss: 0.121084\ttraining's quad_kappa: 0.962743\tvalid_1's multi_logloss: 1.37006\tvalid_1's quad_kappa: 0.510903\n",
      "[2000]\ttraining's multi_logloss: 0.1119\ttraining's quad_kappa: 0.967209\tvalid_1's multi_logloss: 1.3945\tvalid_1's quad_kappa: 0.50906\n",
      "[2100]\ttraining's multi_logloss: 0.103077\ttraining's quad_kappa: 0.969239\tvalid_1's multi_logloss: 1.41715\tvalid_1's quad_kappa: 0.503768\n",
      "Early stopping, best iteration is:                                             \n",
      "[138]\ttraining's multi_logloss: 0.717449\ttraining's quad_kappa: 0.677751\tvalid_1's multi_logloss: 0.996114\tvalid_1's quad_kappa: 0.523745\n",
      "Training until validation scores don't improve for 2000 rounds                 \n",
      "[100]\ttraining's multi_logloss: 0.787345\ttraining's quad_kappa: 0.640399\tvalid_1's multi_logloss: 0.997572\tvalid_1's quad_kappa: 0.542076\n",
      "[200]\ttraining's multi_logloss: 0.663251\ttraining's quad_kappa: 0.707931\tvalid_1's multi_logloss: 1.00398\tvalid_1's quad_kappa: 0.551318\n",
      "[300]\ttraining's multi_logloss: 0.57786\ttraining's quad_kappa: 0.761563\tvalid_1's multi_logloss: 1.02224\tvalid_1's quad_kappa: 0.544348\n",
      "[400]\ttraining's multi_logloss: 0.509923\ttraining's quad_kappa: 0.797148\tvalid_1's multi_logloss: 1.04198\tvalid_1's quad_kappa: 0.538563\n",
      "[500]\ttraining's multi_logloss: 0.454033\ttraining's quad_kappa: 0.827266\tvalid_1's multi_logloss: 1.06206\tvalid_1's quad_kappa: 0.531588\n",
      "[600]\ttraining's multi_logloss: 0.406822\ttraining's quad_kappa: 0.849542\tvalid_1's multi_logloss: 1.08271\tvalid_1's quad_kappa: 0.524319\n",
      "[700]\ttraining's multi_logloss: 0.368954\ttraining's quad_kappa: 0.868069\tvalid_1's multi_logloss: 1.10395\tvalid_1's quad_kappa: 0.525157\n",
      "[800]\ttraining's multi_logloss: 0.335836\ttraining's quad_kappa: 0.879336\tvalid_1's multi_logloss: 1.12804\tvalid_1's quad_kappa: 0.535126\n",
      "[900]\ttraining's multi_logloss: 0.306067\ttraining's quad_kappa: 0.89054\tvalid_1's multi_logloss: 1.15435\tvalid_1's quad_kappa: 0.539809\n",
      "[1000]\ttraining's multi_logloss: 0.279047\ttraining's quad_kappa: 0.902736\tvalid_1's multi_logloss: 1.17974\tvalid_1's quad_kappa: 0.534388\n",
      "[1100]\ttraining's multi_logloss: 0.254361\ttraining's quad_kappa: 0.91157\tvalid_1's multi_logloss: 1.20332\tvalid_1's quad_kappa: 0.535204\n",
      "[1200]\ttraining's multi_logloss: 0.231685\ttraining's quad_kappa: 0.921426\tvalid_1's multi_logloss: 1.22531\tvalid_1's quad_kappa: 0.530802\n",
      "[1300]\ttraining's multi_logloss: 0.212445\ttraining's quad_kappa: 0.929779\tvalid_1's multi_logloss: 1.24922\tvalid_1's quad_kappa: 0.534605\n",
      "[1400]\ttraining's multi_logloss: 0.195376\ttraining's quad_kappa: 0.934799\tvalid_1's multi_logloss: 1.27241\tvalid_1's quad_kappa: 0.530732\n",
      "[1500]\ttraining's multi_logloss: 0.179624\ttraining's quad_kappa: 0.940566\tvalid_1's multi_logloss: 1.29548\tvalid_1's quad_kappa: 0.534946\n",
      "[1600]\ttraining's multi_logloss: 0.164225\ttraining's quad_kappa: 0.947643\tvalid_1's multi_logloss: 1.31801\tvalid_1's quad_kappa: 0.533304\n",
      "[1700]\ttraining's multi_logloss: 0.151733\ttraining's quad_kappa: 0.953689\tvalid_1's multi_logloss: 1.34222\tvalid_1's quad_kappa: 0.5303\n",
      "[1800]\ttraining's multi_logloss: 0.139876\ttraining's quad_kappa: 0.957146\tvalid_1's multi_logloss: 1.3654\tvalid_1's quad_kappa: 0.533472\n",
      "[1900]\ttraining's multi_logloss: 0.12933\ttraining's quad_kappa: 0.960545\tvalid_1's multi_logloss: 1.38912\tvalid_1's quad_kappa: 0.533241\n",
      "[2000]\ttraining's multi_logloss: 0.119795\ttraining's quad_kappa: 0.961756\tvalid_1's multi_logloss: 1.41539\tvalid_1's quad_kappa: 0.525886\n",
      "[2100]\ttraining's multi_logloss: 0.110927\ttraining's quad_kappa: 0.964847\tvalid_1's multi_logloss: 1.4391\tvalid_1's quad_kappa: 0.52977\n",
      "Early stopping, best iteration is:                                             \n",
      "[109]\ttraining's multi_logloss: 0.773019\ttraining's quad_kappa: 0.649042\tvalid_1's multi_logloss: 0.997075\tvalid_1's quad_kappa: 0.541646\n",
      "{'learning_rate': 0.005163921358243677, 'metric': 'multiclass', 'n_estimators': 10000, 'num_classes': 4, 'objective': 'multiclass', 'random_state': 2019}\n",
      "Training until validation scores don't improve for 2000 rounds                 \n",
      " 60%|██████    | 6/10 [41:50<26:51, 402.93s/it, best loss: -0.5135357478561519]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 1.09328\ttraining's quad_kappa: 0.326405\tvalid_1's multi_logloss: 1.10866\tvalid_1's quad_kappa: 0.309696\n",
      "[200]\ttraining's multi_logloss: 1.02238\ttraining's quad_kappa: 0.468732\tvalid_1's multi_logloss: 1.06259\tvalid_1's quad_kappa: 0.44251\n",
      "[300]\ttraining's multi_logloss: 0.974481\ttraining's quad_kappa: 0.512989\tvalid_1's multi_logloss: 1.03884\tvalid_1's quad_kappa: 0.467918\n",
      "[400]\ttraining's multi_logloss: 0.937577\ttraining's quad_kappa: 0.53579\tvalid_1's multi_logloss: 1.02416\tvalid_1's quad_kappa: 0.475935\n",
      "[500]\ttraining's multi_logloss: 0.908467\ttraining's quad_kappa: 0.552831\tvalid_1's multi_logloss: 1.01503\tvalid_1's quad_kappa: 0.472228\n",
      "[600]\ttraining's multi_logloss: 0.883851\ttraining's quad_kappa: 0.570157\tvalid_1's multi_logloss: 1.00935\tvalid_1's quad_kappa: 0.474357\n",
      "[700]\ttraining's multi_logloss: 0.862393\ttraining's quad_kappa: 0.586409\tvalid_1's multi_logloss: 1.0051\tvalid_1's quad_kappa: 0.475931\n",
      "[800]\ttraining's multi_logloss: 0.842884\ttraining's quad_kappa: 0.597369\tvalid_1's multi_logloss: 1.00254\tvalid_1's quad_kappa: 0.484738\n",
      "[900]\ttraining's multi_logloss: 0.825425\ttraining's quad_kappa: 0.61078\tvalid_1's multi_logloss: 1.00127\tvalid_1's quad_kappa: 0.48685\n",
      "[1000]\ttraining's multi_logloss: 0.808663\ttraining's quad_kappa: 0.62169\tvalid_1's multi_logloss: 1.00056\tvalid_1's quad_kappa: 0.489129\n",
      "[1100]\ttraining's multi_logloss: 0.793253\ttraining's quad_kappa: 0.629243\tvalid_1's multi_logloss: 0.999871\tvalid_1's quad_kappa: 0.487667\n",
      "[1200]\ttraining's multi_logloss: 0.779092\ttraining's quad_kappa: 0.637847\tvalid_1's multi_logloss: 1.00049\tvalid_1's quad_kappa: 0.484713\n",
      "[1300]\ttraining's multi_logloss: 0.76597\ttraining's quad_kappa: 0.645416\tvalid_1's multi_logloss: 1.00085\tvalid_1's quad_kappa: 0.481977\n",
      "[1400]\ttraining's multi_logloss: 0.753208\ttraining's quad_kappa: 0.652125\tvalid_1's multi_logloss: 1.0013\tvalid_1's quad_kappa: 0.479372\n",
      "[1500]\ttraining's multi_logloss: 0.741262\ttraining's quad_kappa: 0.660279\tvalid_1's multi_logloss: 1.00183\tvalid_1's quad_kappa: 0.480993\n",
      "[1600]\ttraining's multi_logloss: 0.729866\ttraining's quad_kappa: 0.66881\tvalid_1's multi_logloss: 1.00249\tvalid_1's quad_kappa: 0.485548\n",
      "[1700]\ttraining's multi_logloss: 0.718839\ttraining's quad_kappa: 0.673915\tvalid_1's multi_logloss: 1.00309\tvalid_1's quad_kappa: 0.487333\n",
      "[1800]\ttraining's multi_logloss: 0.70821\ttraining's quad_kappa: 0.678653\tvalid_1's multi_logloss: 1.00377\tvalid_1's quad_kappa: 0.49085\n",
      "[1900]\ttraining's multi_logloss: 0.697673\ttraining's quad_kappa: 0.685268\tvalid_1's multi_logloss: 1.00463\tvalid_1's quad_kappa: 0.49019\n",
      "[2000]\ttraining's multi_logloss: 0.687431\ttraining's quad_kappa: 0.692581\tvalid_1's multi_logloss: 1.00532\tvalid_1's quad_kappa: 0.493297\n",
      "[2100]\ttraining's multi_logloss: 0.677624\ttraining's quad_kappa: 0.699664\tvalid_1's multi_logloss: 1.00612\tvalid_1's quad_kappa: 0.494122\n",
      "[2200]\ttraining's multi_logloss: 0.668219\ttraining's quad_kappa: 0.704302\tvalid_1's multi_logloss: 1.00733\tvalid_1's quad_kappa: 0.493209\n",
      "[2300]\ttraining's multi_logloss: 0.659158\ttraining's quad_kappa: 0.710555\tvalid_1's multi_logloss: 1.00852\tvalid_1's quad_kappa: 0.488686\n",
      "[2400]\ttraining's multi_logloss: 0.650381\ttraining's quad_kappa: 0.716851\tvalid_1's multi_logloss: 1.0099\tvalid_1's quad_kappa: 0.492962\n",
      "[2500]\ttraining's multi_logloss: 0.641763\ttraining's quad_kappa: 0.721342\tvalid_1's multi_logloss: 1.01124\tvalid_1's quad_kappa: 0.493425\n",
      "[2600]\ttraining's multi_logloss: 0.633456\ttraining's quad_kappa: 0.72475\tvalid_1's multi_logloss: 1.01268\tvalid_1's quad_kappa: 0.498418\n",
      "[2700]\ttraining's multi_logloss: 0.625323\ttraining's quad_kappa: 0.731815\tvalid_1's multi_logloss: 1.01433\tvalid_1's quad_kappa: 0.497348\n",
      "[2800]\ttraining's multi_logloss: 0.617284\ttraining's quad_kappa: 0.736434\tvalid_1's multi_logloss: 1.01593\tvalid_1's quad_kappa: 0.499134\n",
      "[2900]\ttraining's multi_logloss: 0.609637\ttraining's quad_kappa: 0.742433\tvalid_1's multi_logloss: 1.01763\tvalid_1's quad_kappa: 0.499196\n",
      "[3000]\ttraining's multi_logloss: 0.602023\ttraining's quad_kappa: 0.7463\tvalid_1's multi_logloss: 1.01916\tvalid_1's quad_kappa: 0.502332\n",
      "Early stopping, best iteration is:                                             \n",
      "[1072]\ttraining's multi_logloss: 0.797424\ttraining's quad_kappa: 0.626203\tvalid_1's multi_logloss: 0.999748\tvalid_1's quad_kappa: 0.488083\n",
      "Training until validation scores don't improve for 2000 rounds                 \n",
      "[100]\ttraining's multi_logloss: 1.08023\ttraining's quad_kappa: 0.33016\tvalid_1's multi_logloss: 1.11059\tvalid_1's quad_kappa: 0.314694\n",
      "[200]\ttraining's multi_logloss: 1.00525\ttraining's quad_kappa: 0.493371\tvalid_1's multi_logloss: 1.06206\tvalid_1's quad_kappa: 0.432006\n",
      "[300]\ttraining's multi_logloss: 0.956294\ttraining's quad_kappa: 0.542443\tvalid_1's multi_logloss: 1.03814\tvalid_1's quad_kappa: 0.473396\n",
      "[400]\ttraining's multi_logloss: 0.919633\ttraining's quad_kappa: 0.561663\tvalid_1's multi_logloss: 1.02366\tvalid_1's quad_kappa: 0.48094\n",
      "[500]\ttraining's multi_logloss: 0.889448\ttraining's quad_kappa: 0.583539\tvalid_1's multi_logloss: 1.01351\tvalid_1's quad_kappa: 0.500969\n",
      "[600]\ttraining's multi_logloss: 0.863876\ttraining's quad_kappa: 0.599011\tvalid_1's multi_logloss: 1.00701\tvalid_1's quad_kappa: 0.504677\n",
      "[700]\ttraining's multi_logloss: 0.841823\ttraining's quad_kappa: 0.611284\tvalid_1's multi_logloss: 1.00337\tvalid_1's quad_kappa: 0.511417\n",
      "[800]\ttraining's multi_logloss: 0.821954\ttraining's quad_kappa: 0.623141\tvalid_1's multi_logloss: 1.00101\tvalid_1's quad_kappa: 0.516052\n",
      "[900]\ttraining's multi_logloss: 0.803984\ttraining's quad_kappa: 0.631905\tvalid_1's multi_logloss: 0.998528\tvalid_1's quad_kappa: 0.508186\n",
      "[1000]\ttraining's multi_logloss: 0.787732\ttraining's quad_kappa: 0.640414\tvalid_1's multi_logloss: 0.996343\tvalid_1's quad_kappa: 0.510777\n",
      "[1100]\ttraining's multi_logloss: 0.772661\ttraining's quad_kappa: 0.650863\tvalid_1's multi_logloss: 0.995101\tvalid_1's quad_kappa: 0.517396\n",
      "[1200]\ttraining's multi_logloss: 0.758657\ttraining's quad_kappa: 0.658462\tvalid_1's multi_logloss: 0.995443\tvalid_1's quad_kappa: 0.52149\n",
      "[1300]\ttraining's multi_logloss: 0.745527\ttraining's quad_kappa: 0.667408\tvalid_1's multi_logloss: 0.99543\tvalid_1's quad_kappa: 0.520936\n",
      "[1400]\ttraining's multi_logloss: 0.73306\ttraining's quad_kappa: 0.6724\tvalid_1's multi_logloss: 0.995439\tvalid_1's quad_kappa: 0.522732\n",
      "[1500]\ttraining's multi_logloss: 0.720988\ttraining's quad_kappa: 0.681902\tvalid_1's multi_logloss: 0.995612\tvalid_1's quad_kappa: 0.525607\n",
      "[1600]\ttraining's multi_logloss: 0.709686\ttraining's quad_kappa: 0.688039\tvalid_1's multi_logloss: 0.995927\tvalid_1's quad_kappa: 0.522689\n",
      "[1700]\ttraining's multi_logloss: 0.698939\ttraining's quad_kappa: 0.693356\tvalid_1's multi_logloss: 0.996063\tvalid_1's quad_kappa: 0.525207\n",
      "[1800]\ttraining's multi_logloss: 0.687801\ttraining's quad_kappa: 0.700514\tvalid_1's multi_logloss: 0.996621\tvalid_1's quad_kappa: 0.521099\n",
      "[1900]\ttraining's multi_logloss: 0.677074\ttraining's quad_kappa: 0.704666\tvalid_1's multi_logloss: 0.997681\tvalid_1's quad_kappa: 0.524808\n",
      "[2000]\ttraining's multi_logloss: 0.667047\ttraining's quad_kappa: 0.711677\tvalid_1's multi_logloss: 0.998817\tvalid_1's quad_kappa: 0.523458\n",
      "[2100]\ttraining's multi_logloss: 0.657455\ttraining's quad_kappa: 0.715692\tvalid_1's multi_logloss: 0.999857\tvalid_1's quad_kappa: 0.524769\n",
      "[2200]\ttraining's multi_logloss: 0.648231\ttraining's quad_kappa: 0.719758\tvalid_1's multi_logloss: 1.00092\tvalid_1's quad_kappa: 0.528101\n",
      "[2300]\ttraining's multi_logloss: 0.639265\ttraining's quad_kappa: 0.72627\tvalid_1's multi_logloss: 1.00184\tvalid_1's quad_kappa: 0.529937\n",
      "[2400]\ttraining's multi_logloss: 0.630643\ttraining's quad_kappa: 0.73078\tvalid_1's multi_logloss: 1.00285\tvalid_1's quad_kappa: 0.530802\n",
      "[2500]\ttraining's multi_logloss: 0.62234\ttraining's quad_kappa: 0.73443\tvalid_1's multi_logloss: 1.00445\tvalid_1's quad_kappa: 0.53096\n",
      "[2600]\ttraining's multi_logloss: 0.614094\ttraining's quad_kappa: 0.740278\tvalid_1's multi_logloss: 1.00641\tvalid_1's quad_kappa: 0.528857\n",
      "[2700]\ttraining's multi_logloss: 0.606139\ttraining's quad_kappa: 0.7439\tvalid_1's multi_logloss: 1.00833\tvalid_1's quad_kappa: 0.528455\n",
      "[2800]\ttraining's multi_logloss: 0.598546\ttraining's quad_kappa: 0.747024\tvalid_1's multi_logloss: 1.01014\tvalid_1's quad_kappa: 0.531381\n",
      "[2900]\ttraining's multi_logloss: 0.590812\ttraining's quad_kappa: 0.75179\tvalid_1's multi_logloss: 1.01185\tvalid_1's quad_kappa: 0.529274\n",
      "[3000]\ttraining's multi_logloss: 0.583474\ttraining's quad_kappa: 0.757611\tvalid_1's multi_logloss: 1.01325\tvalid_1's quad_kappa: 0.527882\n",
      "[3100]\ttraining's multi_logloss: 0.576179\ttraining's quad_kappa: 0.760562\tvalid_1's multi_logloss: 1.01429\tvalid_1's quad_kappa: 0.524233\n",
      "Early stopping, best iteration is:                                             \n",
      "[1101]\ttraining's multi_logloss: 0.772493\ttraining's quad_kappa: 0.651687\tvalid_1's multi_logloss: 0.995076\tvalid_1's quad_kappa: 0.51677\n",
      "Training until validation scores don't improve for 2000 rounds                 \n",
      "[100]\ttraining's multi_logloss: 1.09743\ttraining's quad_kappa: 0.319957\tvalid_1's multi_logloss: 1.1267\tvalid_1's quad_kappa: 0.306481\n",
      "[200]\ttraining's multi_logloss: 1.02325\ttraining's quad_kappa: 0.486701\tvalid_1's multi_logloss: 1.0752\tvalid_1's quad_kappa: 0.453956\n",
      "[300]\ttraining's multi_logloss: 0.97393\ttraining's quad_kappa: 0.530451\tvalid_1's multi_logloss: 1.04673\tvalid_1's quad_kappa: 0.492593\n",
      "[400]\ttraining's multi_logloss: 0.936845\ttraining's quad_kappa: 0.547544\tvalid_1's multi_logloss: 1.02932\tvalid_1's quad_kappa: 0.503818\n",
      "[500]\ttraining's multi_logloss: 0.906159\ttraining's quad_kappa: 0.568112\tvalid_1's multi_logloss: 1.018\tvalid_1's quad_kappa: 0.524469\n",
      "[600]\ttraining's multi_logloss: 0.880222\ttraining's quad_kappa: 0.584459\tvalid_1's multi_logloss: 1.01089\tvalid_1's quad_kappa: 0.533147\n",
      "[700]\ttraining's multi_logloss: 0.858078\ttraining's quad_kappa: 0.599079\tvalid_1's multi_logloss: 1.00675\tvalid_1's quad_kappa: 0.532207\n",
      "[800]\ttraining's multi_logloss: 0.83808\ttraining's quad_kappa: 0.612293\tvalid_1's multi_logloss: 1.00303\tvalid_1's quad_kappa: 0.533046\n",
      "[900]\ttraining's multi_logloss: 0.81996\ttraining's quad_kappa: 0.621242\tvalid_1's multi_logloss: 0.999936\tvalid_1's quad_kappa: 0.533023\n",
      "[1000]\ttraining's multi_logloss: 0.803425\ttraining's quad_kappa: 0.63178\tvalid_1's multi_logloss: 0.998331\tvalid_1's quad_kappa: 0.533619\n",
      "[1100]\ttraining's multi_logloss: 0.788054\ttraining's quad_kappa: 0.640981\tvalid_1's multi_logloss: 0.997267\tvalid_1's quad_kappa: 0.538464\n",
      "[1200]\ttraining's multi_logloss: 0.77366\ttraining's quad_kappa: 0.64949\tvalid_1's multi_logloss: 0.996978\tvalid_1's quad_kappa: 0.540579\n",
      "[1300]\ttraining's multi_logloss: 0.760414\ttraining's quad_kappa: 0.657507\tvalid_1's multi_logloss: 0.996925\tvalid_1's quad_kappa: 0.54076\n",
      "[1400]\ttraining's multi_logloss: 0.747757\ttraining's quad_kappa: 0.665059\tvalid_1's multi_logloss: 0.997113\tvalid_1's quad_kappa: 0.53877\n",
      "[1500]\ttraining's multi_logloss: 0.735848\ttraining's quad_kappa: 0.67082\tvalid_1's multi_logloss: 0.996751\tvalid_1's quad_kappa: 0.542221\n",
      "[1600]\ttraining's multi_logloss: 0.724363\ttraining's quad_kappa: 0.677388\tvalid_1's multi_logloss: 0.996932\tvalid_1's quad_kappa: 0.541474\n",
      "[1700]\ttraining's multi_logloss: 0.713562\ttraining's quad_kappa: 0.682693\tvalid_1's multi_logloss: 0.997838\tvalid_1's quad_kappa: 0.543229\n",
      "[1800]\ttraining's multi_logloss: 0.702786\ttraining's quad_kappa: 0.689989\tvalid_1's multi_logloss: 0.99836\tvalid_1's quad_kappa: 0.541365\n",
      "[1900]\ttraining's multi_logloss: 0.692475\ttraining's quad_kappa: 0.696225\tvalid_1's multi_logloss: 0.998966\tvalid_1's quad_kappa: 0.540945\n",
      "[2000]\ttraining's multi_logloss: 0.682547\ttraining's quad_kappa: 0.702022\tvalid_1's multi_logloss: 0.999906\tvalid_1's quad_kappa: 0.544239\n",
      "[2100]\ttraining's multi_logloss: 0.673014\ttraining's quad_kappa: 0.707921\tvalid_1's multi_logloss: 1.00091\tvalid_1's quad_kappa: 0.541914\n",
      "[2200]\ttraining's multi_logloss: 0.664107\ttraining's quad_kappa: 0.713287\tvalid_1's multi_logloss: 1.00217\tvalid_1's quad_kappa: 0.540266\n",
      "[2300]\ttraining's multi_logloss: 0.655309\ttraining's quad_kappa: 0.716897\tvalid_1's multi_logloss: 1.00385\tvalid_1's quad_kappa: 0.536306\n",
      "[2400]\ttraining's multi_logloss: 0.64657\ttraining's quad_kappa: 0.721849\tvalid_1's multi_logloss: 1.00532\tvalid_1's quad_kappa: 0.535882\n",
      "[2500]\ttraining's multi_logloss: 0.638161\ttraining's quad_kappa: 0.727058\tvalid_1's multi_logloss: 1.00675\tvalid_1's quad_kappa: 0.538148\n",
      "[2600]\ttraining's multi_logloss: 0.629968\ttraining's quad_kappa: 0.73165\tvalid_1's multi_logloss: 1.00809\tvalid_1's quad_kappa: 0.535105\n",
      "[2700]\ttraining's multi_logloss: 0.621922\ttraining's quad_kappa: 0.73688\tvalid_1's multi_logloss: 1.00932\tvalid_1's quad_kappa: 0.534592\n",
      "[2800]\ttraining's multi_logloss: 0.61403\ttraining's quad_kappa: 0.740322\tvalid_1's multi_logloss: 1.0108\tvalid_1's quad_kappa: 0.537109\n",
      "[2900]\ttraining's multi_logloss: 0.606224\ttraining's quad_kappa: 0.745828\tvalid_1's multi_logloss: 1.01274\tvalid_1's quad_kappa: 0.536978\n",
      "[3000]\ttraining's multi_logloss: 0.598971\ttraining's quad_kappa: 0.749251\tvalid_1's multi_logloss: 1.01504\tvalid_1's quad_kappa: 0.535747\n",
      "[3100]\ttraining's multi_logloss: 0.592039\ttraining's quad_kappa: 0.752497\tvalid_1's multi_logloss: 1.01728\tvalid_1's quad_kappa: 0.534694\n",
      "Early stopping, best iteration is:                                             \n",
      "[1166]\ttraining's multi_logloss: 0.77845\ttraining's quad_kappa: 0.645934\tvalid_1's multi_logloss: 0.997217\tvalid_1's quad_kappa: 0.544868\n",
      "{'learning_rate': 0.008386505955168762, 'metric': 'multiclass', 'n_estimators': 10000, 'num_classes': 4, 'objective': 'multiclass', 'random_state': 2019}\n",
      "Training until validation scores don't improve for 2000 rounds                 \n",
      " 70%|███████   | 7/10 [51:54<23:09, 463.21s/it, best loss: -0.5135357478561519]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 1.04515\ttraining's quad_kappa: 0.448744\tvalid_1's multi_logloss: 1.07619\tvalid_1's quad_kappa: 0.416204\n",
      "[200]\ttraining's multi_logloss: 0.964202\ttraining's quad_kappa: 0.52109\tvalid_1's multi_logloss: 1.03421\tvalid_1's quad_kappa: 0.468937\n",
      "[300]\ttraining's multi_logloss: 0.911737\ttraining's quad_kappa: 0.552337\tvalid_1's multi_logloss: 1.01561\tvalid_1's quad_kappa: 0.477253\n",
      "[400]\ttraining's multi_logloss: 0.872954\ttraining's quad_kappa: 0.5786\tvalid_1's multi_logloss: 1.00749\tvalid_1's quad_kappa: 0.483857\n",
      "[500]\ttraining's multi_logloss: 0.84046\ttraining's quad_kappa: 0.598185\tvalid_1's multi_logloss: 1.00223\tvalid_1's quad_kappa: 0.485568\n",
      "[600]\ttraining's multi_logloss: 0.812715\ttraining's quad_kappa: 0.618495\tvalid_1's multi_logloss: 1.00032\tvalid_1's quad_kappa: 0.48859\n",
      "[700]\ttraining's multi_logloss: 0.787544\ttraining's quad_kappa: 0.633967\tvalid_1's multi_logloss: 0.999232\tvalid_1's quad_kappa: 0.486417\n",
      "[800]\ttraining's multi_logloss: 0.765142\ttraining's quad_kappa: 0.643952\tvalid_1's multi_logloss: 0.999552\tvalid_1's quad_kappa: 0.48373\n",
      "[900]\ttraining's multi_logloss: 0.744685\ttraining's quad_kappa: 0.656261\tvalid_1's multi_logloss: 1.00098\tvalid_1's quad_kappa: 0.483035\n",
      "[1000]\ttraining's multi_logloss: 0.726231\ttraining's quad_kappa: 0.668644\tvalid_1's multi_logloss: 1.00239\tvalid_1's quad_kappa: 0.485492\n",
      "[1100]\ttraining's multi_logloss: 0.708792\ttraining's quad_kappa: 0.67925\tvalid_1's multi_logloss: 1.00412\tvalid_1's quad_kappa: 0.491417\n",
      "[1200]\ttraining's multi_logloss: 0.692099\ttraining's quad_kappa: 0.688285\tvalid_1's multi_logloss: 1.00647\tvalid_1's quad_kappa: 0.495949\n",
      "[1300]\ttraining's multi_logloss: 0.675973\ttraining's quad_kappa: 0.699178\tvalid_1's multi_logloss: 1.00916\tvalid_1's quad_kappa: 0.49565\n",
      "[1400]\ttraining's multi_logloss: 0.660579\ttraining's quad_kappa: 0.70871\tvalid_1's multi_logloss: 1.01142\tvalid_1's quad_kappa: 0.498002\n",
      "[1500]\ttraining's multi_logloss: 0.646321\ttraining's quad_kappa: 0.718007\tvalid_1's multi_logloss: 1.01335\tvalid_1's quad_kappa: 0.502885\n",
      "[1600]\ttraining's multi_logloss: 0.632514\ttraining's quad_kappa: 0.727104\tvalid_1's multi_logloss: 1.01561\tvalid_1's quad_kappa: 0.499966\n",
      "[1700]\ttraining's multi_logloss: 0.619371\ttraining's quad_kappa: 0.733202\tvalid_1's multi_logloss: 1.01809\tvalid_1's quad_kappa: 0.503012\n",
      "[1800]\ttraining's multi_logloss: 0.606872\ttraining's quad_kappa: 0.740641\tvalid_1's multi_logloss: 1.0207\tvalid_1's quad_kappa: 0.506516\n",
      "[1900]\ttraining's multi_logloss: 0.59471\ttraining's quad_kappa: 0.747298\tvalid_1's multi_logloss: 1.02267\tvalid_1's quad_kappa: 0.506046\n",
      "[2000]\ttraining's multi_logloss: 0.583453\ttraining's quad_kappa: 0.753818\tvalid_1's multi_logloss: 1.02556\tvalid_1's quad_kappa: 0.509156\n",
      "[2100]\ttraining's multi_logloss: 0.572279\ttraining's quad_kappa: 0.760003\tvalid_1's multi_logloss: 1.02834\tvalid_1's quad_kappa: 0.510858\n",
      "[2200]\ttraining's multi_logloss: 0.562055\ttraining's quad_kappa: 0.767941\tvalid_1's multi_logloss: 1.03113\tvalid_1's quad_kappa: 0.508462\n",
      "[2300]\ttraining's multi_logloss: 0.55189\ttraining's quad_kappa: 0.773134\tvalid_1's multi_logloss: 1.03405\tvalid_1's quad_kappa: 0.505848\n",
      "[2400]\ttraining's multi_logloss: 0.541791\ttraining's quad_kappa: 0.778005\tvalid_1's multi_logloss: 1.03735\tvalid_1's quad_kappa: 0.507903\n",
      "[2500]\ttraining's multi_logloss: 0.532334\ttraining's quad_kappa: 0.784373\tvalid_1's multi_logloss: 1.04081\tvalid_1's quad_kappa: 0.506695\n",
      "[2600]\ttraining's multi_logloss: 0.522737\ttraining's quad_kappa: 0.786962\tvalid_1's multi_logloss: 1.04422\tvalid_1's quad_kappa: 0.509328\n",
      "Early stopping, best iteration is:                                             \n",
      "[687]\ttraining's multi_logloss: 0.790646\ttraining's quad_kappa: 0.632256\tvalid_1's multi_logloss: 0.99919\tvalid_1's quad_kappa: 0.488671\n",
      "Training until validation scores don't improve for 2000 rounds                 \n",
      "[100]\ttraining's multi_logloss: 1.02916\ttraining's quad_kappa: 0.46674\tvalid_1's multi_logloss: 1.07668\tvalid_1's quad_kappa: 0.411795\n",
      "[200]\ttraining's multi_logloss: 0.946037\ttraining's quad_kappa: 0.547077\tvalid_1's multi_logloss: 1.03411\tvalid_1's quad_kappa: 0.474376\n",
      "[300]\ttraining's multi_logloss: 0.892794\ttraining's quad_kappa: 0.582286\tvalid_1's multi_logloss: 1.01471\tvalid_1's quad_kappa: 0.499526\n",
      "[400]\ttraining's multi_logloss: 0.852531\ttraining's quad_kappa: 0.606013\tvalid_1's multi_logloss: 1.00492\tvalid_1's quad_kappa: 0.501063\n",
      "[500]\ttraining's multi_logloss: 0.81973\ttraining's quad_kappa: 0.621744\tvalid_1's multi_logloss: 1.00015\tvalid_1's quad_kappa: 0.515263\n",
      "[600]\ttraining's multi_logloss: 0.791736\ttraining's quad_kappa: 0.637437\tvalid_1's multi_logloss: 0.996681\tvalid_1's quad_kappa: 0.51454\n",
      "[700]\ttraining's multi_logloss: 0.766835\ttraining's quad_kappa: 0.653998\tvalid_1's multi_logloss: 0.995413\tvalid_1's quad_kappa: 0.518507\n",
      "[800]\ttraining's multi_logloss: 0.744734\ttraining's quad_kappa: 0.667019\tvalid_1's multi_logloss: 0.995424\tvalid_1's quad_kappa: 0.518847\n",
      "[900]\ttraining's multi_logloss: 0.724956\ttraining's quad_kappa: 0.677694\tvalid_1's multi_logloss: 0.995185\tvalid_1's quad_kappa: 0.521235\n",
      "[1000]\ttraining's multi_logloss: 0.706654\ttraining's quad_kappa: 0.687285\tvalid_1's multi_logloss: 0.995597\tvalid_1's quad_kappa: 0.521984\n",
      "[1100]\ttraining's multi_logloss: 0.688773\ttraining's quad_kappa: 0.697299\tvalid_1's multi_logloss: 0.996406\tvalid_1's quad_kappa: 0.534039\n",
      "[1200]\ttraining's multi_logloss: 0.671504\ttraining's quad_kappa: 0.705772\tvalid_1's multi_logloss: 0.997112\tvalid_1's quad_kappa: 0.533196\n",
      "[1300]\ttraining's multi_logloss: 0.655109\ttraining's quad_kappa: 0.713414\tvalid_1's multi_logloss: 0.997936\tvalid_1's quad_kappa: 0.532839\n",
      "[1400]\ttraining's multi_logloss: 0.640286\ttraining's quad_kappa: 0.724282\tvalid_1's multi_logloss: 0.999175\tvalid_1's quad_kappa: 0.531264\n",
      "[1500]\ttraining's multi_logloss: 0.626532\ttraining's quad_kappa: 0.730237\tvalid_1's multi_logloss: 1.0013\tvalid_1's quad_kappa: 0.532536\n",
      "[1600]\ttraining's multi_logloss: 0.613103\ttraining's quad_kappa: 0.737592\tvalid_1's multi_logloss: 1.00381\tvalid_1's quad_kappa: 0.53464\n",
      "[1700]\ttraining's multi_logloss: 0.60021\ttraining's quad_kappa: 0.744938\tvalid_1's multi_logloss: 1.00668\tvalid_1's quad_kappa: 0.531628\n",
      "[1800]\ttraining's multi_logloss: 0.587618\ttraining's quad_kappa: 0.753536\tvalid_1's multi_logloss: 1.00933\tvalid_1's quad_kappa: 0.529522\n",
      "[1900]\ttraining's multi_logloss: 0.575642\ttraining's quad_kappa: 0.759301\tvalid_1's multi_logloss: 1.01232\tvalid_1's quad_kappa: 0.52843\n",
      "[2000]\ttraining's multi_logloss: 0.564072\ttraining's quad_kappa: 0.766718\tvalid_1's multi_logloss: 1.0149\tvalid_1's quad_kappa: 0.528005\n",
      "[2100]\ttraining's multi_logloss: 0.553043\ttraining's quad_kappa: 0.77219\tvalid_1's multi_logloss: 1.01744\tvalid_1's quad_kappa: 0.526314\n",
      "[2200]\ttraining's multi_logloss: 0.542552\ttraining's quad_kappa: 0.776806\tvalid_1's multi_logloss: 1.02022\tvalid_1's quad_kappa: 0.524624\n",
      "[2300]\ttraining's multi_logloss: 0.532854\ttraining's quad_kappa: 0.783657\tvalid_1's multi_logloss: 1.0233\tvalid_1's quad_kappa: 0.524654\n",
      "[2400]\ttraining's multi_logloss: 0.523157\ttraining's quad_kappa: 0.790743\tvalid_1's multi_logloss: 1.02566\tvalid_1's quad_kappa: 0.525779\n",
      "[2500]\ttraining's multi_logloss: 0.513651\ttraining's quad_kappa: 0.794008\tvalid_1's multi_logloss: 1.02833\tvalid_1's quad_kappa: 0.530628\n",
      "[2600]\ttraining's multi_logloss: 0.504602\ttraining's quad_kappa: 0.79711\tvalid_1's multi_logloss: 1.03201\tvalid_1's quad_kappa: 0.530714\n",
      "[2700]\ttraining's multi_logloss: 0.495559\ttraining's quad_kappa: 0.803165\tvalid_1's multi_logloss: 1.03519\tvalid_1's quad_kappa: 0.532563\n",
      "[2800]\ttraining's multi_logloss: 0.486449\ttraining's quad_kappa: 0.809923\tvalid_1's multi_logloss: 1.03851\tvalid_1's quad_kappa: 0.531398\n",
      "[2900]\ttraining's multi_logloss: 0.477935\ttraining's quad_kappa: 0.816586\tvalid_1's multi_logloss: 1.04207\tvalid_1's quad_kappa: 0.534531\n",
      "Early stopping, best iteration is:                                             \n",
      "[926]\ttraining's multi_logloss: 0.720003\ttraining's quad_kappa: 0.680754\tvalid_1's multi_logloss: 0.995119\tvalid_1's quad_kappa: 0.52128\n",
      "Training until validation scores don't improve for 2000 rounds                 \n",
      "[100]\ttraining's multi_logloss: 1.04708\ttraining's quad_kappa: 0.436162\tvalid_1's multi_logloss: 1.09083\tvalid_1's quad_kappa: 0.407738\n",
      "[200]\ttraining's multi_logloss: 0.963811\ttraining's quad_kappa: 0.537905\tvalid_1's multi_logloss: 1.04131\tvalid_1's quad_kappa: 0.496086\n",
      "[300]\ttraining's multi_logloss: 0.909626\ttraining's quad_kappa: 0.564974\tvalid_1's multi_logloss: 1.019\tvalid_1's quad_kappa: 0.524895\n",
      "[400]\ttraining's multi_logloss: 0.868758\ttraining's quad_kappa: 0.592819\tvalid_1's multi_logloss: 1.00898\tvalid_1's quad_kappa: 0.530349\n",
      "[500]\ttraining's multi_logloss: 0.835782\ttraining's quad_kappa: 0.611607\tvalid_1's multi_logloss: 1.00302\tvalid_1's quad_kappa: 0.535298\n",
      "[600]\ttraining's multi_logloss: 0.807389\ttraining's quad_kappa: 0.629893\tvalid_1's multi_logloss: 0.999482\tvalid_1's quad_kappa: 0.541123\n",
      "[700]\ttraining's multi_logloss: 0.78254\ttraining's quad_kappa: 0.646204\tvalid_1's multi_logloss: 0.997867\tvalid_1's quad_kappa: 0.543001\n",
      "[800]\ttraining's multi_logloss: 0.759864\ttraining's quad_kappa: 0.659415\tvalid_1's multi_logloss: 0.996494\tvalid_1's quad_kappa: 0.542189\n",
      "[900]\ttraining's multi_logloss: 0.739675\ttraining's quad_kappa: 0.669677\tvalid_1's multi_logloss: 0.99639\tvalid_1's quad_kappa: 0.543963\n",
      "[1000]\ttraining's multi_logloss: 0.721189\ttraining's quad_kappa: 0.681797\tvalid_1's multi_logloss: 0.996972\tvalid_1's quad_kappa: 0.536182\n",
      "[1100]\ttraining's multi_logloss: 0.703715\ttraining's quad_kappa: 0.691071\tvalid_1's multi_logloss: 0.998459\tvalid_1's quad_kappa: 0.538552\n",
      "[1200]\ttraining's multi_logloss: 0.687211\ttraining's quad_kappa: 0.699195\tvalid_1's multi_logloss: 1.00035\tvalid_1's quad_kappa: 0.53976\n",
      "[1300]\ttraining's multi_logloss: 0.671811\ttraining's quad_kappa: 0.706134\tvalid_1's multi_logloss: 1.00289\tvalid_1's quad_kappa: 0.538833\n",
      "[1400]\ttraining's multi_logloss: 0.657088\ttraining's quad_kappa: 0.713867\tvalid_1's multi_logloss: 1.00461\tvalid_1's quad_kappa: 0.537165\n",
      "[1500]\ttraining's multi_logloss: 0.642779\ttraining's quad_kappa: 0.721965\tvalid_1's multi_logloss: 1.00661\tvalid_1's quad_kappa: 0.535217\n",
      "[1600]\ttraining's multi_logloss: 0.629618\ttraining's quad_kappa: 0.729821\tvalid_1's multi_logloss: 1.00887\tvalid_1's quad_kappa: 0.535398\n",
      "[1700]\ttraining's multi_logloss: 0.617124\ttraining's quad_kappa: 0.739437\tvalid_1's multi_logloss: 1.01117\tvalid_1's quad_kappa: 0.536616\n",
      "[1800]\ttraining's multi_logloss: 0.604759\ttraining's quad_kappa: 0.744469\tvalid_1's multi_logloss: 1.01399\tvalid_1's quad_kappa: 0.53336\n",
      "[1900]\ttraining's multi_logloss: 0.592882\ttraining's quad_kappa: 0.749914\tvalid_1's multi_logloss: 1.01681\tvalid_1's quad_kappa: 0.534689\n",
      "[2000]\ttraining's multi_logloss: 0.58119\ttraining's quad_kappa: 0.755146\tvalid_1's multi_logloss: 1.01931\tvalid_1's quad_kappa: 0.537235\n",
      "[2100]\ttraining's multi_logloss: 0.570045\ttraining's quad_kappa: 0.761804\tvalid_1's multi_logloss: 1.02184\tvalid_1's quad_kappa: 0.537936\n",
      "[2200]\ttraining's multi_logloss: 0.55918\ttraining's quad_kappa: 0.769052\tvalid_1's multi_logloss: 1.0245\tvalid_1's quad_kappa: 0.538915\n",
      "[2300]\ttraining's multi_logloss: 0.549067\ttraining's quad_kappa: 0.775625\tvalid_1's multi_logloss: 1.02779\tvalid_1's quad_kappa: 0.535892\n",
      "[2400]\ttraining's multi_logloss: 0.538798\ttraining's quad_kappa: 0.780833\tvalid_1's multi_logloss: 1.03052\tvalid_1's quad_kappa: 0.534128\n",
      "[2500]\ttraining's multi_logloss: 0.529009\ttraining's quad_kappa: 0.786498\tvalid_1's multi_logloss: 1.03338\tvalid_1's quad_kappa: 0.535805\n",
      "[2600]\ttraining's multi_logloss: 0.519656\ttraining's quad_kappa: 0.791523\tvalid_1's multi_logloss: 1.03604\tvalid_1's quad_kappa: 0.544981\n",
      "[2700]\ttraining's multi_logloss: 0.510494\ttraining's quad_kappa: 0.796117\tvalid_1's multi_logloss: 1.03927\tvalid_1's quad_kappa: 0.541214\n",
      "[2800]\ttraining's multi_logloss: 0.501694\ttraining's quad_kappa: 0.801158\tvalid_1's multi_logloss: 1.04201\tvalid_1's quad_kappa: 0.543369\n",
      "Early stopping, best iteration is:                                               \n",
      "[860]\ttraining's multi_logloss: 0.74743\ttraining's quad_kappa: 0.665465\tvalid_1's multi_logloss: 0.99622\tvalid_1's quad_kappa: 0.541491\n",
      "{'learning_rate': 0.009973407290996853, 'metric': 'multiclass', 'n_estimators': 10000, 'num_classes': 4, 'objective': 'multiclass', 'random_state': 2019}\n",
      "Training until validation scores don't improve for 2000 rounds                   \n",
      " 80%|████████  | 8/10 [1:01:14<16:24, 492.11s/it, best loss: -0.5135357478561519]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 1.02601\ttraining's quad_kappa: 0.466215\tvalid_1's multi_logloss: 1.06494\tvalid_1's quad_kappa: 0.432766\n",
      "[200]\ttraining's multi_logloss: 0.941823\ttraining's quad_kappa: 0.533003\tvalid_1's multi_logloss: 1.0266\tvalid_1's quad_kappa: 0.477603\n",
      "[300]\ttraining's multi_logloss: 0.888121\ttraining's quad_kappa: 0.567604\tvalid_1's multi_logloss: 1.01049\tvalid_1's quad_kappa: 0.473866\n",
      "[400]\ttraining's multi_logloss: 0.846933\ttraining's quad_kappa: 0.59451\tvalid_1's multi_logloss: 1.00401\tvalid_1's quad_kappa: 0.485563\n",
      "[500]\ttraining's multi_logloss: 0.813181\ttraining's quad_kappa: 0.618199\tvalid_1's multi_logloss: 1.00065\tvalid_1's quad_kappa: 0.488509\n",
      "[600]\ttraining's multi_logloss: 0.783538\ttraining's quad_kappa: 0.634844\tvalid_1's multi_logloss: 1.00027\tvalid_1's quad_kappa: 0.483772\n",
      "[700]\ttraining's multi_logloss: 0.757963\ttraining's quad_kappa: 0.648762\tvalid_1's multi_logloss: 1.00172\tvalid_1's quad_kappa: 0.478742\n",
      "[800]\ttraining's multi_logloss: 0.734807\ttraining's quad_kappa: 0.662841\tvalid_1's multi_logloss: 1.00356\tvalid_1's quad_kappa: 0.480088\n",
      "[900]\ttraining's multi_logloss: 0.713494\ttraining's quad_kappa: 0.675885\tvalid_1's multi_logloss: 1.00549\tvalid_1's quad_kappa: 0.491232\n",
      "[1000]\ttraining's multi_logloss: 0.693519\ttraining's quad_kappa: 0.688628\tvalid_1's multi_logloss: 1.00753\tvalid_1's quad_kappa: 0.498018\n",
      "[1100]\ttraining's multi_logloss: 0.674384\ttraining's quad_kappa: 0.701285\tvalid_1's multi_logloss: 1.00916\tvalid_1's quad_kappa: 0.493072\n",
      "[1200]\ttraining's multi_logloss: 0.656747\ttraining's quad_kappa: 0.710492\tvalid_1's multi_logloss: 1.01124\tvalid_1's quad_kappa: 0.49396\n",
      "[1300]\ttraining's multi_logloss: 0.640176\ttraining's quad_kappa: 0.720814\tvalid_1's multi_logloss: 1.01298\tvalid_1's quad_kappa: 0.490615\n",
      "[1400]\ttraining's multi_logloss: 0.624708\ttraining's quad_kappa: 0.730496\tvalid_1's multi_logloss: 1.01619\tvalid_1's quad_kappa: 0.496605\n",
      "[1500]\ttraining's multi_logloss: 0.609939\ttraining's quad_kappa: 0.739137\tvalid_1's multi_logloss: 1.0193\tvalid_1's quad_kappa: 0.497923\n",
      "[1600]\ttraining's multi_logloss: 0.596168\ttraining's quad_kappa: 0.747373\tvalid_1's multi_logloss: 1.02263\tvalid_1's quad_kappa: 0.497265\n",
      "[1700]\ttraining's multi_logloss: 0.582688\ttraining's quad_kappa: 0.754392\tvalid_1's multi_logloss: 1.02579\tvalid_1's quad_kappa: 0.502743\n",
      "[1800]\ttraining's multi_logloss: 0.569527\ttraining's quad_kappa: 0.761942\tvalid_1's multi_logloss: 1.02829\tvalid_1's quad_kappa: 0.504643\n",
      "[1900]\ttraining's multi_logloss: 0.557182\ttraining's quad_kappa: 0.769682\tvalid_1's multi_logloss: 1.03239\tvalid_1's quad_kappa: 0.506999\n",
      "[2000]\ttraining's multi_logloss: 0.544744\ttraining's quad_kappa: 0.7765\tvalid_1's multi_logloss: 1.03585\tvalid_1's quad_kappa: 0.508919\n",
      "[2100]\ttraining's multi_logloss: 0.532304\ttraining's quad_kappa: 0.783091\tvalid_1's multi_logloss: 1.03914\tvalid_1's quad_kappa: 0.510931\n",
      "[2200]\ttraining's multi_logloss: 0.52108\ttraining's quad_kappa: 0.789335\tvalid_1's multi_logloss: 1.04238\tvalid_1's quad_kappa: 0.507165\n",
      "[2300]\ttraining's multi_logloss: 0.510543\ttraining's quad_kappa: 0.79528\tvalid_1's multi_logloss: 1.04501\tvalid_1's quad_kappa: 0.508384\n",
      "[2400]\ttraining's multi_logloss: 0.50012\ttraining's quad_kappa: 0.801593\tvalid_1's multi_logloss: 1.04761\tvalid_1's quad_kappa: 0.509346\n",
      "[2500]\ttraining's multi_logloss: 0.490011\ttraining's quad_kappa: 0.806121\tvalid_1's multi_logloss: 1.05069\tvalid_1's quad_kappa: 0.510502\n",
      "Early stopping, best iteration is:                                               \n",
      "[554]\ttraining's multi_logloss: 0.79663\ttraining's quad_kappa: 0.627421\tvalid_1's multi_logloss: 0.999892\tvalid_1's quad_kappa: 0.485804\n",
      "Training until validation scores don't improve for 2000 rounds                   \n",
      "[100]\ttraining's multi_logloss: 1.00903\ttraining's quad_kappa: 0.4903\tvalid_1's multi_logloss: 1.06444\tvalid_1's quad_kappa: 0.432082\n",
      "[200]\ttraining's multi_logloss: 0.923846\ttraining's quad_kappa: 0.559643\tvalid_1's multi_logloss: 1.02525\tvalid_1's quad_kappa: 0.479469\n",
      "[300]\ttraining's multi_logloss: 0.868493\ttraining's quad_kappa: 0.595035\tvalid_1's multi_logloss: 1.00778\tvalid_1's quad_kappa: 0.503452\n",
      "[400]\ttraining's multi_logloss: 0.827114\ttraining's quad_kappa: 0.619143\tvalid_1's multi_logloss: 1.00146\tvalid_1's quad_kappa: 0.511372\n",
      "[500]\ttraining's multi_logloss: 0.793062\ttraining's quad_kappa: 0.638488\tvalid_1's multi_logloss: 0.996935\tvalid_1's quad_kappa: 0.506509\n",
      "[600]\ttraining's multi_logloss: 0.76434\ttraining's quad_kappa: 0.656326\tvalid_1's multi_logloss: 0.995168\tvalid_1's quad_kappa: 0.518229\n",
      "[700]\ttraining's multi_logloss: 0.73856\ttraining's quad_kappa: 0.671292\tvalid_1's multi_logloss: 0.995102\tvalid_1's quad_kappa: 0.522209\n",
      "[800]\ttraining's multi_logloss: 0.715082\ttraining's quad_kappa: 0.685443\tvalid_1's multi_logloss: 0.995088\tvalid_1's quad_kappa: 0.520756\n",
      "[900]\ttraining's multi_logloss: 0.693889\ttraining's quad_kappa: 0.695257\tvalid_1's multi_logloss: 0.995762\tvalid_1's quad_kappa: 0.522015\n",
      "[1000]\ttraining's multi_logloss: 0.673009\ttraining's quad_kappa: 0.706223\tvalid_1's multi_logloss: 0.996518\tvalid_1's quad_kappa: 0.527971\n",
      "[1100]\ttraining's multi_logloss: 0.653622\ttraining's quad_kappa: 0.715308\tvalid_1's multi_logloss: 0.997578\tvalid_1's quad_kappa: 0.528771\n",
      "[1200]\ttraining's multi_logloss: 0.636123\ttraining's quad_kappa: 0.726981\tvalid_1's multi_logloss: 0.999502\tvalid_1's quad_kappa: 0.532984\n",
      "[1300]\ttraining's multi_logloss: 0.619527\ttraining's quad_kappa: 0.735006\tvalid_1's multi_logloss: 1.0023\tvalid_1's quad_kappa: 0.533533\n",
      "[1400]\ttraining's multi_logloss: 0.603849\ttraining's quad_kappa: 0.743898\tvalid_1's multi_logloss: 1.00622\tvalid_1's quad_kappa: 0.532134\n",
      "[1500]\ttraining's multi_logloss: 0.589111\ttraining's quad_kappa: 0.752782\tvalid_1's multi_logloss: 1.00949\tvalid_1's quad_kappa: 0.530496\n",
      "[1600]\ttraining's multi_logloss: 0.574878\ttraining's quad_kappa: 0.7594\tvalid_1's multi_logloss: 1.01278\tvalid_1's quad_kappa: 0.531738\n",
      "[1700]\ttraining's multi_logloss: 0.561194\ttraining's quad_kappa: 0.768351\tvalid_1's multi_logloss: 1.01603\tvalid_1's quad_kappa: 0.528116\n",
      "[1800]\ttraining's multi_logloss: 0.548074\ttraining's quad_kappa: 0.775132\tvalid_1's multi_logloss: 1.0198\tvalid_1's quad_kappa: 0.529917\n",
      "[1900]\ttraining's multi_logloss: 0.535558\ttraining's quad_kappa: 0.782988\tvalid_1's multi_logloss: 1.02335\tvalid_1's quad_kappa: 0.52701\n",
      "[2000]\ttraining's multi_logloss: 0.52368\ttraining's quad_kappa: 0.787868\tvalid_1's multi_logloss: 1.02669\tvalid_1's quad_kappa: 0.527679\n",
      "[2100]\ttraining's multi_logloss: 0.51168\ttraining's quad_kappa: 0.796669\tvalid_1's multi_logloss: 1.03002\tvalid_1's quad_kappa: 0.527211\n",
      "[2200]\ttraining's multi_logloss: 0.49989\ttraining's quad_kappa: 0.802256\tvalid_1's multi_logloss: 1.03317\tvalid_1's quad_kappa: 0.527181\n",
      "[2300]\ttraining's multi_logloss: 0.488858\ttraining's quad_kappa: 0.808857\tvalid_1's multi_logloss: 1.03625\tvalid_1's quad_kappa: 0.529546\n",
      "[2400]\ttraining's multi_logloss: 0.478052\ttraining's quad_kappa: 0.8165\tvalid_1's multi_logloss: 1.03951\tvalid_1's quad_kappa: 0.532068\n",
      "[2500]\ttraining's multi_logloss: 0.468218\ttraining's quad_kappa: 0.822638\tvalid_1's multi_logloss: 1.04345\tvalid_1's quad_kappa: 0.529473\n",
      "[2600]\ttraining's multi_logloss: 0.458595\ttraining's quad_kappa: 0.827747\tvalid_1's multi_logloss: 1.04778\tvalid_1's quad_kappa: 0.530766\n",
      "[2700]\ttraining's multi_logloss: 0.449414\ttraining's quad_kappa: 0.833699\tvalid_1's multi_logloss: 1.052\tvalid_1's quad_kappa: 0.526713\n",
      "Early stopping, best iteration is:                                               \n",
      "[775]\ttraining's multi_logloss: 0.720723\ttraining's quad_kappa: 0.680767\tvalid_1's multi_logloss: 0.994851\tvalid_1's quad_kappa: 0.521415\n",
      "Training until validation scores don't improve for 2000 rounds                   \n",
      "[100]\ttraining's multi_logloss: 1.02713\ttraining's quad_kappa: 0.47376\tvalid_1's multi_logloss: 1.07768\tvalid_1's quad_kappa: 0.443474\n",
      "[200]\ttraining's multi_logloss: 0.941303\ttraining's quad_kappa: 0.546737\tvalid_1's multi_logloss: 1.03134\tvalid_1's quad_kappa: 0.503677\n",
      "[300]\ttraining's multi_logloss: 0.884727\ttraining's quad_kappa: 0.582467\tvalid_1's multi_logloss: 1.01214\tvalid_1's quad_kappa: 0.531057\n",
      "[400]\ttraining's multi_logloss: 0.843009\ttraining's quad_kappa: 0.611658\tvalid_1's multi_logloss: 1.00433\tvalid_1's quad_kappa: 0.53216\n",
      "[500]\ttraining's multi_logloss: 0.808709\ttraining's quad_kappa: 0.630402\tvalid_1's multi_logloss: 0.999554\tvalid_1's quad_kappa: 0.533095\n",
      "[600]\ttraining's multi_logloss: 0.779435\ttraining's quad_kappa: 0.648343\tvalid_1's multi_logloss: 0.997599\tvalid_1's quad_kappa: 0.538045\n",
      "[700]\ttraining's multi_logloss: 0.753786\ttraining's quad_kappa: 0.662384\tvalid_1's multi_logloss: 0.997252\tvalid_1's quad_kappa: 0.537493\n",
      "[800]\ttraining's multi_logloss: 0.730693\ttraining's quad_kappa: 0.675089\tvalid_1's multi_logloss: 0.997787\tvalid_1's quad_kappa: 0.534375\n",
      "[900]\ttraining's multi_logloss: 0.70912\ttraining's quad_kappa: 0.687896\tvalid_1's multi_logloss: 0.998089\tvalid_1's quad_kappa: 0.531606\n",
      "[1000]\ttraining's multi_logloss: 0.68934\ttraining's quad_kappa: 0.699511\tvalid_1's multi_logloss: 0.999255\tvalid_1's quad_kappa: 0.528195\n",
      "[1100]\ttraining's multi_logloss: 0.671376\ttraining's quad_kappa: 0.706572\tvalid_1's multi_logloss: 1.00132\tvalid_1's quad_kappa: 0.53586\n",
      "[1200]\ttraining's multi_logloss: 0.653962\ttraining's quad_kappa: 0.716329\tvalid_1's multi_logloss: 1.00384\tvalid_1's quad_kappa: 0.536755\n",
      "[1300]\ttraining's multi_logloss: 0.637549\ttraining's quad_kappa: 0.725339\tvalid_1's multi_logloss: 1.00674\tvalid_1's quad_kappa: 0.537303\n",
      "[1400]\ttraining's multi_logloss: 0.622168\ttraining's quad_kappa: 0.734343\tvalid_1's multi_logloss: 1.00983\tvalid_1's quad_kappa: 0.538008\n",
      "[1500]\ttraining's multi_logloss: 0.607629\ttraining's quad_kappa: 0.740994\tvalid_1's multi_logloss: 1.01302\tvalid_1's quad_kappa: 0.536841\n",
      "[1600]\ttraining's multi_logloss: 0.59362\ttraining's quad_kappa: 0.750188\tvalid_1's multi_logloss: 1.01604\tvalid_1's quad_kappa: 0.540043\n",
      "[1700]\ttraining's multi_logloss: 0.579979\ttraining's quad_kappa: 0.759801\tvalid_1's multi_logloss: 1.01993\tvalid_1's quad_kappa: 0.538586\n",
      "[1800]\ttraining's multi_logloss: 0.567414\ttraining's quad_kappa: 0.765735\tvalid_1's multi_logloss: 1.0235\tvalid_1's quad_kappa: 0.537779\n",
      "[1900]\ttraining's multi_logloss: 0.555032\ttraining's quad_kappa: 0.77206\tvalid_1's multi_logloss: 1.0264\tvalid_1's quad_kappa: 0.542534\n",
      "[2000]\ttraining's multi_logloss: 0.542479\ttraining's quad_kappa: 0.779691\tvalid_1's multi_logloss: 1.02957\tvalid_1's quad_kappa: 0.542544\n",
      "[2100]\ttraining's multi_logloss: 0.531006\ttraining's quad_kappa: 0.783686\tvalid_1's multi_logloss: 1.0328\tvalid_1's quad_kappa: 0.538555\n",
      "[2200]\ttraining's multi_logloss: 0.519578\ttraining's quad_kappa: 0.791405\tvalid_1's multi_logloss: 1.03644\tvalid_1's quad_kappa: 0.537472\n",
      "[2300]\ttraining's multi_logloss: 0.508633\ttraining's quad_kappa: 0.79802\tvalid_1's multi_logloss: 1.04079\tvalid_1's quad_kappa: 0.536101\n",
      "[2400]\ttraining's multi_logloss: 0.498126\ttraining's quad_kappa: 0.805315\tvalid_1's multi_logloss: 1.0447\tvalid_1's quad_kappa: 0.540439\n",
      "[2500]\ttraining's multi_logloss: 0.48796\ttraining's quad_kappa: 0.809245\tvalid_1's multi_logloss: 1.04905\tvalid_1's quad_kappa: 0.54217\n",
      "[2600]\ttraining's multi_logloss: 0.478112\ttraining's quad_kappa: 0.814219\tvalid_1's multi_logloss: 1.05252\tvalid_1's quad_kappa: 0.53967\n",
      "Early stopping, best iteration is:                                               \n",
      "[677]\ttraining's multi_logloss: 0.759275\ttraining's quad_kappa: 0.660106\tvalid_1's multi_logloss: 0.99707\tvalid_1's quad_kappa: 0.535307\n",
      "{'learning_rate': 0.11664917602088852, 'metric': 'multiclass', 'n_estimators': 10000, 'num_classes': 4, 'objective': 'multiclass', 'random_state': 2019}\n",
      "Training until validation scores don't improve for 2000 rounds                   \n",
      " 90%|█████████ | 9/10 [1:10:10<08:25, 505.37s/it, best loss: -0.5135357478561519]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 0.660461\ttraining's quad_kappa: 0.70558\tvalid_1's multi_logloss: 1.01632\tvalid_1's quad_kappa: 0.504706\n",
      "[200]\ttraining's multi_logloss: 0.503405\ttraining's quad_kappa: 0.800394\tvalid_1's multi_logloss: 1.05612\tvalid_1's quad_kappa: 0.506137\n",
      "[300]\ttraining's multi_logloss: 0.400219\ttraining's quad_kappa: 0.851548\tvalid_1's multi_logloss: 1.10101\tvalid_1's quad_kappa: 0.504405\n",
      "[400]\ttraining's multi_logloss: 0.323967\ttraining's quad_kappa: 0.885296\tvalid_1's multi_logloss: 1.15107\tvalid_1's quad_kappa: 0.50135\n",
      "[500]\ttraining's multi_logloss: 0.268369\ttraining's quad_kappa: 0.904758\tvalid_1's multi_logloss: 1.20336\tvalid_1's quad_kappa: 0.501752\n",
      "[600]\ttraining's multi_logloss: 0.224305\ttraining's quad_kappa: 0.92419\tvalid_1's multi_logloss: 1.25193\tvalid_1's quad_kappa: 0.497283\n",
      "[700]\ttraining's multi_logloss: 0.187789\ttraining's quad_kappa: 0.93911\tvalid_1's multi_logloss: 1.29735\tvalid_1's quad_kappa: 0.493393\n",
      "[800]\ttraining's multi_logloss: 0.156661\ttraining's quad_kappa: 0.952049\tvalid_1's multi_logloss: 1.34043\tvalid_1's quad_kappa: 0.481713\n",
      "[900]\ttraining's multi_logloss: 0.131861\ttraining's quad_kappa: 0.959992\tvalid_1's multi_logloss: 1.38853\tvalid_1's quad_kappa: 0.485766\n",
      "[1000]\ttraining's multi_logloss: 0.111979\ttraining's quad_kappa: 0.96815\tvalid_1's multi_logloss: 1.4375\tvalid_1's quad_kappa: 0.486223\n",
      "[1100]\ttraining's multi_logloss: 0.0950644\ttraining's quad_kappa: 0.97461\tvalid_1's multi_logloss: 1.48501\tvalid_1's quad_kappa: 0.479703\n",
      "[1200]\ttraining's multi_logloss: 0.0810033\ttraining's quad_kappa: 0.97925\tvalid_1's multi_logloss: 1.5311\tvalid_1's quad_kappa: 0.486065\n",
      "[1300]\ttraining's multi_logloss: 0.0685622\ttraining's quad_kappa: 0.981478\tvalid_1's multi_logloss: 1.58477\tvalid_1's quad_kappa: 0.477657\n",
      "[1400]\ttraining's multi_logloss: 0.0584569\ttraining's quad_kappa: 0.984188\tvalid_1's multi_logloss: 1.63196\tvalid_1's quad_kappa: 0.468329\n",
      "[1500]\ttraining's multi_logloss: 0.0504068\ttraining's quad_kappa: 0.986037\tvalid_1's multi_logloss: 1.68052\tvalid_1's quad_kappa: 0.470128\n",
      "[1600]\ttraining's multi_logloss: 0.0430726\ttraining's quad_kappa: 0.988464\tvalid_1's multi_logloss: 1.72769\tvalid_1's quad_kappa: 0.468713\n",
      "[1700]\ttraining's multi_logloss: 0.0371256\ttraining's quad_kappa: 0.990034\tvalid_1's multi_logloss: 1.77397\tvalid_1's quad_kappa: 0.463767\n",
      "[1800]\ttraining's multi_logloss: 0.0320314\ttraining's quad_kappa: 0.991633\tvalid_1's multi_logloss: 1.82869\tvalid_1's quad_kappa: 0.460762\n",
      "[1900]\ttraining's multi_logloss: 0.0279426\ttraining's quad_kappa: 0.992529\tvalid_1's multi_logloss: 1.88055\tvalid_1's quad_kappa: 0.454611\n",
      "[2000]\ttraining's multi_logloss: 0.0244779\ttraining's quad_kappa: 0.993232\tvalid_1's multi_logloss: 1.93393\tvalid_1's quad_kappa: 0.450641\n",
      "Early stopping, best iteration is:                                               \n",
      "[48]\ttraining's multi_logloss: 0.791624\ttraining's quad_kappa: 0.627615\tvalid_1's multi_logloss: 0.999373\tvalid_1's quad_kappa: 0.496307\n",
      "Training until validation scores don't improve for 2000 rounds                   \n",
      "[100]\ttraining's multi_logloss: 0.639351\ttraining's quad_kappa: 0.723471\tvalid_1's multi_logloss: 1.00628\tvalid_1's quad_kappa: 0.52087\n",
      "[200]\ttraining's multi_logloss: 0.483305\ttraining's quad_kappa: 0.816111\tvalid_1's multi_logloss: 1.0483\tvalid_1's quad_kappa: 0.523704\n",
      "[300]\ttraining's multi_logloss: 0.378475\ttraining's quad_kappa: 0.867913\tvalid_1's multi_logloss: 1.09192\tvalid_1's quad_kappa: 0.5215\n",
      "[400]\ttraining's multi_logloss: 0.306462\ttraining's quad_kappa: 0.897183\tvalid_1's multi_logloss: 1.13563\tvalid_1's quad_kappa: 0.525424\n",
      "[500]\ttraining's multi_logloss: 0.25066\ttraining's quad_kappa: 0.916125\tvalid_1's multi_logloss: 1.18552\tvalid_1's quad_kappa: 0.518301\n",
      "[600]\ttraining's multi_logloss: 0.20671\ttraining's quad_kappa: 0.93143\tvalid_1's multi_logloss: 1.23928\tvalid_1's quad_kappa: 0.516842\n",
      "[700]\ttraining's multi_logloss: 0.173542\ttraining's quad_kappa: 0.944088\tvalid_1's multi_logloss: 1.28717\tvalid_1's quad_kappa: 0.519662\n",
      "[800]\ttraining's multi_logloss: 0.143648\ttraining's quad_kappa: 0.955705\tvalid_1's multi_logloss: 1.32513\tvalid_1's quad_kappa: 0.510284\n",
      "[900]\ttraining's multi_logloss: 0.121332\ttraining's quad_kappa: 0.961474\tvalid_1's multi_logloss: 1.37301\tvalid_1's quad_kappa: 0.508447\n",
      "[1000]\ttraining's multi_logloss: 0.102705\ttraining's quad_kappa: 0.967968\tvalid_1's multi_logloss: 1.42279\tvalid_1's quad_kappa: 0.513436\n",
      "[1100]\ttraining's multi_logloss: 0.0869755\ttraining's quad_kappa: 0.974024\tvalid_1's multi_logloss: 1.46987\tvalid_1's quad_kappa: 0.515107\n",
      "[1200]\ttraining's multi_logloss: 0.0736043\ttraining's quad_kappa: 0.977475\tvalid_1's multi_logloss: 1.52002\tvalid_1's quad_kappa: 0.511496\n",
      "[1300]\ttraining's multi_logloss: 0.0630498\ttraining's quad_kappa: 0.980735\tvalid_1's multi_logloss: 1.56645\tvalid_1's quad_kappa: 0.503036\n",
      "[1400]\ttraining's multi_logloss: 0.0538744\ttraining's quad_kappa: 0.985537\tvalid_1's multi_logloss: 1.61037\tvalid_1's quad_kappa: 0.498408\n",
      "[1500]\ttraining's multi_logloss: 0.0462018\ttraining's quad_kappa: 0.98698\tvalid_1's multi_logloss: 1.66207\tvalid_1's quad_kappa: 0.497744\n",
      "[1600]\ttraining's multi_logloss: 0.0398038\ttraining's quad_kappa: 0.988044\tvalid_1's multi_logloss: 1.71019\tvalid_1's quad_kappa: 0.502604\n",
      "[1700]\ttraining's multi_logloss: 0.0347297\ttraining's quad_kappa: 0.989268\tvalid_1's multi_logloss: 1.76342\tvalid_1's quad_kappa: 0.490029\n",
      "[1800]\ttraining's multi_logloss: 0.0304116\ttraining's quad_kappa: 0.989869\tvalid_1's multi_logloss: 1.81739\tvalid_1's quad_kappa: 0.486473\n",
      "[1900]\ttraining's multi_logloss: 0.026466\ttraining's quad_kappa: 0.990371\tvalid_1's multi_logloss: 1.87152\tvalid_1's quad_kappa: 0.486756\n",
      "[2000]\ttraining's multi_logloss: 0.0236294\ttraining's quad_kappa: 0.990432\tvalid_1's multi_logloss: 1.9204\tvalid_1's quad_kappa: 0.487336\n",
      "Early stopping, best iteration is:                                               \n",
      "[65]\ttraining's multi_logloss: 0.72108\ttraining's quad_kappa: 0.679778\tvalid_1's multi_logloss: 0.997091\tvalid_1's quad_kappa: 0.525311\n",
      "Training until validation scores don't improve for 2000 rounds                   \n",
      "[100]\ttraining's multi_logloss: 0.655054\ttraining's quad_kappa: 0.715655\tvalid_1's multi_logloss: 1.01034\tvalid_1's quad_kappa: 0.538226\n",
      "[200]\ttraining's multi_logloss: 0.500238\ttraining's quad_kappa: 0.806941\tvalid_1's multi_logloss: 1.05424\tvalid_1's quad_kappa: 0.544132\n",
      "[300]\ttraining's multi_logloss: 0.397503\ttraining's quad_kappa: 0.854265\tvalid_1's multi_logloss: 1.10118\tvalid_1's quad_kappa: 0.533127\n",
      "[400]\ttraining's multi_logloss: 0.324519\ttraining's quad_kappa: 0.88513\tvalid_1's multi_logloss: 1.148\tvalid_1's quad_kappa: 0.530158\n",
      "[500]\ttraining's multi_logloss: 0.266225\ttraining's quad_kappa: 0.904162\tvalid_1's multi_logloss: 1.19858\tvalid_1's quad_kappa: 0.528406\n",
      "[600]\ttraining's multi_logloss: 0.221501\ttraining's quad_kappa: 0.926214\tvalid_1's multi_logloss: 1.24863\tvalid_1's quad_kappa: 0.535465\n",
      "[700]\ttraining's multi_logloss: 0.184475\ttraining's quad_kappa: 0.941312\tvalid_1's multi_logloss: 1.28976\tvalid_1's quad_kappa: 0.522918\n",
      "[800]\ttraining's multi_logloss: 0.155615\ttraining's quad_kappa: 0.952051\tvalid_1's multi_logloss: 1.33379\tvalid_1's quad_kappa: 0.522959\n",
      "[900]\ttraining's multi_logloss: 0.130775\ttraining's quad_kappa: 0.959076\tvalid_1's multi_logloss: 1.38084\tvalid_1's quad_kappa: 0.519219\n",
      "[1000]\ttraining's multi_logloss: 0.110832\ttraining's quad_kappa: 0.965723\tvalid_1's multi_logloss: 1.43035\tvalid_1's quad_kappa: 0.51225\n",
      "[1100]\ttraining's multi_logloss: 0.0952988\ttraining's quad_kappa: 0.970089\tvalid_1's multi_logloss: 1.47469\tvalid_1's quad_kappa: 0.509802\n",
      "[1200]\ttraining's multi_logloss: 0.0819032\ttraining's quad_kappa: 0.974521\tvalid_1's multi_logloss: 1.52089\tvalid_1's quad_kappa: 0.511119\n",
      "[1300]\ttraining's multi_logloss: 0.0700592\ttraining's quad_kappa: 0.978198\tvalid_1's multi_logloss: 1.56597\tvalid_1's quad_kappa: 0.515267\n",
      "[1400]\ttraining's multi_logloss: 0.0605677\ttraining's quad_kappa: 0.980777\tvalid_1's multi_logloss: 1.61088\tvalid_1's quad_kappa: 0.514968\n",
      "[1500]\ttraining's multi_logloss: 0.0525617\ttraining's quad_kappa: 0.983291\tvalid_1's multi_logloss: 1.65935\tvalid_1's quad_kappa: 0.516698\n",
      "[1600]\ttraining's multi_logloss: 0.0457214\ttraining's quad_kappa: 0.984761\tvalid_1's multi_logloss: 1.70995\tvalid_1's quad_kappa: 0.515415\n",
      "[1700]\ttraining's multi_logloss: 0.039679\ttraining's quad_kappa: 0.986896\tvalid_1's multi_logloss: 1.75978\tvalid_1's quad_kappa: 0.519581\n",
      "[1800]\ttraining's multi_logloss: 0.0350415\ttraining's quad_kappa: 0.987963\tvalid_1's multi_logloss: 1.81502\tvalid_1's quad_kappa: 0.525041\n",
      "[1900]\ttraining's multi_logloss: 0.0311813\ttraining's quad_kappa: 0.988655\tvalid_1's multi_logloss: 1.86782\tvalid_1's quad_kappa: 0.521141\n",
      "[2000]\ttraining's multi_logloss: 0.0278261\ttraining's quad_kappa: 0.9891\tvalid_1's multi_logloss: 1.91752\tvalid_1's quad_kappa: 0.517815\n",
      "Early stopping, best iteration is:                                               \n",
      "[48]\ttraining's multi_logloss: 0.784563\ttraining's quad_kappa: 0.643665\tvalid_1's multi_logloss: 0.997705\tvalid_1's quad_kappa: 0.536844\n",
      "100%|██████████| 10/10 [1:16:17<00:00, 457.78s/it, best loss: -0.5135357478561519]\n",
      "{'learning_rate': 0.006555303260125819}\n",
      "{'feature_fraction': 0.65, 'lambda_l1': 0.4588341277951369, 'lambda_l2': 0.0012594945899472825, 'learning_rate': 0.007, 'max_depth': 3.0, 'metric': 'multiclass', 'n_estimators': 10000, 'num_classes': 4, 'num_leaves': 1023, 'objective': 'multiclass', 'random_state': 2019, 'subsample': 0.47000000000000003}\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "  0%|          | 0/25 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 1.13808\ttraining's quad_kappa: 0.149348\tvalid_1's multi_logloss: 1.13035\tvalid_1's quad_kappa: 0.143923\n",
      "[200]\ttraining's multi_logloss: 1.09209\ttraining's quad_kappa: 0.336443\tvalid_1's multi_logloss: 1.0883\tvalid_1's quad_kappa: 0.313525\n",
      "[300]\ttraining's multi_logloss: 1.06573\ttraining's quad_kappa: 0.357565\tvalid_1's multi_logloss: 1.06859\tvalid_1's quad_kappa: 0.329995\n",
      "[400]\ttraining's multi_logloss: 1.04699\ttraining's quad_kappa: 0.378394\tvalid_1's multi_logloss: 1.05649\tvalid_1's quad_kappa: 0.349893\n",
      "[500]\ttraining's multi_logloss: 1.03117\ttraining's quad_kappa: 0.405117\tvalid_1's multi_logloss: 1.04512\tvalid_1's quad_kappa: 0.375907\n",
      "[600]\ttraining's multi_logloss: 1.01724\ttraining's quad_kappa: 0.437027\tvalid_1's multi_logloss: 1.03589\tvalid_1's quad_kappa: 0.40186\n",
      "[700]\ttraining's multi_logloss: 1.00497\ttraining's quad_kappa: 0.464777\tvalid_1's multi_logloss: 1.02805\tvalid_1's quad_kappa: 0.413176\n",
      "[800]\ttraining's multi_logloss: 0.994374\ttraining's quad_kappa: 0.492126\tvalid_1's multi_logloss: 1.02139\tvalid_1's quad_kappa: 0.45016\n",
      "[900]\ttraining's multi_logloss: 0.985528\ttraining's quad_kappa: 0.501564\tvalid_1's multi_logloss: 1.01646\tvalid_1's quad_kappa: 0.460476\n",
      "[1000]\ttraining's multi_logloss: 0.977636\ttraining's quad_kappa: 0.507422\tvalid_1's multi_logloss: 1.0125\tvalid_1's quad_kappa: 0.466688\n",
      "[1100]\ttraining's multi_logloss: 0.97065\ttraining's quad_kappa: 0.510723\tvalid_1's multi_logloss: 1.00941\tvalid_1's quad_kappa: 0.47863\n",
      "[1200]\ttraining's multi_logloss: 0.964083\ttraining's quad_kappa: 0.51408\tvalid_1's multi_logloss: 1.00697\tvalid_1's quad_kappa: 0.481658\n",
      "[1300]\ttraining's multi_logloss: 0.958007\ttraining's quad_kappa: 0.520297\tvalid_1's multi_logloss: 1.00504\tvalid_1's quad_kappa: 0.484702\n",
      "[1400]\ttraining's multi_logloss: 0.952476\ttraining's quad_kappa: 0.524409\tvalid_1's multi_logloss: 1.0032\tvalid_1's quad_kappa: 0.494968\n",
      "[1500]\ttraining's multi_logloss: 0.947216\ttraining's quad_kappa: 0.530603\tvalid_1's multi_logloss: 1.00155\tvalid_1's quad_kappa: 0.493621\n",
      "[1600]\ttraining's multi_logloss: 0.942183\ttraining's quad_kappa: 0.534596\tvalid_1's multi_logloss: 1.00003\tvalid_1's quad_kappa: 0.494271\n",
      "[1700]\ttraining's multi_logloss: 0.937509\ttraining's quad_kappa: 0.538033\tvalid_1's multi_logloss: 0.999107\tvalid_1's quad_kappa: 0.49623\n",
      "[1800]\ttraining's multi_logloss: 0.933171\ttraining's quad_kappa: 0.537604\tvalid_1's multi_logloss: 0.99839\tvalid_1's quad_kappa: 0.495929\n",
      "[1900]\ttraining's multi_logloss: 0.928938\ttraining's quad_kappa: 0.538431\tvalid_1's multi_logloss: 0.997863\tvalid_1's quad_kappa: 0.492775\n",
      "[2000]\ttraining's multi_logloss: 0.924862\ttraining's quad_kappa: 0.542101\tvalid_1's multi_logloss: 0.997359\tvalid_1's quad_kappa: 0.493702\n",
      "[2100]\ttraining's multi_logloss: 0.920914\ttraining's quad_kappa: 0.544255\tvalid_1's multi_logloss: 0.996863\tvalid_1's quad_kappa: 0.489378\n",
      "[2200]\ttraining's multi_logloss: 0.917002\ttraining's quad_kappa: 0.546802\tvalid_1's multi_logloss: 0.996421\tvalid_1's quad_kappa: 0.49014\n",
      "[2300]\ttraining's multi_logloss: 0.913319\ttraining's quad_kappa: 0.548489\tvalid_1's multi_logloss: 0.995944\tvalid_1's quad_kappa: 0.487394\n",
      "[2400]\ttraining's multi_logloss: 0.909706\ttraining's quad_kappa: 0.550061\tvalid_1's multi_logloss: 0.995791\tvalid_1's quad_kappa: 0.48654\n",
      "[2500]\ttraining's multi_logloss: 0.906137\ttraining's quad_kappa: 0.553049\tvalid_1's multi_logloss: 0.995611\tvalid_1's quad_kappa: 0.48808\n",
      "[2600]\ttraining's multi_logloss: 0.902599\ttraining's quad_kappa: 0.554185\tvalid_1's multi_logloss: 0.995442\tvalid_1's quad_kappa: 0.487664\n",
      "[2700]\ttraining's multi_logloss: 0.899216\ttraining's quad_kappa: 0.55603\tvalid_1's multi_logloss: 0.995443\tvalid_1's quad_kappa: 0.487337\n",
      "[2800]\ttraining's multi_logloss: 0.895968\ttraining's quad_kappa: 0.55752\tvalid_1's multi_logloss: 0.995399\tvalid_1's quad_kappa: 0.485972\n",
      "[2900]\ttraining's multi_logloss: 0.892818\ttraining's quad_kappa: 0.561846\tvalid_1's multi_logloss: 0.995423\tvalid_1's quad_kappa: 0.487609\n",
      "[3000]\ttraining's multi_logloss: 0.889654\ttraining's quad_kappa: 0.56467\tvalid_1's multi_logloss: 0.995578\tvalid_1's quad_kappa: 0.489148\n",
      "[3100]\ttraining's multi_logloss: 0.886526\ttraining's quad_kappa: 0.567622\tvalid_1's multi_logloss: 0.995591\tvalid_1's quad_kappa: 0.490765\n",
      "[3200]\ttraining's multi_logloss: 0.883415\ttraining's quad_kappa: 0.568686\tvalid_1's multi_logloss: 0.99566\tvalid_1's quad_kappa: 0.488757\n",
      "[3300]\ttraining's multi_logloss: 0.880345\ttraining's quad_kappa: 0.570468\tvalid_1's multi_logloss: 0.995951\tvalid_1's quad_kappa: 0.489172\n",
      "[3400]\ttraining's multi_logloss: 0.877333\ttraining's quad_kappa: 0.572055\tvalid_1's multi_logloss: 0.996231\tvalid_1's quad_kappa: 0.488473\n",
      "[3500]\ttraining's multi_logloss: 0.874366\ttraining's quad_kappa: 0.573912\tvalid_1's multi_logloss: 0.996562\tvalid_1's quad_kappa: 0.485727\n",
      "[3600]\ttraining's multi_logloss: 0.871345\ttraining's quad_kappa: 0.576541\tvalid_1's multi_logloss: 0.996767\tvalid_1's quad_kappa: 0.484135\n",
      "Early stopping, best iteration is:                  \n",
      "[1666]\ttraining's multi_logloss: 0.938974\ttraining's quad_kappa: 0.536827\tvalid_1's multi_logloss: 0.999319\tvalid_1's quad_kappa: 0.498068\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[100]\ttraining's multi_logloss: 1.12667\ttraining's quad_kappa: 0.141775\tvalid_1's multi_logloss: 1.13292\tvalid_1's quad_kappa: 0.138291\n",
      "[200]\ttraining's multi_logloss: 1.07678\ttraining's quad_kappa: 0.37275\tvalid_1's multi_logloss: 1.0907\tvalid_1's quad_kappa: 0.361445\n",
      "[300]\ttraining's multi_logloss: 1.0474\ttraining's quad_kappa: 0.39879\tvalid_1's multi_logloss: 1.06855\tvalid_1's quad_kappa: 0.378997\n",
      "[400]\ttraining's multi_logloss: 1.02541\ttraining's quad_kappa: 0.422519\tvalid_1's multi_logloss: 1.05342\tvalid_1's quad_kappa: 0.413763\n",
      "[500]\ttraining's multi_logloss: 1.00865\ttraining's quad_kappa: 0.449531\tvalid_1's multi_logloss: 1.04334\tvalid_1's quad_kappa: 0.415763\n",
      "[600]\ttraining's multi_logloss: 0.994904\ttraining's quad_kappa: 0.479098\tvalid_1's multi_logloss: 1.03537\tvalid_1's quad_kappa: 0.434559\n",
      "[700]\ttraining's multi_logloss: 0.983326\ttraining's quad_kappa: 0.497412\tvalid_1's multi_logloss: 1.02911\tvalid_1's quad_kappa: 0.441388\n",
      "[800]\ttraining's multi_logloss: 0.973437\ttraining's quad_kappa: 0.515543\tvalid_1's multi_logloss: 1.02427\tvalid_1's quad_kappa: 0.462485\n",
      "[900]\ttraining's multi_logloss: 0.964653\ttraining's quad_kappa: 0.53219\tvalid_1's multi_logloss: 1.02015\tvalid_1's quad_kappa: 0.481098\n",
      "[1000]\ttraining's multi_logloss: 0.956731\ttraining's quad_kappa: 0.54221\tvalid_1's multi_logloss: 1.01703\tvalid_1's quad_kappa: 0.486986\n",
      "[1100]\ttraining's multi_logloss: 0.949337\ttraining's quad_kappa: 0.544704\tvalid_1's multi_logloss: 1.01408\tvalid_1's quad_kappa: 0.487471\n",
      "[1200]\ttraining's multi_logloss: 0.942603\ttraining's quad_kappa: 0.5481\tvalid_1's multi_logloss: 1.01193\tvalid_1's quad_kappa: 0.489565\n",
      "[1300]\ttraining's multi_logloss: 0.93631\ttraining's quad_kappa: 0.552323\tvalid_1's multi_logloss: 1.0102\tvalid_1's quad_kappa: 0.497773\n",
      "[1400]\ttraining's multi_logloss: 0.930651\ttraining's quad_kappa: 0.558277\tvalid_1's multi_logloss: 1.00885\tvalid_1's quad_kappa: 0.498447\n",
      "[1500]\ttraining's multi_logloss: 0.925382\ttraining's quad_kappa: 0.561251\tvalid_1's multi_logloss: 1.00746\tvalid_1's quad_kappa: 0.498512\n",
      "[1600]\ttraining's multi_logloss: 0.92035\ttraining's quad_kappa: 0.562886\tvalid_1's multi_logloss: 1.00645\tvalid_1's quad_kappa: 0.497973\n",
      "[1700]\ttraining's multi_logloss: 0.915492\ttraining's quad_kappa: 0.566923\tvalid_1's multi_logloss: 1.00535\tvalid_1's quad_kappa: 0.497322\n",
      "[1800]\ttraining's multi_logloss: 0.910747\ttraining's quad_kappa: 0.57047\tvalid_1's multi_logloss: 1.0045\tvalid_1's quad_kappa: 0.498075\n",
      "[1900]\ttraining's multi_logloss: 0.906252\ttraining's quad_kappa: 0.571635\tvalid_1's multi_logloss: 1.00381\tvalid_1's quad_kappa: 0.502419\n",
      "[2000]\ttraining's multi_logloss: 0.902092\ttraining's quad_kappa: 0.575244\tvalid_1's multi_logloss: 1.00315\tvalid_1's quad_kappa: 0.500366\n",
      "[2100]\ttraining's multi_logloss: 0.897878\ttraining's quad_kappa: 0.578056\tvalid_1's multi_logloss: 1.00266\tvalid_1's quad_kappa: 0.503496\n",
      "[2200]\ttraining's multi_logloss: 0.893898\ttraining's quad_kappa: 0.581257\tvalid_1's multi_logloss: 1.00226\tvalid_1's quad_kappa: 0.50349\n",
      "[2300]\ttraining's multi_logloss: 0.890106\ttraining's quad_kappa: 0.582589\tvalid_1's multi_logloss: 1.00181\tvalid_1's quad_kappa: 0.502771\n",
      "[2400]\ttraining's multi_logloss: 0.886403\ttraining's quad_kappa: 0.584834\tvalid_1's multi_logloss: 1.00133\tvalid_1's quad_kappa: 0.503046\n",
      "[2500]\ttraining's multi_logloss: 0.882783\ttraining's quad_kappa: 0.588413\tvalid_1's multi_logloss: 1.001\tvalid_1's quad_kappa: 0.501016\n",
      "[2600]\ttraining's multi_logloss: 0.879224\ttraining's quad_kappa: 0.589708\tvalid_1's multi_logloss: 1.00067\tvalid_1's quad_kappa: 0.503783\n",
      "[2700]\ttraining's multi_logloss: 0.875752\ttraining's quad_kappa: 0.591785\tvalid_1's multi_logloss: 1.00035\tvalid_1's quad_kappa: 0.504269\n",
      "[2800]\ttraining's multi_logloss: 0.872295\ttraining's quad_kappa: 0.593136\tvalid_1's multi_logloss: 1.00015\tvalid_1's quad_kappa: 0.504749\n",
      "[2900]\ttraining's multi_logloss: 0.869127\ttraining's quad_kappa: 0.594433\tvalid_1's multi_logloss: 0.999974\tvalid_1's quad_kappa: 0.502727\n",
      "[3000]\ttraining's multi_logloss: 0.866024\ttraining's quad_kappa: 0.596675\tvalid_1's multi_logloss: 0.999729\tvalid_1's quad_kappa: 0.504749\n",
      "[3100]\ttraining's multi_logloss: 0.86289\ttraining's quad_kappa: 0.598385\tvalid_1's multi_logloss: 0.999632\tvalid_1's quad_kappa: 0.503064\n",
      "[3200]\ttraining's multi_logloss: 0.859828\ttraining's quad_kappa: 0.601051\tvalid_1's multi_logloss: 0.999496\tvalid_1's quad_kappa: 0.504199\n",
      "[3300]\ttraining's multi_logloss: 0.856773\ttraining's quad_kappa: 0.602699\tvalid_1's multi_logloss: 0.999457\tvalid_1's quad_kappa: 0.503181\n",
      "[3400]\ttraining's multi_logloss: 0.853661\ttraining's quad_kappa: 0.604532\tvalid_1's multi_logloss: 0.9994\tvalid_1's quad_kappa: 0.503897\n",
      "[3500]\ttraining's multi_logloss: 0.850578\ttraining's quad_kappa: 0.607783\tvalid_1's multi_logloss: 0.999197\tvalid_1's quad_kappa: 0.505716\n",
      "[3600]\ttraining's multi_logloss: 0.847661\ttraining's quad_kappa: 0.609228\tvalid_1's multi_logloss: 0.999166\tvalid_1's quad_kappa: 0.505987\n",
      "[3700]\ttraining's multi_logloss: 0.844631\ttraining's quad_kappa: 0.611599\tvalid_1's multi_logloss: 0.999047\tvalid_1's quad_kappa: 0.508899\n",
      "[3800]\ttraining's multi_logloss: 0.841635\ttraining's quad_kappa: 0.612846\tvalid_1's multi_logloss: 0.998995\tvalid_1's quad_kappa: 0.508332\n",
      "[3900]\ttraining's multi_logloss: 0.838739\ttraining's quad_kappa: 0.613531\tvalid_1's multi_logloss: 0.999079\tvalid_1's quad_kappa: 0.508986\n",
      "[4000]\ttraining's multi_logloss: 0.835804\ttraining's quad_kappa: 0.614961\tvalid_1's multi_logloss: 0.999242\tvalid_1's quad_kappa: 0.510976\n",
      "[4100]\ttraining's multi_logloss: 0.832959\ttraining's quad_kappa: 0.616539\tvalid_1's multi_logloss: 0.999346\tvalid_1's quad_kappa: 0.510504\n",
      "[4200]\ttraining's multi_logloss: 0.830081\ttraining's quad_kappa: 0.617963\tvalid_1's multi_logloss: 0.999519\tvalid_1's quad_kappa: 0.509163\n",
      "[4300]\ttraining's multi_logloss: 0.827271\ttraining's quad_kappa: 0.618192\tvalid_1's multi_logloss: 0.999778\tvalid_1's quad_kappa: 0.51003\n",
      "[4400]\ttraining's multi_logloss: 0.824528\ttraining's quad_kappa: 0.618764\tvalid_1's multi_logloss: 0.999972\tvalid_1's quad_kappa: 0.51178\n",
      "[4500]\ttraining's multi_logloss: 0.821889\ttraining's quad_kappa: 0.619757\tvalid_1's multi_logloss: 1.00035\tvalid_1's quad_kappa: 0.512406\n",
      "[4600]\ttraining's multi_logloss: 0.819275\ttraining's quad_kappa: 0.620483\tvalid_1's multi_logloss: 1.00067\tvalid_1's quad_kappa: 0.510655\n",
      "[4700]\ttraining's multi_logloss: 0.816614\ttraining's quad_kappa: 0.620886\tvalid_1's multi_logloss: 1.00087\tvalid_1's quad_kappa: 0.50977\n",
      "[4800]\ttraining's multi_logloss: 0.814073\ttraining's quad_kappa: 0.621553\tvalid_1's multi_logloss: 1.0011\tvalid_1's quad_kappa: 0.511903\n",
      "[4900]\ttraining's multi_logloss: 0.811565\ttraining's quad_kappa: 0.623092\tvalid_1's multi_logloss: 1.00138\tvalid_1's quad_kappa: 0.511903\n",
      "[5000]\ttraining's multi_logloss: 0.809051\ttraining's quad_kappa: 0.625912\tvalid_1's multi_logloss: 1.00184\tvalid_1's quad_kappa: 0.511319\n",
      "[5100]\ttraining's multi_logloss: 0.806484\ttraining's quad_kappa: 0.627283\tvalid_1's multi_logloss: 1.00217\tvalid_1's quad_kappa: 0.512973\n",
      "[5200]\ttraining's multi_logloss: 0.803986\ttraining's quad_kappa: 0.628815\tvalid_1's multi_logloss: 1.00241\tvalid_1's quad_kappa: 0.512252\n",
      "[5300]\ttraining's multi_logloss: 0.8016\ttraining's quad_kappa: 0.630192\tvalid_1's multi_logloss: 1.00286\tvalid_1's quad_kappa: 0.512702\n",
      "[5400]\ttraining's multi_logloss: 0.799157\ttraining's quad_kappa: 0.631261\tvalid_1's multi_logloss: 1.00321\tvalid_1's quad_kappa: 0.51412\n",
      "[5500]\ttraining's multi_logloss: 0.796762\ttraining's quad_kappa: 0.63276\tvalid_1's multi_logloss: 1.00362\tvalid_1's quad_kappa: 0.513712\n",
      "[5600]\ttraining's multi_logloss: 0.794424\ttraining's quad_kappa: 0.632551\tvalid_1's multi_logloss: 1.00406\tvalid_1's quad_kappa: 0.512367\n",
      "[5700]\ttraining's multi_logloss: 0.792076\ttraining's quad_kappa: 0.634143\tvalid_1's multi_logloss: 1.00453\tvalid_1's quad_kappa: 0.510616\n",
      "Early stopping, best iteration is:                  \n",
      "[3798]\ttraining's multi_logloss: 0.841696\ttraining's quad_kappa: 0.612615\tvalid_1's multi_logloss: 0.99899\tvalid_1's quad_kappa: 0.508332\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[100]\ttraining's multi_logloss: 1.14413\ttraining's quad_kappa: 0.200736\tvalid_1's multi_logloss: 1.15472\tvalid_1's quad_kappa: 0.188295\n",
      "[200]\ttraining's multi_logloss: 1.0956\ttraining's quad_kappa: 0.331137\tvalid_1's multi_logloss: 1.11285\tvalid_1's quad_kappa: 0.291164\n",
      "[300]\ttraining's multi_logloss: 1.06565\ttraining's quad_kappa: 0.384076\tvalid_1's multi_logloss: 1.08832\tvalid_1's quad_kappa: 0.361829\n",
      "[400]\ttraining's multi_logloss: 1.04458\ttraining's quad_kappa: 0.411317\tvalid_1's multi_logloss: 1.07234\tvalid_1's quad_kappa: 0.379609\n",
      "[500]\ttraining's multi_logloss: 1.02815\ttraining's quad_kappa: 0.442666\tvalid_1's multi_logloss: 1.06046\tvalid_1's quad_kappa: 0.413701\n",
      "[600]\ttraining's multi_logloss: 1.01517\ttraining's quad_kappa: 0.457859\tvalid_1's multi_logloss: 1.052\tvalid_1's quad_kappa: 0.430956\n",
      "[700]\ttraining's multi_logloss: 1.00339\ttraining's quad_kappa: 0.470049\tvalid_1's multi_logloss: 1.04444\tvalid_1's quad_kappa: 0.443997\n",
      "[800]\ttraining's multi_logloss: 0.993141\ttraining's quad_kappa: 0.48455\tvalid_1's multi_logloss: 1.03821\tvalid_1's quad_kappa: 0.458055\n",
      "[900]\ttraining's multi_logloss: 0.984256\ttraining's quad_kappa: 0.495785\tvalid_1's multi_logloss: 1.03296\tvalid_1's quad_kappa: 0.476408\n",
      "[1000]\ttraining's multi_logloss: 0.976147\ttraining's quad_kappa: 0.508419\tvalid_1's multi_logloss: 1.02856\tvalid_1's quad_kappa: 0.494116\n",
      "[1100]\ttraining's multi_logloss: 0.968824\ttraining's quad_kappa: 0.516778\tvalid_1's multi_logloss: 1.0248\tvalid_1's quad_kappa: 0.504531\n",
      "[1200]\ttraining's multi_logloss: 0.962175\ttraining's quad_kappa: 0.522122\tvalid_1's multi_logloss: 1.02175\tvalid_1's quad_kappa: 0.50719\n",
      "[1300]\ttraining's multi_logloss: 0.955665\ttraining's quad_kappa: 0.526971\tvalid_1's multi_logloss: 1.01857\tvalid_1's quad_kappa: 0.510946\n",
      "[1400]\ttraining's multi_logloss: 0.949764\ttraining's quad_kappa: 0.53252\tvalid_1's multi_logloss: 1.01607\tvalid_1's quad_kappa: 0.516149\n",
      "[1500]\ttraining's multi_logloss: 0.944218\ttraining's quad_kappa: 0.53566\tvalid_1's multi_logloss: 1.01398\tvalid_1's quad_kappa: 0.517389\n",
      "[1600]\ttraining's multi_logloss: 0.939358\ttraining's quad_kappa: 0.538259\tvalid_1's multi_logloss: 1.01224\tvalid_1's quad_kappa: 0.51489\n",
      "[1700]\ttraining's multi_logloss: 0.934723\ttraining's quad_kappa: 0.540777\tvalid_1's multi_logloss: 1.01088\tvalid_1's quad_kappa: 0.516244\n",
      "[1800]\ttraining's multi_logloss: 0.930133\ttraining's quad_kappa: 0.544216\tvalid_1's multi_logloss: 1.00965\tvalid_1's quad_kappa: 0.517515\n",
      "[1900]\ttraining's multi_logloss: 0.925755\ttraining's quad_kappa: 0.546042\tvalid_1's multi_logloss: 1.0086\tvalid_1's quad_kappa: 0.517867\n",
      "[2000]\ttraining's multi_logloss: 0.921457\ttraining's quad_kappa: 0.548593\tvalid_1's multi_logloss: 1.0076\tvalid_1's quad_kappa: 0.523433\n",
      "[2100]\ttraining's multi_logloss: 0.917325\ttraining's quad_kappa: 0.552291\tvalid_1's multi_logloss: 1.00674\tvalid_1's quad_kappa: 0.525643\n",
      "[2200]\ttraining's multi_logloss: 0.91342\ttraining's quad_kappa: 0.553348\tvalid_1's multi_logloss: 1.00591\tvalid_1's quad_kappa: 0.527171\n",
      "[2300]\ttraining's multi_logloss: 0.909581\ttraining's quad_kappa: 0.555753\tvalid_1's multi_logloss: 1.00528\tvalid_1's quad_kappa: 0.526618\n",
      "[2400]\ttraining's multi_logloss: 0.905825\ttraining's quad_kappa: 0.558698\tvalid_1's multi_logloss: 1.00479\tvalid_1's quad_kappa: 0.52596\n",
      "[2500]\ttraining's multi_logloss: 0.90226\ttraining's quad_kappa: 0.561042\tvalid_1's multi_logloss: 1.00422\tvalid_1's quad_kappa: 0.525251\n",
      "[2600]\ttraining's multi_logloss: 0.898688\ttraining's quad_kappa: 0.563843\tvalid_1's multi_logloss: 1.00384\tvalid_1's quad_kappa: 0.526209\n",
      "[2700]\ttraining's multi_logloss: 0.895217\ttraining's quad_kappa: 0.565088\tvalid_1's multi_logloss: 1.00347\tvalid_1's quad_kappa: 0.529249\n",
      "[2800]\ttraining's multi_logloss: 0.891825\ttraining's quad_kappa: 0.568132\tvalid_1's multi_logloss: 1.00301\tvalid_1's quad_kappa: 0.530582\n",
      "[2900]\ttraining's multi_logloss: 0.888563\ttraining's quad_kappa: 0.569298\tvalid_1's multi_logloss: 1.00275\tvalid_1's quad_kappa: 0.533003\n",
      "[3000]\ttraining's multi_logloss: 0.885373\ttraining's quad_kappa: 0.572578\tvalid_1's multi_logloss: 1.00257\tvalid_1's quad_kappa: 0.534937\n",
      "[3100]\ttraining's multi_logloss: 0.882194\ttraining's quad_kappa: 0.573571\tvalid_1's multi_logloss: 1.00239\tvalid_1's quad_kappa: 0.533519\n",
      "[3200]\ttraining's multi_logloss: 0.879084\ttraining's quad_kappa: 0.57568\tvalid_1's multi_logloss: 1.00235\tvalid_1's quad_kappa: 0.533541\n",
      "[3300]\ttraining's multi_logloss: 0.876092\ttraining's quad_kappa: 0.577107\tvalid_1's multi_logloss: 1.00223\tvalid_1's quad_kappa: 0.53321\n",
      "[3400]\ttraining's multi_logloss: 0.873077\ttraining's quad_kappa: 0.579187\tvalid_1's multi_logloss: 1.00202\tvalid_1's quad_kappa: 0.536204\n",
      "[3500]\ttraining's multi_logloss: 0.869959\ttraining's quad_kappa: 0.581442\tvalid_1's multi_logloss: 1.0021\tvalid_1's quad_kappa: 0.536161\n",
      "[3600]\ttraining's multi_logloss: 0.867017\ttraining's quad_kappa: 0.581477\tvalid_1's multi_logloss: 1.00212\tvalid_1's quad_kappa: 0.53452\n",
      "[3700]\ttraining's multi_logloss: 0.86394\ttraining's quad_kappa: 0.583016\tvalid_1's multi_logloss: 1.00232\tvalid_1's quad_kappa: 0.533811\n",
      "[3800]\ttraining's multi_logloss: 0.860994\ttraining's quad_kappa: 0.584643\tvalid_1's multi_logloss: 1.00244\tvalid_1's quad_kappa: 0.53248\n",
      "[3900]\ttraining's multi_logloss: 0.858272\ttraining's quad_kappa: 0.588192\tvalid_1's multi_logloss: 1.0026\tvalid_1's quad_kappa: 0.530793\n",
      "[4000]\ttraining's multi_logloss: 0.855474\ttraining's quad_kappa: 0.589984\tvalid_1's multi_logloss: 1.00281\tvalid_1's quad_kappa: 0.532591\n",
      "[4100]\ttraining's multi_logloss: 0.852803\ttraining's quad_kappa: 0.59091\tvalid_1's multi_logloss: 1.00313\tvalid_1's quad_kappa: 0.529569\n",
      "[4200]\ttraining's multi_logloss: 0.850254\ttraining's quad_kappa: 0.59273\tvalid_1's multi_logloss: 1.00336\tvalid_1's quad_kappa: 0.530571\n",
      "[4300]\ttraining's multi_logloss: 0.847643\ttraining's quad_kappa: 0.594876\tvalid_1's multi_logloss: 1.00359\tvalid_1's quad_kappa: 0.532576\n",
      "[4400]\ttraining's multi_logloss: 0.845054\ttraining's quad_kappa: 0.598844\tvalid_1's multi_logloss: 1.00395\tvalid_1's quad_kappa: 0.53322\n",
      "[4500]\ttraining's multi_logloss: 0.842528\ttraining's quad_kappa: 0.601222\tvalid_1's multi_logloss: 1.00417\tvalid_1's quad_kappa: 0.532933\n",
      "[4600]\ttraining's multi_logloss: 0.839944\ttraining's quad_kappa: 0.603146\tvalid_1's multi_logloss: 1.00441\tvalid_1's quad_kappa: 0.534579\n",
      "[4700]\ttraining's multi_logloss: 0.837436\ttraining's quad_kappa: 0.605394\tvalid_1's multi_logloss: 1.00468\tvalid_1's quad_kappa: 0.534468\n",
      "[4800]\ttraining's multi_logloss: 0.83483\ttraining's quad_kappa: 0.606794\tvalid_1's multi_logloss: 1.00482\tvalid_1's quad_kappa: 0.535825\n",
      "[4900]\ttraining's multi_logloss: 0.832294\ttraining's quad_kappa: 0.608017\tvalid_1's multi_logloss: 1.00494\tvalid_1's quad_kappa: 0.534162\n",
      "[5000]\ttraining's multi_logloss: 0.829754\ttraining's quad_kappa: 0.609741\tvalid_1's multi_logloss: 1.00516\tvalid_1's quad_kappa: 0.534117\n",
      "[5100]\ttraining's multi_logloss: 0.827235\ttraining's quad_kappa: 0.611977\tvalid_1's multi_logloss: 1.00544\tvalid_1's quad_kappa: 0.536658\n",
      "[5200]\ttraining's multi_logloss: 0.824725\ttraining's quad_kappa: 0.613894\tvalid_1's multi_logloss: 1.00569\tvalid_1's quad_kappa: 0.535452\n",
      "[5300]\ttraining's multi_logloss: 0.822298\ttraining's quad_kappa: 0.615569\tvalid_1's multi_logloss: 1.00595\tvalid_1's quad_kappa: 0.537369\n",
      "[5400]\ttraining's multi_logloss: 0.819828\ttraining's quad_kappa: 0.617041\tvalid_1's multi_logloss: 1.00613\tvalid_1's quad_kappa: 0.535723\n",
      "Early stopping, best iteration is:                  \n",
      "[3467]\ttraining's multi_logloss: 0.870988\ttraining's quad_kappa: 0.580556\tvalid_1's multi_logloss: 1.00198\tvalid_1's quad_kappa: 0.535539\n",
      "{'feature_fraction': 0.99, 'lambda_l1': 0.5898038958595597, 'lambda_l2': 0.46615026951135063, 'learning_rate': 0.007, 'max_depth': 7.0, 'metric': 'multiclass', 'n_estimators': 10000, 'num_classes': 4, 'num_leaves': 7, 'objective': 'multiclass', 'random_state': 2019, 'subsample': 0.14}\n",
      "Training until validation scores don't improve for 2000 rounds                   \n",
      "  4%|▍         | 1/25 [13:10<5:15:59, 789.97s/it, best loss: -0.5008594251632342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 1.11871\ttraining's quad_kappa: 0.330799\tvalid_1's multi_logloss: 1.11092\tvalid_1's quad_kappa: 0.311147\n",
      "[200]\ttraining's multi_logloss: 1.07502\ttraining's quad_kappa: 0.390896\tvalid_1's multi_logloss: 1.07412\tvalid_1's quad_kappa: 0.372877\n",
      "[300]\ttraining's multi_logloss: 1.05003\ttraining's quad_kappa: 0.420973\tvalid_1's multi_logloss: 1.0565\tvalid_1's quad_kappa: 0.390781\n",
      "[400]\ttraining's multi_logloss: 1.03184\ttraining's quad_kappa: 0.455069\tvalid_1's multi_logloss: 1.04424\tvalid_1's quad_kappa: 0.4335\n",
      "[500]\ttraining's multi_logloss: 1.01763\ttraining's quad_kappa: 0.47997\tvalid_1's multi_logloss: 1.0345\tvalid_1's quad_kappa: 0.441485\n",
      "[600]\ttraining's multi_logloss: 1.00565\ttraining's quad_kappa: 0.493157\tvalid_1's multi_logloss: 1.0263\tvalid_1's quad_kappa: 0.455342\n",
      "[700]\ttraining's multi_logloss: 0.995223\ttraining's quad_kappa: 0.499543\tvalid_1's multi_logloss: 1.01999\tvalid_1's quad_kappa: 0.47092\n",
      "[800]\ttraining's multi_logloss: 0.985924\ttraining's quad_kappa: 0.504267\tvalid_1's multi_logloss: 1.0153\tvalid_1's quad_kappa: 0.474827\n",
      "[900]\ttraining's multi_logloss: 0.977612\ttraining's quad_kappa: 0.512218\tvalid_1's multi_logloss: 1.01174\tvalid_1's quad_kappa: 0.478901\n",
      "[1000]\ttraining's multi_logloss: 0.970161\ttraining's quad_kappa: 0.518204\tvalid_1's multi_logloss: 1.00969\tvalid_1's quad_kappa: 0.483266\n",
      "[1100]\ttraining's multi_logloss: 0.963292\ttraining's quad_kappa: 0.521813\tvalid_1's multi_logloss: 1.00794\tvalid_1's quad_kappa: 0.484821\n",
      "[1200]\ttraining's multi_logloss: 0.956494\ttraining's quad_kappa: 0.524106\tvalid_1's multi_logloss: 1.0059\tvalid_1's quad_kappa: 0.49019\n",
      "[1300]\ttraining's multi_logloss: 0.950393\ttraining's quad_kappa: 0.524493\tvalid_1's multi_logloss: 1.00418\tvalid_1's quad_kappa: 0.493683\n",
      "[1400]\ttraining's multi_logloss: 0.944532\ttraining's quad_kappa: 0.529603\tvalid_1's multi_logloss: 1.00263\tvalid_1's quad_kappa: 0.492622\n",
      "[1500]\ttraining's multi_logloss: 0.938911\ttraining's quad_kappa: 0.53146\tvalid_1's multi_logloss: 1.00131\tvalid_1's quad_kappa: 0.497096\n",
      "[1600]\ttraining's multi_logloss: 0.933605\ttraining's quad_kappa: 0.53326\tvalid_1's multi_logloss: 1.00036\tvalid_1's quad_kappa: 0.49819\n",
      "[1700]\ttraining's multi_logloss: 0.928463\ttraining's quad_kappa: 0.536846\tvalid_1's multi_logloss: 0.999646\tvalid_1's quad_kappa: 0.49941\n",
      "[1800]\ttraining's multi_logloss: 0.923572\ttraining's quad_kappa: 0.539769\tvalid_1's multi_logloss: 0.999143\tvalid_1's quad_kappa: 0.497747\n",
      "[1900]\ttraining's multi_logloss: 0.918845\ttraining's quad_kappa: 0.543479\tvalid_1's multi_logloss: 0.998562\tvalid_1's quad_kappa: 0.497072\n",
      "[2000]\ttraining's multi_logloss: 0.914232\ttraining's quad_kappa: 0.545207\tvalid_1's multi_logloss: 0.997818\tvalid_1's quad_kappa: 0.496326\n",
      "[2100]\ttraining's multi_logloss: 0.909818\ttraining's quad_kappa: 0.548042\tvalid_1's multi_logloss: 0.997252\tvalid_1's quad_kappa: 0.494028\n",
      "[2200]\ttraining's multi_logloss: 0.905546\ttraining's quad_kappa: 0.550453\tvalid_1's multi_logloss: 0.996795\tvalid_1's quad_kappa: 0.491462\n",
      "[2300]\ttraining's multi_logloss: 0.901381\ttraining's quad_kappa: 0.552772\tvalid_1's multi_logloss: 0.996457\tvalid_1's quad_kappa: 0.493438\n",
      "[2400]\ttraining's multi_logloss: 0.897169\ttraining's quad_kappa: 0.555024\tvalid_1's multi_logloss: 0.996108\tvalid_1's quad_kappa: 0.489642\n",
      "[2500]\ttraining's multi_logloss: 0.893087\ttraining's quad_kappa: 0.558283\tvalid_1's multi_logloss: 0.995796\tvalid_1's quad_kappa: 0.488389\n",
      "[2600]\ttraining's multi_logloss: 0.889123\ttraining's quad_kappa: 0.562406\tvalid_1's multi_logloss: 0.995575\tvalid_1's quad_kappa: 0.485228\n",
      "[2700]\ttraining's multi_logloss: 0.885316\ttraining's quad_kappa: 0.56507\tvalid_1's multi_logloss: 0.99533\tvalid_1's quad_kappa: 0.488304\n",
      "[2800]\ttraining's multi_logloss: 0.881586\ttraining's quad_kappa: 0.567296\tvalid_1's multi_logloss: 0.99525\tvalid_1's quad_kappa: 0.488285\n",
      "[2900]\ttraining's multi_logloss: 0.877919\ttraining's quad_kappa: 0.568444\tvalid_1's multi_logloss: 0.995375\tvalid_1's quad_kappa: 0.487178\n",
      "[3000]\ttraining's multi_logloss: 0.87427\ttraining's quad_kappa: 0.569831\tvalid_1's multi_logloss: 0.99542\tvalid_1's quad_kappa: 0.486761\n",
      "[3100]\ttraining's multi_logloss: 0.870675\ttraining's quad_kappa: 0.570898\tvalid_1's multi_logloss: 0.995446\tvalid_1's quad_kappa: 0.492801\n",
      "[3200]\ttraining's multi_logloss: 0.866976\ttraining's quad_kappa: 0.573432\tvalid_1's multi_logloss: 0.99541\tvalid_1's quad_kappa: 0.493916\n",
      "[3300]\ttraining's multi_logloss: 0.863415\ttraining's quad_kappa: 0.575904\tvalid_1's multi_logloss: 0.995576\tvalid_1's quad_kappa: 0.495177\n",
      "[3400]\ttraining's multi_logloss: 0.859949\ttraining's quad_kappa: 0.577801\tvalid_1's multi_logloss: 0.995656\tvalid_1's quad_kappa: 0.494462\n",
      "[3500]\ttraining's multi_logloss: 0.856575\ttraining's quad_kappa: 0.580703\tvalid_1's multi_logloss: 0.995872\tvalid_1's quad_kappa: 0.495695\n",
      "[3600]\ttraining's multi_logloss: 0.853304\ttraining's quad_kappa: 0.582096\tvalid_1's multi_logloss: 0.996181\tvalid_1's quad_kappa: 0.495455\n",
      "Early stopping, best iteration is:                                               \n",
      "[1678]\ttraining's multi_logloss: 0.929597\ttraining's quad_kappa: 0.535768\tvalid_1's multi_logloss: 0.999788\tvalid_1's quad_kappa: 0.50053\n",
      "Training until validation scores don't improve for 2000 rounds                   \n",
      "[100]\ttraining's multi_logloss: 1.10794\ttraining's quad_kappa: 0.348168\tvalid_1's multi_logloss: 1.11579\tvalid_1's quad_kappa: 0.330736\n",
      "[200]\ttraining's multi_logloss: 1.06071\ttraining's quad_kappa: 0.401251\tvalid_1's multi_logloss: 1.07753\tvalid_1's quad_kappa: 0.3927\n",
      "[300]\ttraining's multi_logloss: 1.03263\ttraining's quad_kappa: 0.454456\tvalid_1's multi_logloss: 1.05652\tvalid_1's quad_kappa: 0.422342\n",
      "[400]\ttraining's multi_logloss: 1.01258\ttraining's quad_kappa: 0.481295\tvalid_1's multi_logloss: 1.04324\tvalid_1's quad_kappa: 0.433708\n",
      "[500]\ttraining's multi_logloss: 0.997068\ttraining's quad_kappa: 0.505543\tvalid_1's multi_logloss: 1.03458\tvalid_1's quad_kappa: 0.463375\n",
      "[600]\ttraining's multi_logloss: 0.984527\ttraining's quad_kappa: 0.51718\tvalid_1's multi_logloss: 1.02814\tvalid_1's quad_kappa: 0.466185\n",
      "[700]\ttraining's multi_logloss: 0.974015\ttraining's quad_kappa: 0.522587\tvalid_1's multi_logloss: 1.02299\tvalid_1's quad_kappa: 0.479113\n",
      "[800]\ttraining's multi_logloss: 0.964415\ttraining's quad_kappa: 0.533117\tvalid_1's multi_logloss: 1.019\tvalid_1's quad_kappa: 0.484013\n",
      "[900]\ttraining's multi_logloss: 0.955939\ttraining's quad_kappa: 0.538699\tvalid_1's multi_logloss: 1.0159\tvalid_1's quad_kappa: 0.484966\n",
      "[1000]\ttraining's multi_logloss: 0.948113\ttraining's quad_kappa: 0.544388\tvalid_1's multi_logloss: 1.01345\tvalid_1's quad_kappa: 0.481534\n",
      "[1100]\ttraining's multi_logloss: 0.940889\ttraining's quad_kappa: 0.5468\tvalid_1's multi_logloss: 1.01164\tvalid_1's quad_kappa: 0.484589\n",
      "[1200]\ttraining's multi_logloss: 0.934337\ttraining's quad_kappa: 0.551803\tvalid_1's multi_logloss: 1.00968\tvalid_1's quad_kappa: 0.486735\n",
      "[1300]\ttraining's multi_logloss: 0.928351\ttraining's quad_kappa: 0.554924\tvalid_1's multi_logloss: 1.00842\tvalid_1's quad_kappa: 0.482187\n",
      "[1400]\ttraining's multi_logloss: 0.922755\ttraining's quad_kappa: 0.55996\tvalid_1's multi_logloss: 1.00739\tvalid_1's quad_kappa: 0.481952\n",
      "[1500]\ttraining's multi_logloss: 0.917588\ttraining's quad_kappa: 0.56325\tvalid_1's multi_logloss: 1.0064\tvalid_1's quad_kappa: 0.482609\n",
      "[1600]\ttraining's multi_logloss: 0.912584\ttraining's quad_kappa: 0.565087\tvalid_1's multi_logloss: 1.00569\tvalid_1's quad_kappa: 0.485071\n",
      "[1700]\ttraining's multi_logloss: 0.907543\ttraining's quad_kappa: 0.566917\tvalid_1's multi_logloss: 1.0047\tvalid_1's quad_kappa: 0.485857\n",
      "[1800]\ttraining's multi_logloss: 0.902472\ttraining's quad_kappa: 0.570225\tvalid_1's multi_logloss: 1.00372\tvalid_1's quad_kappa: 0.488964\n",
      "[1900]\ttraining's multi_logloss: 0.89768\ttraining's quad_kappa: 0.575109\tvalid_1's multi_logloss: 1.00301\tvalid_1's quad_kappa: 0.487522\n",
      "[2000]\ttraining's multi_logloss: 0.892999\ttraining's quad_kappa: 0.576655\tvalid_1's multi_logloss: 1.00238\tvalid_1's quad_kappa: 0.48802\n",
      "[2100]\ttraining's multi_logloss: 0.888501\ttraining's quad_kappa: 0.579179\tvalid_1's multi_logloss: 1.00175\tvalid_1's quad_kappa: 0.488438\n",
      "[2200]\ttraining's multi_logloss: 0.88413\ttraining's quad_kappa: 0.582195\tvalid_1's multi_logloss: 1.0012\tvalid_1's quad_kappa: 0.489166\n",
      "[2300]\ttraining's multi_logloss: 0.879667\ttraining's quad_kappa: 0.583931\tvalid_1's multi_logloss: 1.00082\tvalid_1's quad_kappa: 0.494304\n",
      "[2400]\ttraining's multi_logloss: 0.875352\ttraining's quad_kappa: 0.585301\tvalid_1's multi_logloss: 1.00044\tvalid_1's quad_kappa: 0.493588\n",
      "[2500]\ttraining's multi_logloss: 0.871192\ttraining's quad_kappa: 0.588221\tvalid_1's multi_logloss: 1.00006\tvalid_1's quad_kappa: 0.493204\n",
      "[2600]\ttraining's multi_logloss: 0.867255\ttraining's quad_kappa: 0.590058\tvalid_1's multi_logloss: 0.999691\tvalid_1's quad_kappa: 0.496214\n",
      "[2700]\ttraining's multi_logloss: 0.863397\ttraining's quad_kappa: 0.593711\tvalid_1's multi_logloss: 0.999475\tvalid_1's quad_kappa: 0.497989\n",
      "[2800]\ttraining's multi_logloss: 0.859582\ttraining's quad_kappa: 0.595522\tvalid_1's multi_logloss: 0.999331\tvalid_1's quad_kappa: 0.497072\n",
      "[2900]\ttraining's multi_logloss: 0.855799\ttraining's quad_kappa: 0.598427\tvalid_1's multi_logloss: 0.999283\tvalid_1's quad_kappa: 0.495388\n",
      "[3000]\ttraining's multi_logloss: 0.852125\ttraining's quad_kappa: 0.600303\tvalid_1's multi_logloss: 0.999344\tvalid_1's quad_kappa: 0.496001\n",
      "[3100]\ttraining's multi_logloss: 0.8485\ttraining's quad_kappa: 0.602732\tvalid_1's multi_logloss: 0.999414\tvalid_1's quad_kappa: 0.498166\n",
      "[3200]\ttraining's multi_logloss: 0.844963\ttraining's quad_kappa: 0.606401\tvalid_1's multi_logloss: 0.999377\tvalid_1's quad_kappa: 0.49854\n",
      "[3300]\ttraining's multi_logloss: 0.841511\ttraining's quad_kappa: 0.607819\tvalid_1's multi_logloss: 0.999291\tvalid_1's quad_kappa: 0.498922\n",
      "[3400]\ttraining's multi_logloss: 0.838202\ttraining's quad_kappa: 0.610254\tvalid_1's multi_logloss: 0.999367\tvalid_1's quad_kappa: 0.500334\n",
      "[3500]\ttraining's multi_logloss: 0.834964\ttraining's quad_kappa: 0.613024\tvalid_1's multi_logloss: 0.999589\tvalid_1's quad_kappa: 0.501646\n",
      "[3600]\ttraining's multi_logloss: 0.831707\ttraining's quad_kappa: 0.614398\tvalid_1's multi_logloss: 0.999701\tvalid_1's quad_kappa: 0.501131\n",
      "[3700]\ttraining's multi_logloss: 0.828492\ttraining's quad_kappa: 0.61588\tvalid_1's multi_logloss: 0.999702\tvalid_1's quad_kappa: 0.50584\n",
      "[3800]\ttraining's multi_logloss: 0.825318\ttraining's quad_kappa: 0.617285\tvalid_1's multi_logloss: 0.999695\tvalid_1's quad_kappa: 0.509691\n",
      "[3900]\ttraining's multi_logloss: 0.822181\ttraining's quad_kappa: 0.617681\tvalid_1's multi_logloss: 0.999695\tvalid_1's quad_kappa: 0.510312\n",
      "[4000]\ttraining's multi_logloss: 0.819069\ttraining's quad_kappa: 0.619828\tvalid_1's multi_logloss: 0.999837\tvalid_1's quad_kappa: 0.512169\n",
      "[4100]\ttraining's multi_logloss: 0.81596\ttraining's quad_kappa: 0.620485\tvalid_1's multi_logloss: 0.999914\tvalid_1's quad_kappa: 0.511384\n",
      "[4200]\ttraining's multi_logloss: 0.812932\ttraining's quad_kappa: 0.621964\tvalid_1's multi_logloss: 0.999928\tvalid_1's quad_kappa: 0.512109\n",
      "[4300]\ttraining's multi_logloss: 0.809933\ttraining's quad_kappa: 0.622541\tvalid_1's multi_logloss: 0.99999\tvalid_1's quad_kappa: 0.51077\n",
      "[4400]\ttraining's multi_logloss: 0.806928\ttraining's quad_kappa: 0.623995\tvalid_1's multi_logloss: 0.999987\tvalid_1's quad_kappa: 0.511353\n",
      "[4500]\ttraining's multi_logloss: 0.803941\ttraining's quad_kappa: 0.625389\tvalid_1's multi_logloss: 1.00004\tvalid_1's quad_kappa: 0.51088\n",
      "[4600]\ttraining's multi_logloss: 0.800993\ttraining's quad_kappa: 0.62715\tvalid_1's multi_logloss: 1.00004\tvalid_1's quad_kappa: 0.511052\n",
      "[4700]\ttraining's multi_logloss: 0.798107\ttraining's quad_kappa: 0.628569\tvalid_1's multi_logloss: 1.00015\tvalid_1's quad_kappa: 0.510369\n",
      "[4800]\ttraining's multi_logloss: 0.795275\ttraining's quad_kappa: 0.630841\tvalid_1's multi_logloss: 1.00048\tvalid_1's quad_kappa: 0.510823\n",
      "Early stopping, best iteration is:                                               \n",
      "[2847]\ttraining's multi_logloss: 0.8578\ttraining's quad_kappa: 0.596898\tvalid_1's multi_logloss: 0.99922\tvalid_1's quad_kappa: 0.497575\n",
      "Training until validation scores don't improve for 2000 rounds                   \n",
      "[100]\ttraining's multi_logloss: 1.1282\ttraining's quad_kappa: 0.311296\tvalid_1's multi_logloss: 1.13686\tvalid_1's quad_kappa: 0.289875\n",
      "[200]\ttraining's multi_logloss: 1.08186\ttraining's quad_kappa: 0.383463\tvalid_1's multi_logloss: 1.09693\tvalid_1's quad_kappa: 0.361518\n",
      "[300]\ttraining's multi_logloss: 1.05337\ttraining's quad_kappa: 0.429352\tvalid_1's multi_logloss: 1.0736\tvalid_1's quad_kappa: 0.415527\n",
      "[400]\ttraining's multi_logloss: 1.03309\ttraining's quad_kappa: 0.453294\tvalid_1's multi_logloss: 1.05818\tvalid_1's quad_kappa: 0.446516\n",
      "[500]\ttraining's multi_logloss: 1.017\ttraining's quad_kappa: 0.476865\tvalid_1's multi_logloss: 1.04663\tvalid_1's quad_kappa: 0.477067\n",
      "[600]\ttraining's multi_logloss: 1.00368\ttraining's quad_kappa: 0.493783\tvalid_1's multi_logloss: 1.03767\tvalid_1's quad_kappa: 0.485892\n",
      "[700]\ttraining's multi_logloss: 0.992241\ttraining's quad_kappa: 0.502045\tvalid_1's multi_logloss: 1.02988\tvalid_1's quad_kappa: 0.490193\n",
      "[800]\ttraining's multi_logloss: 0.982286\ttraining's quad_kappa: 0.51462\tvalid_1's multi_logloss: 1.02395\tvalid_1's quad_kappa: 0.500274\n",
      "[900]\ttraining's multi_logloss: 0.973813\ttraining's quad_kappa: 0.522393\tvalid_1's multi_logloss: 1.01947\tvalid_1's quad_kappa: 0.505498\n",
      "[1000]\ttraining's multi_logloss: 0.966073\ttraining's quad_kappa: 0.525257\tvalid_1's multi_logloss: 1.01591\tvalid_1's quad_kappa: 0.505417\n",
      "[1100]\ttraining's multi_logloss: 0.958827\ttraining's quad_kappa: 0.52873\tvalid_1's multi_logloss: 1.01246\tvalid_1's quad_kappa: 0.510955\n",
      "[1200]\ttraining's multi_logloss: 0.952366\ttraining's quad_kappa: 0.533003\tvalid_1's multi_logloss: 1.00984\tvalid_1's quad_kappa: 0.516586\n",
      "[1300]\ttraining's multi_logloss: 0.946218\ttraining's quad_kappa: 0.535804\tvalid_1's multi_logloss: 1.00774\tvalid_1's quad_kappa: 0.518726\n",
      "[1400]\ttraining's multi_logloss: 0.940301\ttraining's quad_kappa: 0.538045\tvalid_1's multi_logloss: 1.00591\tvalid_1's quad_kappa: 0.524354\n",
      "[1500]\ttraining's multi_logloss: 0.934497\ttraining's quad_kappa: 0.541702\tvalid_1's multi_logloss: 1.0042\tvalid_1's quad_kappa: 0.525184\n",
      "[1600]\ttraining's multi_logloss: 0.929157\ttraining's quad_kappa: 0.547099\tvalid_1's multi_logloss: 1.00302\tvalid_1's quad_kappa: 0.520474\n",
      "[1700]\ttraining's multi_logloss: 0.924174\ttraining's quad_kappa: 0.550712\tvalid_1's multi_logloss: 1.00191\tvalid_1's quad_kappa: 0.525011\n",
      "[1800]\ttraining's multi_logloss: 0.919421\ttraining's quad_kappa: 0.553934\tvalid_1's multi_logloss: 1.00093\tvalid_1's quad_kappa: 0.521972\n",
      "[1900]\ttraining's multi_logloss: 0.914731\ttraining's quad_kappa: 0.554647\tvalid_1's multi_logloss: 1.00001\tvalid_1's quad_kappa: 0.528506\n",
      "[2000]\ttraining's multi_logloss: 0.910029\ttraining's quad_kappa: 0.558114\tvalid_1's multi_logloss: 0.999185\tvalid_1's quad_kappa: 0.530196\n",
      "[2100]\ttraining's multi_logloss: 0.905447\ttraining's quad_kappa: 0.559389\tvalid_1's multi_logloss: 0.998475\tvalid_1's quad_kappa: 0.533842\n",
      "[2200]\ttraining's multi_logloss: 0.900995\ttraining's quad_kappa: 0.563426\tvalid_1's multi_logloss: 0.99776\tvalid_1's quad_kappa: 0.538083\n",
      "[2300]\ttraining's multi_logloss: 0.896641\ttraining's quad_kappa: 0.56483\tvalid_1's multi_logloss: 0.996935\tvalid_1's quad_kappa: 0.544232\n",
      "[2400]\ttraining's multi_logloss: 0.892486\ttraining's quad_kappa: 0.567282\tvalid_1's multi_logloss: 0.996184\tvalid_1's quad_kappa: 0.540726\n",
      "[2500]\ttraining's multi_logloss: 0.888402\ttraining's quad_kappa: 0.567711\tvalid_1's multi_logloss: 0.995574\tvalid_1's quad_kappa: 0.540506\n",
      "[2600]\ttraining's multi_logloss: 0.884357\ttraining's quad_kappa: 0.569917\tvalid_1's multi_logloss: 0.995311\tvalid_1's quad_kappa: 0.536247\n",
      "[2700]\ttraining's multi_logloss: 0.88029\ttraining's quad_kappa: 0.57248\tvalid_1's multi_logloss: 0.995036\tvalid_1's quad_kappa: 0.536648\n",
      "[2800]\ttraining's multi_logloss: 0.876325\ttraining's quad_kappa: 0.574769\tvalid_1's multi_logloss: 0.994658\tvalid_1's quad_kappa: 0.538558\n",
      "[2900]\ttraining's multi_logloss: 0.872465\ttraining's quad_kappa: 0.577681\tvalid_1's multi_logloss: 0.994122\tvalid_1's quad_kappa: 0.538336\n",
      "[3000]\ttraining's multi_logloss: 0.868624\ttraining's quad_kappa: 0.579746\tvalid_1's multi_logloss: 0.993717\tvalid_1's quad_kappa: 0.537209\n",
      "[3100]\ttraining's multi_logloss: 0.864933\ttraining's quad_kappa: 0.582816\tvalid_1's multi_logloss: 0.993474\tvalid_1's quad_kappa: 0.537351\n",
      "[3200]\ttraining's multi_logloss: 0.861359\ttraining's quad_kappa: 0.585092\tvalid_1's multi_logloss: 0.993322\tvalid_1's quad_kappa: 0.536374\n",
      "[3300]\ttraining's multi_logloss: 0.857828\ttraining's quad_kappa: 0.588491\tvalid_1's multi_logloss: 0.993295\tvalid_1's quad_kappa: 0.536621\n",
      "[3400]\ttraining's multi_logloss: 0.854388\ttraining's quad_kappa: 0.591088\tvalid_1's multi_logloss: 0.993276\tvalid_1's quad_kappa: 0.537735\n",
      "[3500]\ttraining's multi_logloss: 0.850903\ttraining's quad_kappa: 0.593896\tvalid_1's multi_logloss: 0.99319\tvalid_1's quad_kappa: 0.536021\n",
      "[3600]\ttraining's multi_logloss: 0.847495\ttraining's quad_kappa: 0.596508\tvalid_1's multi_logloss: 0.993123\tvalid_1's quad_kappa: 0.538917\n",
      "[3700]\ttraining's multi_logloss: 0.844264\ttraining's quad_kappa: 0.598683\tvalid_1's multi_logloss: 0.993027\tvalid_1's quad_kappa: 0.538292\n",
      "[3800]\ttraining's multi_logloss: 0.841037\ttraining's quad_kappa: 0.599102\tvalid_1's multi_logloss: 0.993006\tvalid_1's quad_kappa: 0.538961\n",
      "[3900]\ttraining's multi_logloss: 0.837845\ttraining's quad_kappa: 0.601424\tvalid_1's multi_logloss: 0.992984\tvalid_1's quad_kappa: 0.540211\n",
      "[4000]\ttraining's multi_logloss: 0.834716\ttraining's quad_kappa: 0.603959\tvalid_1's multi_logloss: 0.99311\tvalid_1's quad_kappa: 0.53883\n",
      "[4100]\ttraining's multi_logloss: 0.831649\ttraining's quad_kappa: 0.604937\tvalid_1's multi_logloss: 0.993273\tvalid_1's quad_kappa: 0.541137\n",
      "[4200]\ttraining's multi_logloss: 0.82854\ttraining's quad_kappa: 0.607307\tvalid_1's multi_logloss: 0.99334\tvalid_1's quad_kappa: 0.538891\n",
      "Early stopping, best iteration is:                                               \n",
      "[2271]\ttraining's multi_logloss: 0.897871\ttraining's quad_kappa: 0.563733\tvalid_1's multi_logloss: 0.997156\tvalid_1's quad_kappa: 0.544232\n",
      "{'feature_fraction': 0.22, 'lambda_l1': 0.10824873946327764, 'lambda_l2': 0.28213053257198845, 'learning_rate': 0.007, 'max_depth': 5.0, 'metric': 'multiclass', 'n_estimators': 10000, 'num_classes': 4, 'num_leaves': 31, 'objective': 'multiclass', 'random_state': 2019, 'subsample': 0.5}\n",
      "Training until validation scores don't improve for 2000 rounds                   \n",
      "  8%|▊         | 2/25 [24:11<4:47:58, 751.24s/it, best loss: -0.5032286503292337]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 1.14119\ttraining's quad_kappa: 0.00678929\tvalid_1's multi_logloss: 1.1499\tvalid_1's quad_kappa: 0.00700368\n",
      "[200]\ttraining's multi_logloss: 1.08208\ttraining's quad_kappa: 0.224708\tvalid_1's multi_logloss: 1.10941\tvalid_1's quad_kappa: 0.196999\n",
      "[300]\ttraining's multi_logloss: 1.0415\ttraining's quad_kappa: 0.350541\tvalid_1's multi_logloss: 1.08573\tvalid_1's quad_kappa: 0.313262\n",
      "[400]\ttraining's multi_logloss: 1.00504\ttraining's quad_kappa: 0.454693\tvalid_1's multi_logloss: 1.06461\tvalid_1's quad_kappa: 0.39041\n",
      "[500]\ttraining's multi_logloss: 0.976874\ttraining's quad_kappa: 0.495834\tvalid_1's multi_logloss: 1.05076\tvalid_1's quad_kappa: 0.424073\n",
      "[600]\ttraining's multi_logloss: 0.951886\ttraining's quad_kappa: 0.526788\tvalid_1's multi_logloss: 1.03896\tvalid_1's quad_kappa: 0.430497\n",
      "[700]\ttraining's multi_logloss: 0.932268\ttraining's quad_kappa: 0.55264\tvalid_1's multi_logloss: 1.03094\tvalid_1's quad_kappa: 0.455781\n",
      "[800]\ttraining's multi_logloss: 0.914362\ttraining's quad_kappa: 0.564932\tvalid_1's multi_logloss: 1.02378\tvalid_1's quad_kappa: 0.465586\n",
      "[900]\ttraining's multi_logloss: 0.898919\ttraining's quad_kappa: 0.57624\tvalid_1's multi_logloss: 1.01872\tvalid_1's quad_kappa: 0.480584\n",
      "[1000]\ttraining's multi_logloss: 0.884928\ttraining's quad_kappa: 0.58544\tvalid_1's multi_logloss: 1.0143\tvalid_1's quad_kappa: 0.475233\n",
      "[1100]\ttraining's multi_logloss: 0.872055\ttraining's quad_kappa: 0.592632\tvalid_1's multi_logloss: 1.01037\tvalid_1's quad_kappa: 0.479959\n",
      "[1200]\ttraining's multi_logloss: 0.861006\ttraining's quad_kappa: 0.599434\tvalid_1's multi_logloss: 1.00814\tvalid_1's quad_kappa: 0.474782\n",
      "[1300]\ttraining's multi_logloss: 0.850733\ttraining's quad_kappa: 0.60577\tvalid_1's multi_logloss: 1.00621\tvalid_1's quad_kappa: 0.478635\n",
      "[1400]\ttraining's multi_logloss: 0.841209\ttraining's quad_kappa: 0.611415\tvalid_1's multi_logloss: 1.00488\tvalid_1's quad_kappa: 0.478225\n",
      "[1500]\ttraining's multi_logloss: 0.831229\ttraining's quad_kappa: 0.617099\tvalid_1's multi_logloss: 1.00308\tvalid_1's quad_kappa: 0.480777\n",
      "[1600]\ttraining's multi_logloss: 0.822387\ttraining's quad_kappa: 0.621516\tvalid_1's multi_logloss: 1.00225\tvalid_1's quad_kappa: 0.48463\n",
      "[1700]\ttraining's multi_logloss: 0.81346\ttraining's quad_kappa: 0.627131\tvalid_1's multi_logloss: 1.00142\tvalid_1's quad_kappa: 0.490046\n",
      "[1800]\ttraining's multi_logloss: 0.804998\ttraining's quad_kappa: 0.631027\tvalid_1's multi_logloss: 1.00072\tvalid_1's quad_kappa: 0.491171\n",
      "[1900]\ttraining's multi_logloss: 0.797637\ttraining's quad_kappa: 0.634392\tvalid_1's multi_logloss: 1.00083\tvalid_1's quad_kappa: 0.490833\n",
      "[2000]\ttraining's multi_logloss: 0.790352\ttraining's quad_kappa: 0.637634\tvalid_1's multi_logloss: 1.00073\tvalid_1's quad_kappa: 0.492294\n",
      "[2100]\ttraining's multi_logloss: 0.782948\ttraining's quad_kappa: 0.641913\tvalid_1's multi_logloss: 1.00071\tvalid_1's quad_kappa: 0.497479\n",
      "[2200]\ttraining's multi_logloss: 0.775193\ttraining's quad_kappa: 0.64571\tvalid_1's multi_logloss: 1.0007\tvalid_1's quad_kappa: 0.498785\n",
      "[2300]\ttraining's multi_logloss: 0.767957\ttraining's quad_kappa: 0.64889\tvalid_1's multi_logloss: 1.00109\tvalid_1's quad_kappa: 0.500299\n",
      "[2400]\ttraining's multi_logloss: 0.761276\ttraining's quad_kappa: 0.651519\tvalid_1's multi_logloss: 1.00152\tvalid_1's quad_kappa: 0.500547\n",
      "[2500]\ttraining's multi_logloss: 0.754605\ttraining's quad_kappa: 0.654996\tvalid_1's multi_logloss: 1.00226\tvalid_1's quad_kappa: 0.5019\n",
      "[2600]\ttraining's multi_logloss: 0.748153\ttraining's quad_kappa: 0.658368\tvalid_1's multi_logloss: 1.00314\tvalid_1's quad_kappa: 0.50304\n",
      "[2700]\ttraining's multi_logloss: 0.742128\ttraining's quad_kappa: 0.661874\tvalid_1's multi_logloss: 1.0039\tvalid_1's quad_kappa: 0.503047\n",
      "[2800]\ttraining's multi_logloss: 0.736002\ttraining's quad_kappa: 0.665023\tvalid_1's multi_logloss: 1.00468\tvalid_1's quad_kappa: 0.502844\n",
      "[2900]\ttraining's multi_logloss: 0.729815\ttraining's quad_kappa: 0.668833\tvalid_1's multi_logloss: 1.00543\tvalid_1's quad_kappa: 0.504045\n",
      "[3000]\ttraining's multi_logloss: 0.723855\ttraining's quad_kappa: 0.670526\tvalid_1's multi_logloss: 1.00619\tvalid_1's quad_kappa: 0.504045\n",
      "[3100]\ttraining's multi_logloss: 0.718136\ttraining's quad_kappa: 0.673835\tvalid_1's multi_logloss: 1.00731\tvalid_1's quad_kappa: 0.503427\n",
      "[3200]\ttraining's multi_logloss: 0.712576\ttraining's quad_kappa: 0.675853\tvalid_1's multi_logloss: 1.00818\tvalid_1's quad_kappa: 0.504492\n",
      "[3300]\ttraining's multi_logloss: 0.706842\ttraining's quad_kappa: 0.678244\tvalid_1's multi_logloss: 1.00921\tvalid_1's quad_kappa: 0.506964\n",
      "[3400]\ttraining's multi_logloss: 0.70119\ttraining's quad_kappa: 0.681615\tvalid_1's multi_logloss: 1.01027\tvalid_1's quad_kappa: 0.507755\n",
      "[3500]\ttraining's multi_logloss: 0.69578\ttraining's quad_kappa: 0.68512\tvalid_1's multi_logloss: 1.01145\tvalid_1's quad_kappa: 0.508032\n",
      "[3600]\ttraining's multi_logloss: 0.690316\ttraining's quad_kappa: 0.687858\tvalid_1's multi_logloss: 1.01265\tvalid_1's quad_kappa: 0.509386\n",
      "[3700]\ttraining's multi_logloss: 0.685149\ttraining's quad_kappa: 0.691341\tvalid_1's multi_logloss: 1.01378\tvalid_1's quad_kappa: 0.509078\n",
      "[3800]\ttraining's multi_logloss: 0.680097\ttraining's quad_kappa: 0.695779\tvalid_1's multi_logloss: 1.01496\tvalid_1's quad_kappa: 0.506137\n",
      "[3900]\ttraining's multi_logloss: 0.675202\ttraining's quad_kappa: 0.69882\tvalid_1's multi_logloss: 1.01613\tvalid_1's quad_kappa: 0.508371\n",
      "[4000]\ttraining's multi_logloss: 0.670558\ttraining's quad_kappa: 0.702993\tvalid_1's multi_logloss: 1.01719\tvalid_1's quad_kappa: 0.506177\n",
      "[4100]\ttraining's multi_logloss: 0.665583\ttraining's quad_kappa: 0.70722\tvalid_1's multi_logloss: 1.01815\tvalid_1's quad_kappa: 0.5079\n",
      "Early stopping, best iteration is:                                               \n",
      "[2136]\ttraining's multi_logloss: 0.779964\ttraining's quad_kappa: 0.64443\tvalid_1's multi_logloss: 1.00058\tvalid_1's quad_kappa: 0.498132\n",
      "Training until validation scores don't improve for 2000 rounds                   \n",
      "[100]\ttraining's multi_logloss: 1.13016\ttraining's quad_kappa: 0.0565444\tvalid_1's multi_logloss: 1.14871\tvalid_1's quad_kappa: 0.0488908\n",
      "[200]\ttraining's multi_logloss: 1.06728\ttraining's quad_kappa: 0.283375\tvalid_1's multi_logloss: 1.10524\tvalid_1's quad_kappa: 0.257557\n",
      "[300]\ttraining's multi_logloss: 1.02463\ttraining's quad_kappa: 0.392748\tvalid_1's multi_logloss: 1.07973\tvalid_1's quad_kappa: 0.343437\n",
      "[400]\ttraining's multi_logloss: 0.987078\ttraining's quad_kappa: 0.487901\tvalid_1's multi_logloss: 1.05819\tvalid_1's quad_kappa: 0.419845\n",
      "[500]\ttraining's multi_logloss: 0.959164\ttraining's quad_kappa: 0.524205\tvalid_1's multi_logloss: 1.04412\tvalid_1's quad_kappa: 0.454873\n",
      "[600]\ttraining's multi_logloss: 0.934888\ttraining's quad_kappa: 0.54778\tvalid_1's multi_logloss: 1.03273\tvalid_1's quad_kappa: 0.470525\n",
      "[700]\ttraining's multi_logloss: 0.916012\ttraining's quad_kappa: 0.564534\tvalid_1's multi_logloss: 1.0248\tvalid_1's quad_kappa: 0.477998\n",
      "[800]\ttraining's multi_logloss: 0.898452\ttraining's quad_kappa: 0.583686\tvalid_1's multi_logloss: 1.01761\tvalid_1's quad_kappa: 0.492574\n",
      "[900]\ttraining's multi_logloss: 0.882988\ttraining's quad_kappa: 0.593742\tvalid_1's multi_logloss: 1.01249\tvalid_1's quad_kappa: 0.494657\n",
      "[1000]\ttraining's multi_logloss: 0.868941\ttraining's quad_kappa: 0.603371\tvalid_1's multi_logloss: 1.00819\tvalid_1's quad_kappa: 0.496435\n",
      "[1100]\ttraining's multi_logloss: 0.855911\ttraining's quad_kappa: 0.611556\tvalid_1's multi_logloss: 1.00433\tvalid_1's quad_kappa: 0.496896\n",
      "[1200]\ttraining's multi_logloss: 0.844726\ttraining's quad_kappa: 0.617481\tvalid_1's multi_logloss: 1.00195\tvalid_1's quad_kappa: 0.495934\n",
      "[1300]\ttraining's multi_logloss: 0.834394\ttraining's quad_kappa: 0.622794\tvalid_1's multi_logloss: 1.00014\tvalid_1's quad_kappa: 0.494194\n",
      "[1400]\ttraining's multi_logloss: 0.824554\ttraining's quad_kappa: 0.626272\tvalid_1's multi_logloss: 0.998633\tvalid_1's quad_kappa: 0.49733\n",
      "[1500]\ttraining's multi_logloss: 0.814453\ttraining's quad_kappa: 0.631604\tvalid_1's multi_logloss: 0.996894\tvalid_1's quad_kappa: 0.49928\n",
      "[1600]\ttraining's multi_logloss: 0.805534\ttraining's quad_kappa: 0.63774\tvalid_1's multi_logloss: 0.995921\tvalid_1's quad_kappa: 0.499326\n",
      "[1700]\ttraining's multi_logloss: 0.796741\ttraining's quad_kappa: 0.641413\tvalid_1's multi_logloss: 0.99519\tvalid_1's quad_kappa: 0.498661\n",
      "[1800]\ttraining's multi_logloss: 0.787871\ttraining's quad_kappa: 0.64636\tvalid_1's multi_logloss: 0.994379\tvalid_1's quad_kappa: 0.498301\n",
      "[1900]\ttraining's multi_logloss: 0.780234\ttraining's quad_kappa: 0.650776\tvalid_1's multi_logloss: 0.994408\tvalid_1's quad_kappa: 0.500374\n",
      "[2000]\ttraining's multi_logloss: 0.772565\ttraining's quad_kappa: 0.654393\tvalid_1's multi_logloss: 0.994312\tvalid_1's quad_kappa: 0.499106\n",
      "[2100]\ttraining's multi_logloss: 0.765015\ttraining's quad_kappa: 0.657457\tvalid_1's multi_logloss: 0.994091\tvalid_1's quad_kappa: 0.498933\n",
      "[2200]\ttraining's multi_logloss: 0.757247\ttraining's quad_kappa: 0.659724\tvalid_1's multi_logloss: 0.994028\tvalid_1's quad_kappa: 0.498313\n",
      "[2300]\ttraining's multi_logloss: 0.749735\ttraining's quad_kappa: 0.663095\tvalid_1's multi_logloss: 0.994258\tvalid_1's quad_kappa: 0.500571\n",
      "[2400]\ttraining's multi_logloss: 0.742144\ttraining's quad_kappa: 0.667351\tvalid_1's multi_logloss: 0.994547\tvalid_1's quad_kappa: 0.502413\n",
      "[2500]\ttraining's multi_logloss: 0.734929\ttraining's quad_kappa: 0.671371\tvalid_1's multi_logloss: 0.994814\tvalid_1's quad_kappa: 0.506737\n",
      "[2600]\ttraining's multi_logloss: 0.728107\ttraining's quad_kappa: 0.675064\tvalid_1's multi_logloss: 0.99551\tvalid_1's quad_kappa: 0.507577\n",
      "[2700]\ttraining's multi_logloss: 0.722029\ttraining's quad_kappa: 0.67901\tvalid_1's multi_logloss: 0.99645\tvalid_1's quad_kappa: 0.511102\n",
      "[2800]\ttraining's multi_logloss: 0.715567\ttraining's quad_kappa: 0.681296\tvalid_1's multi_logloss: 0.997126\tvalid_1's quad_kappa: 0.516064\n",
      "[2900]\ttraining's multi_logloss: 0.709522\ttraining's quad_kappa: 0.684089\tvalid_1's multi_logloss: 0.997823\tvalid_1's quad_kappa: 0.516841\n",
      "[3000]\ttraining's multi_logloss: 0.703295\ttraining's quad_kappa: 0.687145\tvalid_1's multi_logloss: 0.998575\tvalid_1's quad_kappa: 0.518646\n",
      "[3100]\ttraining's multi_logloss: 0.697477\ttraining's quad_kappa: 0.688674\tvalid_1's multi_logloss: 0.999629\tvalid_1's quad_kappa: 0.518598\n",
      "[3200]\ttraining's multi_logloss: 0.692024\ttraining's quad_kappa: 0.691131\tvalid_1's multi_logloss: 1.00058\tvalid_1's quad_kappa: 0.52033\n",
      "[3300]\ttraining's multi_logloss: 0.686577\ttraining's quad_kappa: 0.694532\tvalid_1's multi_logloss: 1.00157\tvalid_1's quad_kappa: 0.517894\n",
      "[3400]\ttraining's multi_logloss: 0.681252\ttraining's quad_kappa: 0.69776\tvalid_1's multi_logloss: 1.00268\tvalid_1's quad_kappa: 0.520828\n",
      "[3500]\ttraining's multi_logloss: 0.676002\ttraining's quad_kappa: 0.701871\tvalid_1's multi_logloss: 1.00352\tvalid_1's quad_kappa: 0.524166\n",
      "[3600]\ttraining's multi_logloss: 0.670557\ttraining's quad_kappa: 0.70461\tvalid_1's multi_logloss: 1.00462\tvalid_1's quad_kappa: 0.52322\n",
      "[3700]\ttraining's multi_logloss: 0.665171\ttraining's quad_kappa: 0.706817\tvalid_1's multi_logloss: 1.00566\tvalid_1's quad_kappa: 0.523625\n",
      "[3800]\ttraining's multi_logloss: 0.660167\ttraining's quad_kappa: 0.709201\tvalid_1's multi_logloss: 1.00695\tvalid_1's quad_kappa: 0.523098\n",
      "[3900]\ttraining's multi_logloss: 0.654952\ttraining's quad_kappa: 0.711118\tvalid_1's multi_logloss: 1.00817\tvalid_1's quad_kappa: 0.525942\n",
      "[4000]\ttraining's multi_logloss: 0.650232\ttraining's quad_kappa: 0.713747\tvalid_1's multi_logloss: 1.00928\tvalid_1's quad_kappa: 0.52343\n",
      "[4100]\ttraining's multi_logloss: 0.64515\ttraining's quad_kappa: 0.715438\tvalid_1's multi_logloss: 1.01042\tvalid_1's quad_kappa: 0.521714\n",
      "Early stopping, best iteration is:                                               \n",
      "[2138]\ttraining's multi_logloss: 0.761903\ttraining's quad_kappa: 0.658504\tvalid_1's multi_logloss: 0.993919\tvalid_1's quad_kappa: 0.497937\n",
      "Training until validation scores don't improve for 2000 rounds                   \n",
      "[100]\ttraining's multi_logloss: 1.14277\ttraining's quad_kappa: 0.0511216\tvalid_1's multi_logloss: 1.16652\tvalid_1's quad_kappa: 0.0441286\n",
      "[200]\ttraining's multi_logloss: 1.07984\ttraining's quad_kappa: 0.280587\tvalid_1's multi_logloss: 1.12059\tvalid_1's quad_kappa: 0.243242\n",
      "[300]\ttraining's multi_logloss: 1.0369\ttraining's quad_kappa: 0.39625\tvalid_1's multi_logloss: 1.09349\tvalid_1's quad_kappa: 0.322507\n",
      "[400]\ttraining's multi_logloss: 0.999475\ttraining's quad_kappa: 0.481855\tvalid_1's multi_logloss: 1.07053\tvalid_1's quad_kappa: 0.418882\n",
      "[500]\ttraining's multi_logloss: 0.97057\ttraining's quad_kappa: 0.512377\tvalid_1's multi_logloss: 1.05548\tvalid_1's quad_kappa: 0.442326\n",
      "[600]\ttraining's multi_logloss: 0.945493\ttraining's quad_kappa: 0.530304\tvalid_1's multi_logloss: 1.04302\tvalid_1's quad_kappa: 0.453437\n",
      "[700]\ttraining's multi_logloss: 0.925603\ttraining's quad_kappa: 0.555151\tvalid_1's multi_logloss: 1.03473\tvalid_1's quad_kappa: 0.464107\n",
      "[800]\ttraining's multi_logloss: 0.907222\ttraining's quad_kappa: 0.570535\tvalid_1's multi_logloss: 1.02706\tvalid_1's quad_kappa: 0.485202\n",
      "[900]\ttraining's multi_logloss: 0.891246\ttraining's quad_kappa: 0.581059\tvalid_1's multi_logloss: 1.02116\tvalid_1's quad_kappa: 0.490187\n",
      "[1000]\ttraining's multi_logloss: 0.876915\ttraining's quad_kappa: 0.589319\tvalid_1's multi_logloss: 1.01641\tvalid_1's quad_kappa: 0.494412\n",
      "[1100]\ttraining's multi_logloss: 0.863682\ttraining's quad_kappa: 0.598977\tvalid_1's multi_logloss: 1.01238\tvalid_1's quad_kappa: 0.499807\n",
      "[1200]\ttraining's multi_logloss: 0.852575\ttraining's quad_kappa: 0.604678\tvalid_1's multi_logloss: 1.00967\tvalid_1's quad_kappa: 0.507671\n",
      "[1300]\ttraining's multi_logloss: 0.842193\ttraining's quad_kappa: 0.613338\tvalid_1's multi_logloss: 1.00745\tvalid_1's quad_kappa: 0.509893\n",
      "[1400]\ttraining's multi_logloss: 0.832383\ttraining's quad_kappa: 0.620247\tvalid_1's multi_logloss: 1.00544\tvalid_1's quad_kappa: 0.511791\n",
      "[1500]\ttraining's multi_logloss: 0.822181\ttraining's quad_kappa: 0.626195\tvalid_1's multi_logloss: 1.00324\tvalid_1's quad_kappa: 0.516908\n",
      "[1600]\ttraining's multi_logloss: 0.813563\ttraining's quad_kappa: 0.628292\tvalid_1's multi_logloss: 1.00196\tvalid_1's quad_kappa: 0.516979\n",
      "[1700]\ttraining's multi_logloss: 0.804994\ttraining's quad_kappa: 0.634518\tvalid_1's multi_logloss: 1.00087\tvalid_1's quad_kappa: 0.523176\n",
      "[1800]\ttraining's multi_logloss: 0.796493\ttraining's quad_kappa: 0.639391\tvalid_1's multi_logloss: 0.999809\tvalid_1's quad_kappa: 0.525487\n",
      "[1900]\ttraining's multi_logloss: 0.789073\ttraining's quad_kappa: 0.643424\tvalid_1's multi_logloss: 0.999727\tvalid_1's quad_kappa: 0.530819\n",
      "[2000]\ttraining's multi_logloss: 0.781701\ttraining's quad_kappa: 0.647798\tvalid_1's multi_logloss: 0.999214\tvalid_1's quad_kappa: 0.534075\n",
      "[2100]\ttraining's multi_logloss: 0.77428\ttraining's quad_kappa: 0.651764\tvalid_1's multi_logloss: 0.999055\tvalid_1's quad_kappa: 0.539348\n",
      "[2200]\ttraining's multi_logloss: 0.766728\ttraining's quad_kappa: 0.654803\tvalid_1's multi_logloss: 0.999047\tvalid_1's quad_kappa: 0.537594\n",
      "[2300]\ttraining's multi_logloss: 0.759514\ttraining's quad_kappa: 0.656935\tvalid_1's multi_logloss: 0.998884\tvalid_1's quad_kappa: 0.535254\n",
      "[2400]\ttraining's multi_logloss: 0.752553\ttraining's quad_kappa: 0.658806\tvalid_1's multi_logloss: 0.99909\tvalid_1's quad_kappa: 0.537178\n",
      "[2500]\ttraining's multi_logloss: 0.745846\ttraining's quad_kappa: 0.662462\tvalid_1's multi_logloss: 0.999348\tvalid_1's quad_kappa: 0.540151\n",
      "[2600]\ttraining's multi_logloss: 0.73934\ttraining's quad_kappa: 0.664874\tvalid_1's multi_logloss: 0.99977\tvalid_1's quad_kappa: 0.539129\n",
      "[2700]\ttraining's multi_logloss: 0.733913\ttraining's quad_kappa: 0.667814\tvalid_1's multi_logloss: 1.0004\tvalid_1's quad_kappa: 0.536445\n",
      "[2800]\ttraining's multi_logloss: 0.727794\ttraining's quad_kappa: 0.671793\tvalid_1's multi_logloss: 1.00115\tvalid_1's quad_kappa: 0.536179\n",
      "[2900]\ttraining's multi_logloss: 0.72199\ttraining's quad_kappa: 0.673052\tvalid_1's multi_logloss: 1.00189\tvalid_1's quad_kappa: 0.532986\n",
      "[3000]\ttraining's multi_logloss: 0.716194\ttraining's quad_kappa: 0.675005\tvalid_1's multi_logloss: 1.00259\tvalid_1's quad_kappa: 0.534596\n",
      "[3100]\ttraining's multi_logloss: 0.71073\ttraining's quad_kappa: 0.676597\tvalid_1's multi_logloss: 1.00358\tvalid_1's quad_kappa: 0.535333\n",
      "[3200]\ttraining's multi_logloss: 0.705307\ttraining's quad_kappa: 0.679841\tvalid_1's multi_logloss: 1.00449\tvalid_1's quad_kappa: 0.538404\n",
      "[3300]\ttraining's multi_logloss: 0.699907\ttraining's quad_kappa: 0.683698\tvalid_1's multi_logloss: 1.00535\tvalid_1's quad_kappa: 0.536593\n",
      "[3400]\ttraining's multi_logloss: 0.694792\ttraining's quad_kappa: 0.685769\tvalid_1's multi_logloss: 1.00613\tvalid_1's quad_kappa: 0.537962\n",
      "[3500]\ttraining's multi_logloss: 0.68983\ttraining's quad_kappa: 0.689098\tvalid_1's multi_logloss: 1.00712\tvalid_1's quad_kappa: 0.536998\n",
      "[3600]\ttraining's multi_logloss: 0.685089\ttraining's quad_kappa: 0.691846\tvalid_1's multi_logloss: 1.00824\tvalid_1's quad_kappa: 0.538187\n",
      "[3700]\ttraining's multi_logloss: 0.680283\ttraining's quad_kappa: 0.694528\tvalid_1's multi_logloss: 1.00916\tvalid_1's quad_kappa: 0.538187\n",
      "[3800]\ttraining's multi_logloss: 0.675537\ttraining's quad_kappa: 0.69521\tvalid_1's multi_logloss: 1.01016\tvalid_1's quad_kappa: 0.539336\n",
      "[3900]\ttraining's multi_logloss: 0.670905\ttraining's quad_kappa: 0.696239\tvalid_1's multi_logloss: 1.01127\tvalid_1's quad_kappa: 0.536194\n",
      "[4000]\ttraining's multi_logloss: 0.666299\ttraining's quad_kappa: 0.699019\tvalid_1's multi_logloss: 1.0124\tvalid_1's quad_kappa: 0.534465\n",
      "[4100]\ttraining's multi_logloss: 0.661583\ttraining's quad_kappa: 0.701869\tvalid_1's multi_logloss: 1.01355\tvalid_1's quad_kappa: 0.534129\n",
      "Early stopping, best iteration is:                                               \n",
      "[2134]\ttraining's multi_logloss: 0.771505\ttraining's quad_kappa: 0.652553\tvalid_1's multi_logloss: 0.998836\tvalid_1's quad_kappa: 0.540713\n",
      "{'feature_fraction': 0.58, 'lambda_l1': 0.45619796864269707, 'lambda_l2': 0.033257384218246686, 'learning_rate': 0.007, 'max_depth': 14.0, 'metric': 'multiclass', 'n_estimators': 10000, 'num_classes': 4, 'num_leaves': 31, 'objective': 'multiclass', 'random_state': 2019, 'subsample': 0.9500000000000001}\n",
      "Training until validation scores don't improve for 2000 rounds                   \n",
      " 12%|█▏        | 3/25 [35:13<4:25:44, 724.74s/it, best loss: -0.5130700898122246]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 1.09017\ttraining's quad_kappa: 0.184839\tvalid_1's multi_logloss: 1.1145\tvalid_1's quad_kappa: 0.162364\n",
      "[200]\ttraining's multi_logloss: 1.00815\ttraining's quad_kappa: 0.464852\tvalid_1's multi_logloss: 1.06198\tvalid_1's quad_kappa: 0.425616\n",
      "[300]\ttraining's multi_logloss: 0.954668\ttraining's quad_kappa: 0.529659\tvalid_1's multi_logloss: 1.03538\tvalid_1's quad_kappa: 0.445519\n",
      "[400]\ttraining's multi_logloss: 0.912858\ttraining's quad_kappa: 0.562269\tvalid_1's multi_logloss: 1.01845\tvalid_1's quad_kappa: 0.464727\n",
      "[500]\ttraining's multi_logloss: 0.880797\ttraining's quad_kappa: 0.580601\tvalid_1's multi_logloss: 1.00944\tvalid_1's quad_kappa: 0.470109\n",
      "[600]\ttraining's multi_logloss: 0.853583\ttraining's quad_kappa: 0.597996\tvalid_1's multi_logloss: 1.00364\tvalid_1's quad_kappa: 0.474902\n",
      "[700]\ttraining's multi_logloss: 0.830137\ttraining's quad_kappa: 0.613224\tvalid_1's multi_logloss: 1.00038\tvalid_1's quad_kappa: 0.483596\n",
      "[800]\ttraining's multi_logloss: 0.808976\ttraining's quad_kappa: 0.623316\tvalid_1's multi_logloss: 0.998925\tvalid_1's quad_kappa: 0.486946\n",
      "[900]\ttraining's multi_logloss: 0.789516\ttraining's quad_kappa: 0.633628\tvalid_1's multi_logloss: 0.998383\tvalid_1's quad_kappa: 0.489871\n",
      "[1000]\ttraining's multi_logloss: 0.771462\ttraining's quad_kappa: 0.648172\tvalid_1's multi_logloss: 0.998603\tvalid_1's quad_kappa: 0.489316\n",
      "[1100]\ttraining's multi_logloss: 0.754702\ttraining's quad_kappa: 0.656426\tvalid_1's multi_logloss: 0.998982\tvalid_1's quad_kappa: 0.489395\n",
      "[1200]\ttraining's multi_logloss: 0.739162\ttraining's quad_kappa: 0.663934\tvalid_1's multi_logloss: 0.999609\tvalid_1's quad_kappa: 0.485653\n",
      "[1300]\ttraining's multi_logloss: 0.724994\ttraining's quad_kappa: 0.671037\tvalid_1's multi_logloss: 1.00042\tvalid_1's quad_kappa: 0.48397\n",
      "[1400]\ttraining's multi_logloss: 0.7119\ttraining's quad_kappa: 0.676741\tvalid_1's multi_logloss: 1.00144\tvalid_1's quad_kappa: 0.48558\n",
      "[1500]\ttraining's multi_logloss: 0.69953\ttraining's quad_kappa: 0.682908\tvalid_1's multi_logloss: 1.00253\tvalid_1's quad_kappa: 0.485195\n",
      "[1600]\ttraining's multi_logloss: 0.68759\ttraining's quad_kappa: 0.690325\tvalid_1's multi_logloss: 1.00361\tvalid_1's quad_kappa: 0.485519\n",
      "[1700]\ttraining's multi_logloss: 0.676141\ttraining's quad_kappa: 0.698092\tvalid_1's multi_logloss: 1.00487\tvalid_1's quad_kappa: 0.483952\n",
      "[1800]\ttraining's multi_logloss: 0.665131\ttraining's quad_kappa: 0.703168\tvalid_1's multi_logloss: 1.0061\tvalid_1's quad_kappa: 0.482543\n",
      "[1900]\ttraining's multi_logloss: 0.654254\ttraining's quad_kappa: 0.710048\tvalid_1's multi_logloss: 1.00768\tvalid_1's quad_kappa: 0.485804\n",
      "[2000]\ttraining's multi_logloss: 0.643818\ttraining's quad_kappa: 0.716045\tvalid_1's multi_logloss: 1.00914\tvalid_1's quad_kappa: 0.488562\n",
      "[2100]\ttraining's multi_logloss: 0.633718\ttraining's quad_kappa: 0.724195\tvalid_1's multi_logloss: 1.01055\tvalid_1's quad_kappa: 0.487734\n",
      "[2200]\ttraining's multi_logloss: 0.624088\ttraining's quad_kappa: 0.729967\tvalid_1's multi_logloss: 1.01269\tvalid_1's quad_kappa: 0.490595\n",
      "[2300]\ttraining's multi_logloss: 0.614511\ttraining's quad_kappa: 0.736123\tvalid_1's multi_logloss: 1.01433\tvalid_1's quad_kappa: 0.492091\n",
      "[2400]\ttraining's multi_logloss: 0.605358\ttraining's quad_kappa: 0.741037\tvalid_1's multi_logloss: 1.0161\tvalid_1's quad_kappa: 0.494535\n",
      "[2500]\ttraining's multi_logloss: 0.596546\ttraining's quad_kappa: 0.745704\tvalid_1's multi_logloss: 1.01781\tvalid_1's quad_kappa: 0.500592\n",
      "[2600]\ttraining's multi_logloss: 0.587861\ttraining's quad_kappa: 0.751899\tvalid_1's multi_logloss: 1.01964\tvalid_1's quad_kappa: 0.504882\n",
      "[2700]\ttraining's multi_logloss: 0.57952\ttraining's quad_kappa: 0.757214\tvalid_1's multi_logloss: 1.02165\tvalid_1's quad_kappa: 0.504124\n",
      "[2800]\ttraining's multi_logloss: 0.5712\ttraining's quad_kappa: 0.760266\tvalid_1's multi_logloss: 1.02325\tvalid_1's quad_kappa: 0.502855\n",
      "Early stopping, best iteration is:                                               \n",
      "[866]\ttraining's multi_logloss: 0.796021\ttraining's quad_kappa: 0.630645\tvalid_1's multi_logloss: 0.998225\tvalid_1's quad_kappa: 0.490543\n",
      "Training until validation scores don't improve for 2000 rounds                   \n",
      "[100]\ttraining's multi_logloss: 1.07708\ttraining's quad_kappa: 0.254931\tvalid_1's multi_logloss: 1.11196\tvalid_1's quad_kappa: 0.226209\n",
      "[200]\ttraining's multi_logloss: 0.991016\ttraining's quad_kappa: 0.499819\tvalid_1's multi_logloss: 1.05769\tvalid_1's quad_kappa: 0.439819\n",
      "[300]\ttraining's multi_logloss: 0.935744\ttraining's quad_kappa: 0.560292\tvalid_1's multi_logloss: 1.02958\tvalid_1's quad_kappa: 0.483112\n",
      "[400]\ttraining's multi_logloss: 0.893269\ttraining's quad_kappa: 0.586199\tvalid_1's multi_logloss: 1.01226\tvalid_1's quad_kappa: 0.497224\n",
      "[500]\ttraining's multi_logloss: 0.860585\ttraining's quad_kappa: 0.60264\tvalid_1's multi_logloss: 1.00285\tvalid_1's quad_kappa: 0.51\n",
      "[600]\ttraining's multi_logloss: 0.833478\ttraining's quad_kappa: 0.616565\tvalid_1's multi_logloss: 0.997392\tvalid_1's quad_kappa: 0.512962\n",
      "[700]\ttraining's multi_logloss: 0.809916\ttraining's quad_kappa: 0.628163\tvalid_1's multi_logloss: 0.994279\tvalid_1's quad_kappa: 0.512201\n",
      "[800]\ttraining's multi_logloss: 0.788691\ttraining's quad_kappa: 0.641867\tvalid_1's multi_logloss: 0.992187\tvalid_1's quad_kappa: 0.516325\n",
      "[900]\ttraining's multi_logloss: 0.769168\ttraining's quad_kappa: 0.652464\tvalid_1's multi_logloss: 0.990614\tvalid_1's quad_kappa: 0.515974\n",
      "[1000]\ttraining's multi_logloss: 0.751424\ttraining's quad_kappa: 0.662521\tvalid_1's multi_logloss: 0.990022\tvalid_1's quad_kappa: 0.517878\n",
      "[1100]\ttraining's multi_logloss: 0.73507\ttraining's quad_kappa: 0.6726\tvalid_1's multi_logloss: 0.989688\tvalid_1's quad_kappa: 0.518578\n",
      "[1200]\ttraining's multi_logloss: 0.720337\ttraining's quad_kappa: 0.682138\tvalid_1's multi_logloss: 0.989752\tvalid_1's quad_kappa: 0.521625\n",
      "[1300]\ttraining's multi_logloss: 0.706386\ttraining's quad_kappa: 0.688618\tvalid_1's multi_logloss: 0.990072\tvalid_1's quad_kappa: 0.521549\n",
      "[1400]\ttraining's multi_logloss: 0.693135\ttraining's quad_kappa: 0.69555\tvalid_1's multi_logloss: 0.990926\tvalid_1's quad_kappa: 0.520392\n",
      "[1500]\ttraining's multi_logloss: 0.680573\ttraining's quad_kappa: 0.700067\tvalid_1's multi_logloss: 0.991915\tvalid_1's quad_kappa: 0.521203\n",
      "[1600]\ttraining's multi_logloss: 0.668576\ttraining's quad_kappa: 0.706442\tvalid_1's multi_logloss: 0.993287\tvalid_1's quad_kappa: 0.52478\n",
      "[1700]\ttraining's multi_logloss: 0.65714\ttraining's quad_kappa: 0.712623\tvalid_1's multi_logloss: 0.994801\tvalid_1's quad_kappa: 0.526112\n",
      "[1800]\ttraining's multi_logloss: 0.645843\ttraining's quad_kappa: 0.721089\tvalid_1's multi_logloss: 0.996696\tvalid_1's quad_kappa: 0.524123\n",
      "[1900]\ttraining's multi_logloss: 0.635037\ttraining's quad_kappa: 0.72858\tvalid_1's multi_logloss: 0.998587\tvalid_1's quad_kappa: 0.522075\n",
      "[2000]\ttraining's multi_logloss: 0.624526\ttraining's quad_kappa: 0.733917\tvalid_1's multi_logloss: 1.00019\tvalid_1's quad_kappa: 0.52337\n",
      "[2100]\ttraining's multi_logloss: 0.614321\ttraining's quad_kappa: 0.738783\tvalid_1's multi_logloss: 1.00199\tvalid_1's quad_kappa: 0.517273\n",
      "[2200]\ttraining's multi_logloss: 0.604409\ttraining's quad_kappa: 0.742963\tvalid_1's multi_logloss: 1.00377\tvalid_1's quad_kappa: 0.517737\n",
      "[2300]\ttraining's multi_logloss: 0.59491\ttraining's quad_kappa: 0.748385\tvalid_1's multi_logloss: 1.00559\tvalid_1's quad_kappa: 0.519108\n",
      "[2400]\ttraining's multi_logloss: 0.585836\ttraining's quad_kappa: 0.754934\tvalid_1's multi_logloss: 1.0078\tvalid_1's quad_kappa: 0.521578\n",
      "[2500]\ttraining's multi_logloss: 0.576857\ttraining's quad_kappa: 0.759408\tvalid_1's multi_logloss: 1.0096\tvalid_1's quad_kappa: 0.526168\n",
      "[2600]\ttraining's multi_logloss: 0.568113\ttraining's quad_kappa: 0.763811\tvalid_1's multi_logloss: 1.01155\tvalid_1's quad_kappa: 0.528862\n",
      "[2700]\ttraining's multi_logloss: 0.559726\ttraining's quad_kappa: 0.76833\tvalid_1's multi_logloss: 1.01325\tvalid_1's quad_kappa: 0.531716\n",
      "[2800]\ttraining's multi_logloss: 0.551267\ttraining's quad_kappa: 0.772917\tvalid_1's multi_logloss: 1.01484\tvalid_1's quad_kappa: 0.529157\n",
      "[2900]\ttraining's multi_logloss: 0.54321\ttraining's quad_kappa: 0.777742\tvalid_1's multi_logloss: 1.01669\tvalid_1's quad_kappa: 0.535644\n",
      "[3000]\ttraining's multi_logloss: 0.535251\ttraining's quad_kappa: 0.782304\tvalid_1's multi_logloss: 1.01835\tvalid_1's quad_kappa: 0.530486\n",
      "[3100]\ttraining's multi_logloss: 0.527491\ttraining's quad_kappa: 0.786344\tvalid_1's multi_logloss: 1.02027\tvalid_1's quad_kappa: 0.530797\n",
      "Early stopping, best iteration is:                                               \n",
      "[1122]\ttraining's multi_logloss: 0.731657\ttraining's quad_kappa: 0.674193\tvalid_1's multi_logloss: 0.98951\tvalid_1's quad_kappa: 0.520453\n",
      "Training until validation scores don't improve for 2000 rounds                   \n",
      "[100]\ttraining's multi_logloss: 1.09156\ttraining's quad_kappa: 0.242945\tvalid_1's multi_logloss: 1.12761\tvalid_1's quad_kappa: 0.205183\n",
      "[200]\ttraining's multi_logloss: 1.00584\ttraining's quad_kappa: 0.480254\tvalid_1's multi_logloss: 1.06949\tvalid_1's quad_kappa: 0.434608\n",
      "[300]\ttraining's multi_logloss: 0.95086\ttraining's quad_kappa: 0.53864\tvalid_1's multi_logloss: 1.03946\tvalid_1's quad_kappa: 0.485623\n",
      "[400]\ttraining's multi_logloss: 0.908617\ttraining's quad_kappa: 0.570569\tvalid_1's multi_logloss: 1.02006\tvalid_1's quad_kappa: 0.516626\n",
      "[500]\ttraining's multi_logloss: 0.875326\ttraining's quad_kappa: 0.592708\tvalid_1's multi_logloss: 1.00927\tvalid_1's quad_kappa: 0.528249\n",
      "[600]\ttraining's multi_logloss: 0.847163\ttraining's quad_kappa: 0.609008\tvalid_1's multi_logloss: 1.00227\tvalid_1's quad_kappa: 0.535332\n",
      "[700]\ttraining's multi_logloss: 0.823114\ttraining's quad_kappa: 0.621723\tvalid_1's multi_logloss: 0.997898\tvalid_1's quad_kappa: 0.537577\n",
      "[800]\ttraining's multi_logloss: 0.802161\ttraining's quad_kappa: 0.632501\tvalid_1's multi_logloss: 0.99512\tvalid_1's quad_kappa: 0.537411\n",
      "[900]\ttraining's multi_logloss: 0.783012\ttraining's quad_kappa: 0.641901\tvalid_1's multi_logloss: 0.993442\tvalid_1's quad_kappa: 0.542888\n",
      "[1000]\ttraining's multi_logloss: 0.765438\ttraining's quad_kappa: 0.650691\tvalid_1's multi_logloss: 0.992624\tvalid_1's quad_kappa: 0.542622\n",
      "[1100]\ttraining's multi_logloss: 0.749189\ttraining's quad_kappa: 0.658926\tvalid_1's multi_logloss: 0.992088\tvalid_1's quad_kappa: 0.543741\n",
      "[1200]\ttraining's multi_logloss: 0.734367\ttraining's quad_kappa: 0.669219\tvalid_1's multi_logloss: 0.992106\tvalid_1's quad_kappa: 0.541925\n",
      "[1300]\ttraining's multi_logloss: 0.720569\ttraining's quad_kappa: 0.679161\tvalid_1's multi_logloss: 0.992382\tvalid_1's quad_kappa: 0.540834\n",
      "[1400]\ttraining's multi_logloss: 0.707681\ttraining's quad_kappa: 0.685635\tvalid_1's multi_logloss: 0.9935\tvalid_1's quad_kappa: 0.539928\n",
      "[1500]\ttraining's multi_logloss: 0.695434\ttraining's quad_kappa: 0.691363\tvalid_1's multi_logloss: 0.994781\tvalid_1's quad_kappa: 0.541288\n",
      "[1600]\ttraining's multi_logloss: 0.683554\ttraining's quad_kappa: 0.697927\tvalid_1's multi_logloss: 0.996075\tvalid_1's quad_kappa: 0.545932\n",
      "[1700]\ttraining's multi_logloss: 0.672084\ttraining's quad_kappa: 0.703533\tvalid_1's multi_logloss: 0.997491\tvalid_1's quad_kappa: 0.539577\n",
      "[1800]\ttraining's multi_logloss: 0.660956\ttraining's quad_kappa: 0.710891\tvalid_1's multi_logloss: 0.999166\tvalid_1's quad_kappa: 0.543087\n",
      "[1900]\ttraining's multi_logloss: 0.650153\ttraining's quad_kappa: 0.718226\tvalid_1's multi_logloss: 1.00066\tvalid_1's quad_kappa: 0.545163\n",
      "[2000]\ttraining's multi_logloss: 0.639478\ttraining's quad_kappa: 0.72499\tvalid_1's multi_logloss: 1.00232\tvalid_1's quad_kappa: 0.545019\n",
      "[2100]\ttraining's multi_logloss: 0.629482\ttraining's quad_kappa: 0.731138\tvalid_1's multi_logloss: 1.00405\tvalid_1's quad_kappa: 0.544834\n",
      "[2200]\ttraining's multi_logloss: 0.619596\ttraining's quad_kappa: 0.735503\tvalid_1's multi_logloss: 1.0058\tvalid_1's quad_kappa: 0.548063\n",
      "[2300]\ttraining's multi_logloss: 0.610083\ttraining's quad_kappa: 0.741569\tvalid_1's multi_logloss: 1.00791\tvalid_1's quad_kappa: 0.546952\n",
      "[2400]\ttraining's multi_logloss: 0.600713\ttraining's quad_kappa: 0.746742\tvalid_1's multi_logloss: 1.0097\tvalid_1's quad_kappa: 0.546687\n",
      "[2500]\ttraining's multi_logloss: 0.591628\ttraining's quad_kappa: 0.752833\tvalid_1's multi_logloss: 1.01144\tvalid_1's quad_kappa: 0.546269\n",
      "[2600]\ttraining's multi_logloss: 0.58291\ttraining's quad_kappa: 0.757483\tvalid_1's multi_logloss: 1.01332\tvalid_1's quad_kappa: 0.548837\n",
      "[2700]\ttraining's multi_logloss: 0.574434\ttraining's quad_kappa: 0.762958\tvalid_1's multi_logloss: 1.0151\tvalid_1's quad_kappa: 0.550873\n",
      "[2800]\ttraining's multi_logloss: 0.566119\ttraining's quad_kappa: 0.767637\tvalid_1's multi_logloss: 1.01698\tvalid_1's quad_kappa: 0.553568\n",
      "[2900]\ttraining's multi_logloss: 0.558117\ttraining's quad_kappa: 0.772602\tvalid_1's multi_logloss: 1.01895\tvalid_1's quad_kappa: 0.553077\n",
      "[3000]\ttraining's multi_logloss: 0.550271\ttraining's quad_kappa: 0.775006\tvalid_1's multi_logloss: 1.02106\tvalid_1's quad_kappa: 0.554036\n",
      "[3100]\ttraining's multi_logloss: 0.54265\ttraining's quad_kappa: 0.78013\tvalid_1's multi_logloss: 1.02315\tvalid_1's quad_kappa: 0.55322\n",
      "Early stopping, best iteration is:                                               \n",
      "[1131]\ttraining's multi_logloss: 0.744399\ttraining's quad_kappa: 0.6624\tvalid_1's multi_logloss: 0.991907\tvalid_1's quad_kappa: 0.542358\n",
      "{'feature_fraction': 0.68, 'lambda_l1': 0.4989870787833573, 'lambda_l2': 0.2797842989494472, 'learning_rate': 0.007, 'max_depth': 13.0, 'metric': 'multiclass', 'n_estimators': 10000, 'num_classes': 4, 'num_leaves': 4095, 'objective': 'multiclass', 'random_state': 2019, 'subsample': 0.5}\n",
      " 16%|█▌        | 4/25 [44:49<3:57:57, 679.89s/it, best loss: -0.5188369088259418]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2000 rounds                   \n",
      "[100]\ttraining's multi_logloss: 0.988471\ttraining's quad_kappa: 0.364645\tvalid_1's multi_logloss: 1.09842\tvalid_1's quad_kappa: 0.250467\n",
      "[200]\ttraining's multi_logloss: 0.844101\ttraining's quad_kappa: 0.619084\tvalid_1's multi_logloss: 1.04701\tvalid_1's quad_kappa: 0.447323\n",
      "[300]\ttraining's multi_logloss: 0.742388\ttraining's quad_kappa: 0.695747\tvalid_1's multi_logloss: 1.02396\tvalid_1's quad_kappa: 0.470528\n",
      "[400]\ttraining's multi_logloss: 0.665349\ttraining's quad_kappa: 0.737957\tvalid_1's multi_logloss: 1.01402\tvalid_1's quad_kappa: 0.486434\n",
      "[500]\ttraining's multi_logloss: 0.603425\ttraining's quad_kappa: 0.769357\tvalid_1's multi_logloss: 1.01228\tvalid_1's quad_kappa: 0.486881\n",
      "[600]\ttraining's multi_logloss: 0.554989\ttraining's quad_kappa: 0.793363\tvalid_1's multi_logloss: 1.01453\tvalid_1's quad_kappa: 0.491967\n",
      "[700]\ttraining's multi_logloss: 0.515906\ttraining's quad_kappa: 0.810023\tvalid_1's multi_logloss: 1.01807\tvalid_1's quad_kappa: 0.489315\n",
      "[800]\ttraining's multi_logloss: 0.483176\ttraining's quad_kappa: 0.824059\tvalid_1's multi_logloss: 1.0238\tvalid_1's quad_kappa: 0.487712\n",
      "[900]\ttraining's multi_logloss: 0.454307\ttraining's quad_kappa: 0.840601\tvalid_1's multi_logloss: 1.03058\tvalid_1's quad_kappa: 0.493023\n",
      "[1000]\ttraining's multi_logloss: 0.428304\ttraining's quad_kappa: 0.850159\tvalid_1's multi_logloss: 1.03804\tvalid_1's quad_kappa: 0.492036\n",
      "[1100]\ttraining's multi_logloss: 0.404417\ttraining's quad_kappa: 0.860852\tvalid_1's multi_logloss: 1.04568\tvalid_1's quad_kappa: 0.496258\n",
      "[1200]\ttraining's multi_logloss: 0.382908\ttraining's quad_kappa: 0.869964\tvalid_1's multi_logloss: 1.05355\tvalid_1's quad_kappa: 0.495869\n",
      "[1300]\ttraining's multi_logloss: 0.363098\ttraining's quad_kappa: 0.876954\tvalid_1's multi_logloss: 1.06197\tvalid_1's quad_kappa: 0.497331\n",
      "[1400]\ttraining's multi_logloss: 0.345295\ttraining's quad_kappa: 0.883245\tvalid_1's multi_logloss: 1.07012\tvalid_1's quad_kappa: 0.501252\n",
      "[1500]\ttraining's multi_logloss: 0.328152\ttraining's quad_kappa: 0.887612\tvalid_1's multi_logloss: 1.07889\tvalid_1's quad_kappa: 0.499951\n",
      "[1600]\ttraining's multi_logloss: 0.312806\ttraining's quad_kappa: 0.892157\tvalid_1's multi_logloss: 1.08793\tvalid_1's quad_kappa: 0.498557\n",
      "[1700]\ttraining's multi_logloss: 0.298441\ttraining's quad_kappa: 0.898834\tvalid_1's multi_logloss: 1.09628\tvalid_1's quad_kappa: 0.500022\n",
      "[1800]\ttraining's multi_logloss: 0.285173\ttraining's quad_kappa: 0.906535\tvalid_1's multi_logloss: 1.10489\tvalid_1's quad_kappa: 0.504949\n",
      "[1900]\ttraining's multi_logloss: 0.2729\ttraining's quad_kappa: 0.912321\tvalid_1's multi_logloss: 1.11374\tvalid_1's quad_kappa: 0.509951\n",
      "[2000]\ttraining's multi_logloss: 0.261617\ttraining's quad_kappa: 0.917855\tvalid_1's multi_logloss: 1.12199\tvalid_1's quad_kappa: 0.506461\n",
      "[2100]\ttraining's multi_logloss: 0.250903\ttraining's quad_kappa: 0.922565\tvalid_1's multi_logloss: 1.12994\tvalid_1's quad_kappa: 0.50647\n",
      "[2200]\ttraining's multi_logloss: 0.241191\ttraining's quad_kappa: 0.926763\tvalid_1's multi_logloss: 1.13835\tvalid_1's quad_kappa: 0.509048\n",
      "[2300]\ttraining's multi_logloss: 0.231871\ttraining's quad_kappa: 0.931586\tvalid_1's multi_logloss: 1.14585\tvalid_1's quad_kappa: 0.507869\n",
      "[2400]\ttraining's multi_logloss: 0.223355\ttraining's quad_kappa: 0.935109\tvalid_1's multi_logloss: 1.15324\tvalid_1's quad_kappa: 0.509027\n",
      "Early stopping, best iteration is:                                               \n",
      "[490]\ttraining's multi_logloss: 0.608919\ttraining's quad_kappa: 0.767363\tvalid_1's multi_logloss: 1.01218\tvalid_1's quad_kappa: 0.487589\n",
      "Training until validation scores don't improve for 2000 rounds                   \n",
      "[100]\ttraining's multi_logloss: 0.978819\ttraining's quad_kappa: 0.422262\tvalid_1's multi_logloss: 1.09226\tvalid_1's quad_kappa: 0.309358\n",
      "[200]\ttraining's multi_logloss: 0.831411\ttraining's quad_kappa: 0.638742\tvalid_1's multi_logloss: 1.03684\tvalid_1's quad_kappa: 0.467922\n",
      "[300]\ttraining's multi_logloss: 0.726499\ttraining's quad_kappa: 0.704576\tvalid_1's multi_logloss: 1.01164\tvalid_1's quad_kappa: 0.513779\n",
      "[400]\ttraining's multi_logloss: 0.647217\ttraining's quad_kappa: 0.742974\tvalid_1's multi_logloss: 1.00073\tvalid_1's quad_kappa: 0.51812\n",
      "[500]\ttraining's multi_logloss: 0.586292\ttraining's quad_kappa: 0.775072\tvalid_1's multi_logloss: 0.998225\tvalid_1's quad_kappa: 0.520565\n",
      "[600]\ttraining's multi_logloss: 0.537904\ttraining's quad_kappa: 0.799123\tvalid_1's multi_logloss: 1.00049\tvalid_1's quad_kappa: 0.523772\n",
      "[700]\ttraining's multi_logloss: 0.497451\ttraining's quad_kappa: 0.822071\tvalid_1's multi_logloss: 1.0057\tvalid_1's quad_kappa: 0.521865\n",
      "[800]\ttraining's multi_logloss: 0.464486\ttraining's quad_kappa: 0.836976\tvalid_1's multi_logloss: 1.01193\tvalid_1's quad_kappa: 0.532024\n",
      "[900]\ttraining's multi_logloss: 0.436333\ttraining's quad_kappa: 0.850748\tvalid_1's multi_logloss: 1.01849\tvalid_1's quad_kappa: 0.535879\n",
      "[1000]\ttraining's multi_logloss: 0.410854\ttraining's quad_kappa: 0.862081\tvalid_1's multi_logloss: 1.0257\tvalid_1's quad_kappa: 0.531336\n",
      "[1100]\ttraining's multi_logloss: 0.387219\ttraining's quad_kappa: 0.872762\tvalid_1's multi_logloss: 1.03408\tvalid_1's quad_kappa: 0.533569\n",
      "[1200]\ttraining's multi_logloss: 0.365655\ttraining's quad_kappa: 0.881421\tvalid_1's multi_logloss: 1.04212\tvalid_1's quad_kappa: 0.530854\n",
      "[1300]\ttraining's multi_logloss: 0.346656\ttraining's quad_kappa: 0.888617\tvalid_1's multi_logloss: 1.05027\tvalid_1's quad_kappa: 0.529459\n",
      "[1400]\ttraining's multi_logloss: 0.329215\ttraining's quad_kappa: 0.894379\tvalid_1's multi_logloss: 1.05934\tvalid_1's quad_kappa: 0.53199\n",
      "[1500]\ttraining's multi_logloss: 0.313862\ttraining's quad_kappa: 0.899797\tvalid_1's multi_logloss: 1.06768\tvalid_1's quad_kappa: 0.529276\n",
      "[1600]\ttraining's multi_logloss: 0.299545\ttraining's quad_kappa: 0.905522\tvalid_1's multi_logloss: 1.07572\tvalid_1's quad_kappa: 0.525577\n",
      "[1700]\ttraining's multi_logloss: 0.285929\ttraining's quad_kappa: 0.910385\tvalid_1's multi_logloss: 1.08389\tvalid_1's quad_kappa: 0.52252\n",
      "[1800]\ttraining's multi_logloss: 0.273713\ttraining's quad_kappa: 0.913514\tvalid_1's multi_logloss: 1.09145\tvalid_1's quad_kappa: 0.517495\n",
      "[1900]\ttraining's multi_logloss: 0.261873\ttraining's quad_kappa: 0.918482\tvalid_1's multi_logloss: 1.09946\tvalid_1's quad_kappa: 0.519459\n",
      "[2000]\ttraining's multi_logloss: 0.250993\ttraining's quad_kappa: 0.92028\tvalid_1's multi_logloss: 1.10739\tvalid_1's quad_kappa: 0.513304\n",
      "[2100]\ttraining's multi_logloss: 0.240499\ttraining's quad_kappa: 0.925359\tvalid_1's multi_logloss: 1.11536\tvalid_1's quad_kappa: 0.512373\n",
      "[2200]\ttraining's multi_logloss: 0.231132\ttraining's quad_kappa: 0.930765\tvalid_1's multi_logloss: 1.12295\tvalid_1's quad_kappa: 0.512066\n",
      "[2300]\ttraining's multi_logloss: 0.222548\ttraining's quad_kappa: 0.933341\tvalid_1's multi_logloss: 1.13019\tvalid_1's quad_kappa: 0.512736\n",
      "[2400]\ttraining's multi_logloss: 0.214207\ttraining's quad_kappa: 0.936273\tvalid_1's multi_logloss: 1.13776\tvalid_1's quad_kappa: 0.513238\n",
      "Early stopping, best iteration is:                                               \n",
      "[491]\ttraining's multi_logloss: 0.59107\ttraining's quad_kappa: 0.772318\tvalid_1's multi_logloss: 0.998114\tvalid_1's quad_kappa: 0.518824\n",
      "Training until validation scores don't improve for 2000 rounds                   \n",
      "[100]\ttraining's multi_logloss: 0.98782\ttraining's quad_kappa: 0.414897\tvalid_1's multi_logloss: 1.10812\tvalid_1's quad_kappa: 0.301852\n",
      "[200]\ttraining's multi_logloss: 0.840341\ttraining's quad_kappa: 0.627891\tvalid_1's multi_logloss: 1.04925\tvalid_1's quad_kappa: 0.463339\n",
      "[300]\ttraining's multi_logloss: 0.73956\ttraining's quad_kappa: 0.702802\tvalid_1's multi_logloss: 1.02235\tvalid_1's quad_kappa: 0.5056\n",
      "[400]\ttraining's multi_logloss: 0.661552\ttraining's quad_kappa: 0.74274\tvalid_1's multi_logloss: 1.01002\tvalid_1's quad_kappa: 0.52945\n",
      "[500]\ttraining's multi_logloss: 0.600834\ttraining's quad_kappa: 0.775306\tvalid_1's multi_logloss: 1.00729\tvalid_1's quad_kappa: 0.536615\n",
      "[600]\ttraining's multi_logloss: 0.552754\ttraining's quad_kappa: 0.799387\tvalid_1's multi_logloss: 1.00928\tvalid_1's quad_kappa: 0.538771\n",
      "[700]\ttraining's multi_logloss: 0.513023\ttraining's quad_kappa: 0.819252\tvalid_1's multi_logloss: 1.01418\tvalid_1's quad_kappa: 0.542682\n",
      "[800]\ttraining's multi_logloss: 0.479695\ttraining's quad_kappa: 0.829808\tvalid_1's multi_logloss: 1.02051\tvalid_1's quad_kappa: 0.544166\n",
      "[900]\ttraining's multi_logloss: 0.451933\ttraining's quad_kappa: 0.840391\tvalid_1's multi_logloss: 1.0274\tvalid_1's quad_kappa: 0.542069\n",
      "[1000]\ttraining's multi_logloss: 0.427236\ttraining's quad_kappa: 0.849792\tvalid_1's multi_logloss: 1.03447\tvalid_1's quad_kappa: 0.546935\n",
      "[1100]\ttraining's multi_logloss: 0.404295\ttraining's quad_kappa: 0.860742\tvalid_1's multi_logloss: 1.04192\tvalid_1's quad_kappa: 0.54612\n",
      "[1200]\ttraining's multi_logloss: 0.383336\ttraining's quad_kappa: 0.869091\tvalid_1's multi_logloss: 1.05005\tvalid_1's quad_kappa: 0.544973\n",
      "[1300]\ttraining's multi_logloss: 0.364013\ttraining's quad_kappa: 0.878824\tvalid_1's multi_logloss: 1.05801\tvalid_1's quad_kappa: 0.541351\n",
      "[1400]\ttraining's multi_logloss: 0.346087\ttraining's quad_kappa: 0.889223\tvalid_1's multi_logloss: 1.06637\tvalid_1's quad_kappa: 0.53952\n",
      "[1500]\ttraining's multi_logloss: 0.329395\ttraining's quad_kappa: 0.896179\tvalid_1's multi_logloss: 1.07434\tvalid_1's quad_kappa: 0.539701\n",
      "[1600]\ttraining's multi_logloss: 0.313563\ttraining's quad_kappa: 0.90246\tvalid_1's multi_logloss: 1.08207\tvalid_1's quad_kappa: 0.538628\n",
      "[1700]\ttraining's multi_logloss: 0.299385\ttraining's quad_kappa: 0.906965\tvalid_1's multi_logloss: 1.09028\tvalid_1's quad_kappa: 0.538669\n",
      "[1800]\ttraining's multi_logloss: 0.285718\ttraining's quad_kappa: 0.911321\tvalid_1's multi_logloss: 1.09891\tvalid_1's quad_kappa: 0.540075\n",
      "[1900]\ttraining's multi_logloss: 0.273576\ttraining's quad_kappa: 0.917512\tvalid_1's multi_logloss: 1.1072\tvalid_1's quad_kappa: 0.541153\n",
      "[2000]\ttraining's multi_logloss: 0.262561\ttraining's quad_kappa: 0.920748\tvalid_1's multi_logloss: 1.11512\tvalid_1's quad_kappa: 0.541417\n",
      "[2100]\ttraining's multi_logloss: 0.252023\ttraining's quad_kappa: 0.92525\tvalid_1's multi_logloss: 1.12296\tvalid_1's quad_kappa: 0.539869\n",
      "[2200]\ttraining's multi_logloss: 0.242124\ttraining's quad_kappa: 0.927959\tvalid_1's multi_logloss: 1.13044\tvalid_1's quad_kappa: 0.540656\n",
      "[2300]\ttraining's multi_logloss: 0.232881\ttraining's quad_kappa: 0.932712\tvalid_1's multi_logloss: 1.13794\tvalid_1's quad_kappa: 0.541061\n",
      "[2400]\ttraining's multi_logloss: 0.224139\ttraining's quad_kappa: 0.935266\tvalid_1's multi_logloss: 1.14549\tvalid_1's quad_kappa: 0.540499\n",
      "Early stopping, best iteration is:                                               \n",
      "[491]\ttraining's multi_logloss: 0.605735\ttraining's quad_kappa: 0.77332\tvalid_1's multi_logloss: 1.00724\tvalid_1's quad_kappa: 0.534839\n",
      "{'feature_fraction': 0.39, 'lambda_l1': 0.5931248613057111, 'lambda_l2': 0.8595029581277763, 'learning_rate': 0.007, 'max_depth': 5.0, 'metric': 'multiclass', 'n_estimators': 10000, 'num_classes': 4, 'num_leaves': 15, 'objective': 'multiclass', 'random_state': 2019, 'subsample': 0.87}\n",
      "Training until validation scores don't improve for 2000 rounds                   \n",
      " 20%|██        | 5/25 [58:18<3:59:31, 718.58s/it, best loss: -0.5188369088259418]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 1.13529\ttraining's quad_kappa: 0.0241339\tvalid_1's multi_logloss: 1.13719\tvalid_1's quad_kappa: 0.0232643\n",
      "[200]\ttraining's multi_logloss: 1.07607\ttraining's quad_kappa: 0.349008\tvalid_1's multi_logloss: 1.09029\tvalid_1's quad_kappa: 0.330266\n",
      "[300]\ttraining's multi_logloss: 1.03769\ttraining's quad_kappa: 0.43139\tvalid_1's multi_logloss: 1.06349\tvalid_1's quad_kappa: 0.397931\n",
      "[400]\ttraining's multi_logloss: 1.00642\ttraining's quad_kappa: 0.484159\tvalid_1's multi_logloss: 1.04316\tvalid_1's quad_kappa: 0.445232\n",
      "[500]\ttraining's multi_logloss: 0.982052\ttraining's quad_kappa: 0.507941\tvalid_1's multi_logloss: 1.02883\tvalid_1's quad_kappa: 0.450097\n",
      "[600]\ttraining's multi_logloss: 0.961821\ttraining's quad_kappa: 0.520356\tvalid_1's multi_logloss: 1.01846\tvalid_1's quad_kappa: 0.471518\n",
      "[700]\ttraining's multi_logloss: 0.945369\ttraining's quad_kappa: 0.535463\tvalid_1's multi_logloss: 1.01118\tvalid_1's quad_kappa: 0.481435\n",
      "[800]\ttraining's multi_logloss: 0.931082\ttraining's quad_kappa: 0.544338\tvalid_1's multi_logloss: 1.00569\tvalid_1's quad_kappa: 0.487389\n",
      "[900]\ttraining's multi_logloss: 0.918857\ttraining's quad_kappa: 0.550702\tvalid_1's multi_logloss: 1.00216\tvalid_1's quad_kappa: 0.490177\n",
      "[1000]\ttraining's multi_logloss: 0.907992\ttraining's quad_kappa: 0.55715\tvalid_1's multi_logloss: 0.999809\tvalid_1's quad_kappa: 0.492285\n",
      "[1100]\ttraining's multi_logloss: 0.898027\ttraining's quad_kappa: 0.563535\tvalid_1's multi_logloss: 0.998383\tvalid_1's quad_kappa: 0.492294\n",
      "[1200]\ttraining's multi_logloss: 0.888896\ttraining's quad_kappa: 0.567233\tvalid_1's multi_logloss: 0.99723\tvalid_1's quad_kappa: 0.492331\n",
      "[1300]\ttraining's multi_logloss: 0.880273\ttraining's quad_kappa: 0.571733\tvalid_1's multi_logloss: 0.996199\tvalid_1's quad_kappa: 0.486422\n",
      "[1400]\ttraining's multi_logloss: 0.871881\ttraining's quad_kappa: 0.577201\tvalid_1's multi_logloss: 0.995726\tvalid_1's quad_kappa: 0.491423\n",
      "[1500]\ttraining's multi_logloss: 0.863765\ttraining's quad_kappa: 0.583262\tvalid_1's multi_logloss: 0.995306\tvalid_1's quad_kappa: 0.487839\n",
      "[1600]\ttraining's multi_logloss: 0.856173\ttraining's quad_kappa: 0.585932\tvalid_1's multi_logloss: 0.994972\tvalid_1's quad_kappa: 0.489514\n",
      "[1700]\ttraining's multi_logloss: 0.848881\ttraining's quad_kappa: 0.591077\tvalid_1's multi_logloss: 0.994977\tvalid_1's quad_kappa: 0.490244\n",
      "[1800]\ttraining's multi_logloss: 0.841821\ttraining's quad_kappa: 0.596021\tvalid_1's multi_logloss: 0.995153\tvalid_1's quad_kappa: 0.487254\n",
      "[1900]\ttraining's multi_logloss: 0.835078\ttraining's quad_kappa: 0.59868\tvalid_1's multi_logloss: 0.995218\tvalid_1's quad_kappa: 0.488849\n",
      "[2000]\ttraining's multi_logloss: 0.828541\ttraining's quad_kappa: 0.603926\tvalid_1's multi_logloss: 0.995566\tvalid_1's quad_kappa: 0.490329\n",
      "[2100]\ttraining's multi_logloss: 0.82234\ttraining's quad_kappa: 0.607418\tvalid_1's multi_logloss: 0.995795\tvalid_1's quad_kappa: 0.490382\n",
      "[2200]\ttraining's multi_logloss: 0.816357\ttraining's quad_kappa: 0.610387\tvalid_1's multi_logloss: 0.996041\tvalid_1's quad_kappa: 0.492435\n",
      "[2300]\ttraining's multi_logloss: 0.81045\ttraining's quad_kappa: 0.614344\tvalid_1's multi_logloss: 0.996226\tvalid_1's quad_kappa: 0.495361\n",
      "[2400]\ttraining's multi_logloss: 0.804696\ttraining's quad_kappa: 0.619371\tvalid_1's multi_logloss: 0.996485\tvalid_1's quad_kappa: 0.498381\n",
      "[2500]\ttraining's multi_logloss: 0.798999\ttraining's quad_kappa: 0.622274\tvalid_1's multi_logloss: 0.996729\tvalid_1's quad_kappa: 0.498987\n",
      "[2600]\ttraining's multi_logloss: 0.79325\ttraining's quad_kappa: 0.627878\tvalid_1's multi_logloss: 0.997011\tvalid_1's quad_kappa: 0.49674\n",
      "[2700]\ttraining's multi_logloss: 0.787692\ttraining's quad_kappa: 0.631458\tvalid_1's multi_logloss: 0.997209\tvalid_1's quad_kappa: 0.49708\n",
      "[2800]\ttraining's multi_logloss: 0.782193\ttraining's quad_kappa: 0.633977\tvalid_1's multi_logloss: 0.997707\tvalid_1's quad_kappa: 0.497443\n",
      "[2900]\ttraining's multi_logloss: 0.776755\ttraining's quad_kappa: 0.637661\tvalid_1's multi_logloss: 0.998237\tvalid_1's quad_kappa: 0.497443\n",
      "[3000]\ttraining's multi_logloss: 0.77151\ttraining's quad_kappa: 0.641301\tvalid_1's multi_logloss: 0.998686\tvalid_1's quad_kappa: 0.49951\n",
      "[3100]\ttraining's multi_logloss: 0.766367\ttraining's quad_kappa: 0.643871\tvalid_1's multi_logloss: 0.999146\tvalid_1's quad_kappa: 0.499492\n",
      "[3200]\ttraining's multi_logloss: 0.761338\ttraining's quad_kappa: 0.64532\tvalid_1's multi_logloss: 0.999669\tvalid_1's quad_kappa: 0.498569\n",
      "[3300]\ttraining's multi_logloss: 0.756398\ttraining's quad_kappa: 0.647512\tvalid_1's multi_logloss: 1.0002\tvalid_1's quad_kappa: 0.504241\n",
      "[3400]\ttraining's multi_logloss: 0.751529\ttraining's quad_kappa: 0.650361\tvalid_1's multi_logloss: 1.00099\tvalid_1's quad_kappa: 0.501448\n",
      "[3500]\ttraining's multi_logloss: 0.746697\ttraining's quad_kappa: 0.652867\tvalid_1's multi_logloss: 1.0015\tvalid_1's quad_kappa: 0.501931\n",
      "[3600]\ttraining's multi_logloss: 0.742012\ttraining's quad_kappa: 0.655979\tvalid_1's multi_logloss: 1.00195\tvalid_1's quad_kappa: 0.501659\n",
      "[3700]\ttraining's multi_logloss: 0.7375\ttraining's quad_kappa: 0.659095\tvalid_1's multi_logloss: 1.00255\tvalid_1's quad_kappa: 0.504329\n",
      "Early stopping, best iteration is:                                                 \n",
      "[1716]\ttraining's multi_logloss: 0.847712\ttraining's quad_kappa: 0.591926\tvalid_1's multi_logloss: 0.994881\tvalid_1's quad_kappa: 0.490244\n",
      "Training until validation scores don't improve for 2000 rounds                     \n",
      "[100]\ttraining's multi_logloss: 1.12397\ttraining's quad_kappa: 0.079512\tvalid_1's multi_logloss: 1.13702\tvalid_1's quad_kappa: 0.0778559\n",
      "[200]\ttraining's multi_logloss: 1.06044\ttraining's quad_kappa: 0.383495\tvalid_1's multi_logloss: 1.08784\tvalid_1's quad_kappa: 0.361988\n",
      "[300]\ttraining's multi_logloss: 1.01982\ttraining's quad_kappa: 0.46601\tvalid_1's multi_logloss: 1.05998\tvalid_1's quad_kappa: 0.42336\n",
      "[400]\ttraining's multi_logloss: 0.987448\ttraining's quad_kappa: 0.507053\tvalid_1's multi_logloss: 1.03953\tvalid_1's quad_kappa: 0.456137\n",
      "[500]\ttraining's multi_logloss: 0.962362\ttraining's quad_kappa: 0.538379\tvalid_1's multi_logloss: 1.02568\tvalid_1's quad_kappa: 0.478786\n",
      "[600]\ttraining's multi_logloss: 0.941816\ttraining's quad_kappa: 0.554766\tvalid_1's multi_logloss: 1.01572\tvalid_1's quad_kappa: 0.487573\n",
      "[700]\ttraining's multi_logloss: 0.9251\ttraining's quad_kappa: 0.564248\tvalid_1's multi_logloss: 1.00888\tvalid_1's quad_kappa: 0.497787\n",
      "[800]\ttraining's multi_logloss: 0.910925\ttraining's quad_kappa: 0.573447\tvalid_1's multi_logloss: 1.00401\tvalid_1's quad_kappa: 0.501414\n",
      "[900]\ttraining's multi_logloss: 0.898385\ttraining's quad_kappa: 0.57771\tvalid_1's multi_logloss: 1.00066\tvalid_1's quad_kappa: 0.506848\n",
      "[1000]\ttraining's multi_logloss: 0.887103\ttraining's quad_kappa: 0.581344\tvalid_1's multi_logloss: 0.998119\tvalid_1's quad_kappa: 0.507883\n",
      "[1100]\ttraining's multi_logloss: 0.876615\ttraining's quad_kappa: 0.588598\tvalid_1's multi_logloss: 0.996102\tvalid_1's quad_kappa: 0.507699\n",
      "[1200]\ttraining's multi_logloss: 0.867365\ttraining's quad_kappa: 0.595344\tvalid_1's multi_logloss: 0.994601\tvalid_1's quad_kappa: 0.502143\n",
      "[1300]\ttraining's multi_logloss: 0.858447\ttraining's quad_kappa: 0.598733\tvalid_1's multi_logloss: 0.993495\tvalid_1's quad_kappa: 0.504859\n",
      "[1400]\ttraining's multi_logloss: 0.85007\ttraining's quad_kappa: 0.603847\tvalid_1's multi_logloss: 0.992773\tvalid_1's quad_kappa: 0.511098\n",
      "[1500]\ttraining's multi_logloss: 0.841899\ttraining's quad_kappa: 0.607273\tvalid_1's multi_logloss: 0.992\tvalid_1's quad_kappa: 0.51379\n",
      "[1600]\ttraining's multi_logloss: 0.834257\ttraining's quad_kappa: 0.611739\tvalid_1's multi_logloss: 0.991502\tvalid_1's quad_kappa: 0.514871\n",
      "[1700]\ttraining's multi_logloss: 0.826877\ttraining's quad_kappa: 0.614908\tvalid_1's multi_logloss: 0.991222\tvalid_1's quad_kappa: 0.514745\n",
      "[1800]\ttraining's multi_logloss: 0.819904\ttraining's quad_kappa: 0.618475\tvalid_1's multi_logloss: 0.990966\tvalid_1's quad_kappa: 0.512442\n",
      "[1900]\ttraining's multi_logloss: 0.813269\ttraining's quad_kappa: 0.62419\tvalid_1's multi_logloss: 0.990964\tvalid_1's quad_kappa: 0.514131\n",
      "[2000]\ttraining's multi_logloss: 0.806978\ttraining's quad_kappa: 0.628061\tvalid_1's multi_logloss: 0.990958\tvalid_1's quad_kappa: 0.512225\n",
      "[2100]\ttraining's multi_logloss: 0.800927\ttraining's quad_kappa: 0.629346\tvalid_1's multi_logloss: 0.991306\tvalid_1's quad_kappa: 0.513953\n",
      "[2200]\ttraining's multi_logloss: 0.794976\ttraining's quad_kappa: 0.632208\tvalid_1's multi_logloss: 0.991517\tvalid_1's quad_kappa: 0.514297\n",
      "[2300]\ttraining's multi_logloss: 0.789088\ttraining's quad_kappa: 0.635183\tvalid_1's multi_logloss: 0.991925\tvalid_1's quad_kappa: 0.517032\n",
      "[2400]\ttraining's multi_logloss: 0.783294\ttraining's quad_kappa: 0.638325\tvalid_1's multi_logloss: 0.992429\tvalid_1's quad_kappa: 0.515086\n",
      "[2500]\ttraining's multi_logloss: 0.777756\ttraining's quad_kappa: 0.642227\tvalid_1's multi_logloss: 0.992877\tvalid_1's quad_kappa: 0.515482\n",
      "[2600]\ttraining's multi_logloss: 0.77208\ttraining's quad_kappa: 0.644138\tvalid_1's multi_logloss: 0.993604\tvalid_1's quad_kappa: 0.515931\n",
      "[2700]\ttraining's multi_logloss: 0.766638\ttraining's quad_kappa: 0.647079\tvalid_1's multi_logloss: 0.994279\tvalid_1's quad_kappa: 0.517385\n",
      "[2800]\ttraining's multi_logloss: 0.761405\ttraining's quad_kappa: 0.64871\tvalid_1's multi_logloss: 0.994854\tvalid_1's quad_kappa: 0.518523\n",
      "[2900]\ttraining's multi_logloss: 0.756158\ttraining's quad_kappa: 0.651289\tvalid_1's multi_logloss: 0.995346\tvalid_1's quad_kappa: 0.518763\n",
      "[3000]\ttraining's multi_logloss: 0.751126\ttraining's quad_kappa: 0.653973\tvalid_1's multi_logloss: 0.995944\tvalid_1's quad_kappa: 0.517503\n",
      "[3100]\ttraining's multi_logloss: 0.746193\ttraining's quad_kappa: 0.65722\tvalid_1's multi_logloss: 0.996653\tvalid_1's quad_kappa: 0.517472\n",
      "[3200]\ttraining's multi_logloss: 0.741193\ttraining's quad_kappa: 0.660235\tvalid_1's multi_logloss: 0.997091\tvalid_1's quad_kappa: 0.517528\n",
      "[3300]\ttraining's multi_logloss: 0.736456\ttraining's quad_kappa: 0.663237\tvalid_1's multi_logloss: 0.997725\tvalid_1's quad_kappa: 0.518577\n",
      "[3400]\ttraining's multi_logloss: 0.7318\ttraining's quad_kappa: 0.665674\tvalid_1's multi_logloss: 0.998391\tvalid_1's quad_kappa: 0.517387\n",
      "[3500]\ttraining's multi_logloss: 0.727209\ttraining's quad_kappa: 0.667951\tvalid_1's multi_logloss: 0.999051\tvalid_1's quad_kappa: 0.519296\n",
      "[3600]\ttraining's multi_logloss: 0.722548\ttraining's quad_kappa: 0.671797\tvalid_1's multi_logloss: 0.99992\tvalid_1's quad_kappa: 0.518106\n",
      "[3700]\ttraining's multi_logloss: 0.717903\ttraining's quad_kappa: 0.673983\tvalid_1's multi_logloss: 1.00054\tvalid_1's quad_kappa: 0.516325\n",
      "[3800]\ttraining's multi_logloss: 0.713309\ttraining's quad_kappa: 0.674924\tvalid_1's multi_logloss: 1.00117\tvalid_1's quad_kappa: 0.516261\n",
      "Early stopping, best iteration is:                                                 \n",
      "[1855]\ttraining's multi_logloss: 0.816213\ttraining's quad_kappa: 0.62219\tvalid_1's multi_logloss: 0.990873\tvalid_1's quad_kappa: 0.513472\n",
      "Training until validation scores don't improve for 2000 rounds                     \n",
      "[100]\ttraining's multi_logloss: 1.13811\ttraining's quad_kappa: 0.0700939\tvalid_1's multi_logloss: 1.1549\tvalid_1's quad_kappa: 0.0598923\n",
      "[200]\ttraining's multi_logloss: 1.07531\ttraining's quad_kappa: 0.374598\tvalid_1's multi_logloss: 1.10308\tvalid_1's quad_kappa: 0.344977\n",
      "[300]\ttraining's multi_logloss: 1.03458\ttraining's quad_kappa: 0.445275\tvalid_1's multi_logloss: 1.07329\tvalid_1's quad_kappa: 0.406249\n",
      "[400]\ttraining's multi_logloss: 1.00206\ttraining's quad_kappa: 0.487362\tvalid_1's multi_logloss: 1.05073\tvalid_1's quad_kappa: 0.448346\n",
      "[500]\ttraining's multi_logloss: 0.976891\ttraining's quad_kappa: 0.516716\tvalid_1's multi_logloss: 1.03528\tvalid_1's quad_kappa: 0.48003\n",
      "[600]\ttraining's multi_logloss: 0.955967\ttraining's quad_kappa: 0.534959\tvalid_1's multi_logloss: 1.02406\tvalid_1's quad_kappa: 0.500603\n",
      "[700]\ttraining's multi_logloss: 0.938823\ttraining's quad_kappa: 0.548176\tvalid_1's multi_logloss: 1.01592\tvalid_1's quad_kappa: 0.513996\n",
      "[800]\ttraining's multi_logloss: 0.924162\ttraining's quad_kappa: 0.559053\tvalid_1's multi_logloss: 1.01007\tvalid_1's quad_kappa: 0.51816\n",
      "[900]\ttraining's multi_logloss: 0.911426\ttraining's quad_kappa: 0.567934\tvalid_1's multi_logloss: 1.00593\tvalid_1's quad_kappa: 0.523484\n",
      "[1000]\ttraining's multi_logloss: 0.900025\ttraining's quad_kappa: 0.572451\tvalid_1's multi_logloss: 1.0025\tvalid_1's quad_kappa: 0.529396\n",
      "[1100]\ttraining's multi_logloss: 0.889471\ttraining's quad_kappa: 0.575946\tvalid_1's multi_logloss: 0.999857\tvalid_1's quad_kappa: 0.534909\n",
      "[1200]\ttraining's multi_logloss: 0.880013\ttraining's quad_kappa: 0.58309\tvalid_1's multi_logloss: 0.998036\tvalid_1's quad_kappa: 0.535953\n",
      "[1300]\ttraining's multi_logloss: 0.871393\ttraining's quad_kappa: 0.588095\tvalid_1's multi_logloss: 0.99648\tvalid_1's quad_kappa: 0.536974\n",
      "[1400]\ttraining's multi_logloss: 0.863193\ttraining's quad_kappa: 0.592243\tvalid_1's multi_logloss: 0.99509\tvalid_1's quad_kappa: 0.536247\n",
      "[1500]\ttraining's multi_logloss: 0.855299\ttraining's quad_kappa: 0.59482\tvalid_1's multi_logloss: 0.99394\tvalid_1's quad_kappa: 0.534408\n",
      "[1600]\ttraining's multi_logloss: 0.848111\ttraining's quad_kappa: 0.599484\tvalid_1's multi_logloss: 0.993333\tvalid_1's quad_kappa: 0.534367\n",
      "[1700]\ttraining's multi_logloss: 0.841036\ttraining's quad_kappa: 0.602949\tvalid_1's multi_logloss: 0.992868\tvalid_1's quad_kappa: 0.535945\n",
      "[1800]\ttraining's multi_logloss: 0.834279\ttraining's quad_kappa: 0.605669\tvalid_1's multi_logloss: 0.992793\tvalid_1's quad_kappa: 0.536567\n",
      "[1900]\ttraining's multi_logloss: 0.827967\ttraining's quad_kappa: 0.608215\tvalid_1's multi_logloss: 0.99282\tvalid_1's quad_kappa: 0.539416\n",
      "[2000]\ttraining's multi_logloss: 0.821756\ttraining's quad_kappa: 0.614995\tvalid_1's multi_logloss: 0.992754\tvalid_1's quad_kappa: 0.539645\n",
      "[2100]\ttraining's multi_logloss: 0.815642\ttraining's quad_kappa: 0.617974\tvalid_1's multi_logloss: 0.993001\tvalid_1's quad_kappa: 0.540019\n",
      "[2200]\ttraining's multi_logloss: 0.809657\ttraining's quad_kappa: 0.62189\tvalid_1's multi_logloss: 0.993241\tvalid_1's quad_kappa: 0.546038\n",
      "[2300]\ttraining's multi_logloss: 0.803829\ttraining's quad_kappa: 0.627645\tvalid_1's multi_logloss: 0.993625\tvalid_1's quad_kappa: 0.547851\n",
      "[2400]\ttraining's multi_logloss: 0.798026\ttraining's quad_kappa: 0.630003\tvalid_1's multi_logloss: 0.994095\tvalid_1's quad_kappa: 0.5461\n",
      "[2500]\ttraining's multi_logloss: 0.792582\ttraining's quad_kappa: 0.631703\tvalid_1's multi_logloss: 0.994473\tvalid_1's quad_kappa: 0.544788\n",
      "[2600]\ttraining's multi_logloss: 0.787137\ttraining's quad_kappa: 0.636352\tvalid_1's multi_logloss: 0.994833\tvalid_1's quad_kappa: 0.545522\n",
      "[2700]\ttraining's multi_logloss: 0.781798\ttraining's quad_kappa: 0.640697\tvalid_1's multi_logloss: 0.995483\tvalid_1's quad_kappa: 0.546696\n",
      "[2800]\ttraining's multi_logloss: 0.776548\ttraining's quad_kappa: 0.642404\tvalid_1's multi_logloss: 0.995923\tvalid_1's quad_kappa: 0.546805\n",
      "[2900]\ttraining's multi_logloss: 0.771213\ttraining's quad_kappa: 0.644961\tvalid_1's multi_logloss: 0.99639\tvalid_1's quad_kappa: 0.550828\n",
      "[3000]\ttraining's multi_logloss: 0.76632\ttraining's quad_kappa: 0.647332\tvalid_1's multi_logloss: 0.99705\tvalid_1's quad_kappa: 0.549227\n",
      "[3100]\ttraining's multi_logloss: 0.761447\ttraining's quad_kappa: 0.650456\tvalid_1's multi_logloss: 0.997514\tvalid_1's quad_kappa: 0.547662\n",
      "[3200]\ttraining's multi_logloss: 0.756773\ttraining's quad_kappa: 0.65327\tvalid_1's multi_logloss: 0.998033\tvalid_1's quad_kappa: 0.550107\n",
      "[3300]\ttraining's multi_logloss: 0.752074\ttraining's quad_kappa: 0.654448\tvalid_1's multi_logloss: 0.998598\tvalid_1's quad_kappa: 0.55007\n",
      "[3400]\ttraining's multi_logloss: 0.747387\ttraining's quad_kappa: 0.656955\tvalid_1's multi_logloss: 0.999149\tvalid_1's quad_kappa: 0.548021\n",
      "[3500]\ttraining's multi_logloss: 0.742904\ttraining's quad_kappa: 0.66046\tvalid_1's multi_logloss: 0.999778\tvalid_1's quad_kappa: 0.546972\n",
      "[3600]\ttraining's multi_logloss: 0.738469\ttraining's quad_kappa: 0.661586\tvalid_1's multi_logloss: 1.00039\tvalid_1's quad_kappa: 0.543842\n",
      "[3700]\ttraining's multi_logloss: 0.733952\ttraining's quad_kappa: 0.66383\tvalid_1's multi_logloss: 1.00103\tvalid_1's quad_kappa: 0.544664\n",
      "[3800]\ttraining's multi_logloss: 0.729567\ttraining's quad_kappa: 0.668434\tvalid_1's multi_logloss: 1.00152\tvalid_1's quad_kappa: 0.543797\n",
      "[3900]\ttraining's multi_logloss: 0.725127\ttraining's quad_kappa: 0.66958\tvalid_1's multi_logloss: 1.00204\tvalid_1's quad_kappa: 0.543783\n",
      "Early stopping, best iteration is:                                                 \n",
      "[1943]\ttraining's multi_logloss: 0.825263\ttraining's quad_kappa: 0.611138\tvalid_1's multi_logloss: 0.992635\tvalid_1's quad_kappa: 0.537485\n",
      "{'feature_fraction': 0.87, 'lambda_l1': 0.7474988909558209, 'lambda_l2': 0.12521930130222197, 'learning_rate': 0.007, 'max_depth': 3.0, 'metric': 'multiclass', 'n_estimators': 10000, 'num_classes': 4, 'num_leaves': 15, 'objective': 'multiclass', 'random_state': 2019, 'subsample': 0.2}\n",
      "Training until validation scores don't improve for 2000 rounds                     \n",
      " 24%|██▍       | 6/25 [1:08:36<3:38:03, 688.62s/it, best loss: -0.5188369088259418]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 1.12819\ttraining's quad_kappa: 0.298741\tvalid_1's multi_logloss: 1.11923\tvalid_1's quad_kappa: 0.283521\n",
      "[200]\ttraining's multi_logloss: 1.08791\ttraining's quad_kappa: 0.34761\tvalid_1's multi_logloss: 1.08619\tvalid_1's quad_kappa: 0.319993\n",
      "[300]\ttraining's multi_logloss: 1.06441\ttraining's quad_kappa: 0.357388\tvalid_1's multi_logloss: 1.06984\tvalid_1's quad_kappa: 0.32793\n",
      "[400]\ttraining's multi_logloss: 1.04494\ttraining's quad_kappa: 0.372913\tvalid_1's multi_logloss: 1.05489\tvalid_1's quad_kappa: 0.344477\n",
      "[500]\ttraining's multi_logloss: 1.02858\ttraining's quad_kappa: 0.410204\tvalid_1's multi_logloss: 1.04298\tvalid_1's quad_kappa: 0.383513\n",
      "[600]\ttraining's multi_logloss: 1.01512\ttraining's quad_kappa: 0.443904\tvalid_1's multi_logloss: 1.03393\tvalid_1's quad_kappa: 0.40283\n",
      "[700]\ttraining's multi_logloss: 1.00377\ttraining's quad_kappa: 0.466031\tvalid_1's multi_logloss: 1.02701\tvalid_1's quad_kappa: 0.412874\n",
      "[800]\ttraining's multi_logloss: 0.993926\ttraining's quad_kappa: 0.492822\tvalid_1's multi_logloss: 1.0211\tvalid_1's quad_kappa: 0.443573\n",
      "[900]\ttraining's multi_logloss: 0.985201\ttraining's quad_kappa: 0.501883\tvalid_1's multi_logloss: 1.01652\tvalid_1's quad_kappa: 0.461265\n",
      "[1000]\ttraining's multi_logloss: 0.977318\ttraining's quad_kappa: 0.507649\tvalid_1's multi_logloss: 1.01267\tvalid_1's quad_kappa: 0.469445\n",
      "[1100]\ttraining's multi_logloss: 0.97012\ttraining's quad_kappa: 0.511389\tvalid_1's multi_logloss: 1.00954\tvalid_1's quad_kappa: 0.478681\n",
      "[1200]\ttraining's multi_logloss: 0.963538\ttraining's quad_kappa: 0.51495\tvalid_1's multi_logloss: 1.00741\tvalid_1's quad_kappa: 0.479004\n",
      "[1300]\ttraining's multi_logloss: 0.957518\ttraining's quad_kappa: 0.519969\tvalid_1's multi_logloss: 1.00568\tvalid_1's quad_kappa: 0.482255\n",
      "[1400]\ttraining's multi_logloss: 0.951818\ttraining's quad_kappa: 0.524525\tvalid_1's multi_logloss: 1.00398\tvalid_1's quad_kappa: 0.488264\n",
      "[1500]\ttraining's multi_logloss: 0.946398\ttraining's quad_kappa: 0.527669\tvalid_1's multi_logloss: 1.0024\tvalid_1's quad_kappa: 0.487806\n",
      "[1600]\ttraining's multi_logloss: 0.941307\ttraining's quad_kappa: 0.531316\tvalid_1's multi_logloss: 1.00104\tvalid_1's quad_kappa: 0.487264\n",
      "[1700]\ttraining's multi_logloss: 0.936601\ttraining's quad_kappa: 0.534679\tvalid_1's multi_logloss: 1.00004\tvalid_1's quad_kappa: 0.495338\n",
      "[1800]\ttraining's multi_logloss: 0.932138\ttraining's quad_kappa: 0.53639\tvalid_1's multi_logloss: 0.999243\tvalid_1's quad_kappa: 0.492887\n",
      "[1900]\ttraining's multi_logloss: 0.927833\ttraining's quad_kappa: 0.537821\tvalid_1's multi_logloss: 0.998716\tvalid_1's quad_kappa: 0.49154\n",
      "[2000]\ttraining's multi_logloss: 0.92373\ttraining's quad_kappa: 0.540721\tvalid_1's multi_logloss: 0.998296\tvalid_1's quad_kappa: 0.487025\n",
      "[2100]\ttraining's multi_logloss: 0.91983\ttraining's quad_kappa: 0.54449\tvalid_1's multi_logloss: 0.997937\tvalid_1's quad_kappa: 0.484987\n",
      "[2200]\ttraining's multi_logloss: 0.91591\ttraining's quad_kappa: 0.546944\tvalid_1's multi_logloss: 0.997431\tvalid_1's quad_kappa: 0.485331\n",
      "[2300]\ttraining's multi_logloss: 0.912141\ttraining's quad_kappa: 0.548994\tvalid_1's multi_logloss: 0.996966\tvalid_1's quad_kappa: 0.486607\n",
      "[2400]\ttraining's multi_logloss: 0.908443\ttraining's quad_kappa: 0.550546\tvalid_1's multi_logloss: 0.996676\tvalid_1's quad_kappa: 0.484188\n",
      "[2500]\ttraining's multi_logloss: 0.90486\ttraining's quad_kappa: 0.552409\tvalid_1's multi_logloss: 0.996561\tvalid_1's quad_kappa: 0.483474\n",
      "[2600]\ttraining's multi_logloss: 0.901405\ttraining's quad_kappa: 0.555885\tvalid_1's multi_logloss: 0.996446\tvalid_1's quad_kappa: 0.483572\n",
      "[2700]\ttraining's multi_logloss: 0.89812\ttraining's quad_kappa: 0.557975\tvalid_1's multi_logloss: 0.996398\tvalid_1's quad_kappa: 0.486994\n",
      "[2800]\ttraining's multi_logloss: 0.894692\ttraining's quad_kappa: 0.560278\tvalid_1's multi_logloss: 0.996306\tvalid_1's quad_kappa: 0.486323\n",
      "[2900]\ttraining's multi_logloss: 0.891304\ttraining's quad_kappa: 0.562845\tvalid_1's multi_logloss: 0.996229\tvalid_1's quad_kappa: 0.490538\n",
      "[3000]\ttraining's multi_logloss: 0.887991\ttraining's quad_kappa: 0.565121\tvalid_1's multi_logloss: 0.996359\tvalid_1's quad_kappa: 0.48719\n",
      "[3100]\ttraining's multi_logloss: 0.884813\ttraining's quad_kappa: 0.567046\tvalid_1's multi_logloss: 0.996445\tvalid_1's quad_kappa: 0.485919\n",
      "[3200]\ttraining's multi_logloss: 0.881644\ttraining's quad_kappa: 0.56772\tvalid_1's multi_logloss: 0.996607\tvalid_1's quad_kappa: 0.485502\n",
      "[3300]\ttraining's multi_logloss: 0.878446\ttraining's quad_kappa: 0.570258\tvalid_1's multi_logloss: 0.996614\tvalid_1's quad_kappa: 0.483559\n",
      "[3400]\ttraining's multi_logloss: 0.875286\ttraining's quad_kappa: 0.573666\tvalid_1's multi_logloss: 0.996935\tvalid_1's quad_kappa: 0.482177\n",
      "[3500]\ttraining's multi_logloss: 0.872173\ttraining's quad_kappa: 0.575173\tvalid_1's multi_logloss: 0.997191\tvalid_1's quad_kappa: 0.482518\n",
      "[3600]\ttraining's multi_logloss: 0.869041\ttraining's quad_kappa: 0.576344\tvalid_1's multi_logloss: 0.997448\tvalid_1's quad_kappa: 0.484322\n",
      "Early stopping, best iteration is:                                                 \n",
      "[1694]\ttraining's multi_logloss: 0.936865\ttraining's quad_kappa: 0.534997\tvalid_1's multi_logloss: 1.00009\tvalid_1's quad_kappa: 0.495338\n",
      "Training until validation scores don't improve for 2000 rounds                     \n",
      "[100]\ttraining's multi_logloss: 1.11729\ttraining's quad_kappa: 0.314128\tvalid_1's multi_logloss: 1.12373\tvalid_1's quad_kappa: 0.310857\n",
      "[200]\ttraining's multi_logloss: 1.07195\ttraining's quad_kappa: 0.37429\tvalid_1's multi_logloss: 1.08633\tvalid_1's quad_kappa: 0.356743\n",
      "[300]\ttraining's multi_logloss: 1.04428\ttraining's quad_kappa: 0.391624\tvalid_1's multi_logloss: 1.06587\tvalid_1's quad_kappa: 0.369868\n",
      "[400]\ttraining's multi_logloss: 1.02237\ttraining's quad_kappa: 0.421401\tvalid_1's multi_logloss: 1.05168\tvalid_1's quad_kappa: 0.40573\n",
      "[500]\ttraining's multi_logloss: 1.00642\ttraining's quad_kappa: 0.461771\tvalid_1's multi_logloss: 1.04221\tvalid_1's quad_kappa: 0.424272\n",
      "[600]\ttraining's multi_logloss: 0.994202\ttraining's quad_kappa: 0.482356\tvalid_1's multi_logloss: 1.03523\tvalid_1's quad_kappa: 0.435309\n",
      "[700]\ttraining's multi_logloss: 0.983591\ttraining's quad_kappa: 0.502713\tvalid_1's multi_logloss: 1.02982\tvalid_1's quad_kappa: 0.44322\n",
      "[800]\ttraining's multi_logloss: 0.973849\ttraining's quad_kappa: 0.515762\tvalid_1's multi_logloss: 1.0253\tvalid_1's quad_kappa: 0.461416\n",
      "[900]\ttraining's multi_logloss: 0.964641\ttraining's quad_kappa: 0.530065\tvalid_1's multi_logloss: 1.02099\tvalid_1's quad_kappa: 0.481584\n",
      "[1000]\ttraining's multi_logloss: 0.956266\ttraining's quad_kappa: 0.540347\tvalid_1's multi_logloss: 1.01732\tvalid_1's quad_kappa: 0.484836\n",
      "[1100]\ttraining's multi_logloss: 0.948953\ttraining's quad_kappa: 0.545629\tvalid_1's multi_logloss: 1.01442\tvalid_1's quad_kappa: 0.49011\n",
      "[1200]\ttraining's multi_logloss: 0.942269\ttraining's quad_kappa: 0.550662\tvalid_1's multi_logloss: 1.01241\tvalid_1's quad_kappa: 0.497096\n",
      "[1300]\ttraining's multi_logloss: 0.936028\ttraining's quad_kappa: 0.553368\tvalid_1's multi_logloss: 1.0107\tvalid_1's quad_kappa: 0.49618\n",
      "[1400]\ttraining's multi_logloss: 0.930519\ttraining's quad_kappa: 0.557345\tvalid_1's multi_logloss: 1.00939\tvalid_1's quad_kappa: 0.501603\n",
      "[1500]\ttraining's multi_logloss: 0.925116\ttraining's quad_kappa: 0.560789\tvalid_1's multi_logloss: 1.00822\tvalid_1's quad_kappa: 0.501827\n",
      "[1600]\ttraining's multi_logloss: 0.919954\ttraining's quad_kappa: 0.563876\tvalid_1's multi_logloss: 1.00724\tvalid_1's quad_kappa: 0.499122\n",
      "[1700]\ttraining's multi_logloss: 0.915252\ttraining's quad_kappa: 0.565904\tvalid_1's multi_logloss: 1.00636\tvalid_1's quad_kappa: 0.50162\n",
      "[1800]\ttraining's multi_logloss: 0.910519\ttraining's quad_kappa: 0.569168\tvalid_1's multi_logloss: 1.00544\tvalid_1's quad_kappa: 0.501251\n",
      "[1900]\ttraining's multi_logloss: 0.905874\ttraining's quad_kappa: 0.570929\tvalid_1's multi_logloss: 1.00442\tvalid_1's quad_kappa: 0.505019\n",
      "[2000]\ttraining's multi_logloss: 0.901454\ttraining's quad_kappa: 0.573198\tvalid_1's multi_logloss: 1.00355\tvalid_1's quad_kappa: 0.505881\n",
      "[2100]\ttraining's multi_logloss: 0.897344\ttraining's quad_kappa: 0.576461\tvalid_1's multi_logloss: 1.00297\tvalid_1's quad_kappa: 0.505129\n",
      "[2200]\ttraining's multi_logloss: 0.893376\ttraining's quad_kappa: 0.579003\tvalid_1's multi_logloss: 1.00246\tvalid_1's quad_kappa: 0.505546\n",
      "[2300]\ttraining's multi_logloss: 0.889523\ttraining's quad_kappa: 0.583516\tvalid_1's multi_logloss: 1.00192\tvalid_1's quad_kappa: 0.507985\n",
      "[2400]\ttraining's multi_logloss: 0.885718\ttraining's quad_kappa: 0.585859\tvalid_1's multi_logloss: 1.00162\tvalid_1's quad_kappa: 0.502819\n",
      "[2500]\ttraining's multi_logloss: 0.882033\ttraining's quad_kappa: 0.587713\tvalid_1's multi_logloss: 1.00144\tvalid_1's quad_kappa: 0.50361\n",
      "[2600]\ttraining's multi_logloss: 0.878407\ttraining's quad_kappa: 0.58979\tvalid_1's multi_logloss: 1.00116\tvalid_1's quad_kappa: 0.503755\n",
      "[2700]\ttraining's multi_logloss: 0.874769\ttraining's quad_kappa: 0.59203\tvalid_1's multi_logloss: 1.00091\tvalid_1's quad_kappa: 0.504378\n",
      "[2800]\ttraining's multi_logloss: 0.871197\ttraining's quad_kappa: 0.593252\tvalid_1's multi_logloss: 1.00074\tvalid_1's quad_kappa: 0.503974\n",
      "[2900]\ttraining's multi_logloss: 0.867628\ttraining's quad_kappa: 0.594684\tvalid_1's multi_logloss: 1.00057\tvalid_1's quad_kappa: 0.504217\n",
      "[3000]\ttraining's multi_logloss: 0.864317\ttraining's quad_kappa: 0.597482\tvalid_1's multi_logloss: 1.00052\tvalid_1's quad_kappa: 0.503671\n",
      "[3100]\ttraining's multi_logloss: 0.861032\ttraining's quad_kappa: 0.598792\tvalid_1's multi_logloss: 1.00046\tvalid_1's quad_kappa: 0.503977\n",
      "[3200]\ttraining's multi_logloss: 0.8578\ttraining's quad_kappa: 0.599823\tvalid_1's multi_logloss: 1.00043\tvalid_1's quad_kappa: 0.503977\n",
      "[3300]\ttraining's multi_logloss: 0.854632\ttraining's quad_kappa: 0.601653\tvalid_1's multi_logloss: 1.00033\tvalid_1's quad_kappa: 0.504489\n",
      "[3400]\ttraining's multi_logloss: 0.851536\ttraining's quad_kappa: 0.603437\tvalid_1's multi_logloss: 1.00021\tvalid_1's quad_kappa: 0.506886\n",
      "[3500]\ttraining's multi_logloss: 0.848516\ttraining's quad_kappa: 0.605261\tvalid_1's multi_logloss: 1.00007\tvalid_1's quad_kappa: 0.508705\n",
      "[3600]\ttraining's multi_logloss: 0.845507\ttraining's quad_kappa: 0.60652\tvalid_1's multi_logloss: 1\tvalid_1's quad_kappa: 0.513259\n",
      "[3700]\ttraining's multi_logloss: 0.842427\ttraining's quad_kappa: 0.608695\tvalid_1's multi_logloss: 1.0001\tvalid_1's quad_kappa: 0.510893\n",
      "[3800]\ttraining's multi_logloss: 0.839587\ttraining's quad_kappa: 0.610193\tvalid_1's multi_logloss: 1.00006\tvalid_1's quad_kappa: 0.510581\n",
      "[3900]\ttraining's multi_logloss: 0.836604\ttraining's quad_kappa: 0.612119\tvalid_1's multi_logloss: 1.00001\tvalid_1's quad_kappa: 0.50842\n",
      "[4000]\ttraining's multi_logloss: 0.833718\ttraining's quad_kappa: 0.613464\tvalid_1's multi_logloss: 1.00011\tvalid_1's quad_kappa: 0.511136\n",
      "[4100]\ttraining's multi_logloss: 0.830989\ttraining's quad_kappa: 0.614912\tvalid_1's multi_logloss: 1.0003\tvalid_1's quad_kappa: 0.513101\n",
      "[4200]\ttraining's multi_logloss: 0.828196\ttraining's quad_kappa: 0.615901\tvalid_1's multi_logloss: 1.00055\tvalid_1's quad_kappa: 0.511978\n",
      "[4300]\ttraining's multi_logloss: 0.825393\ttraining's quad_kappa: 0.617576\tvalid_1's multi_logloss: 1.00084\tvalid_1's quad_kappa: 0.512115\n",
      "[4400]\ttraining's multi_logloss: 0.822684\ttraining's quad_kappa: 0.618469\tvalid_1's multi_logloss: 1.00107\tvalid_1's quad_kappa: 0.514689\n",
      "[4500]\ttraining's multi_logloss: 0.819999\ttraining's quad_kappa: 0.620271\tvalid_1's multi_logloss: 1.0014\tvalid_1's quad_kappa: 0.516437\n",
      "[4600]\ttraining's multi_logloss: 0.817182\ttraining's quad_kappa: 0.621849\tvalid_1's multi_logloss: 1.00174\tvalid_1's quad_kappa: 0.5113\n",
      "[4700]\ttraining's multi_logloss: 0.814507\ttraining's quad_kappa: 0.62239\tvalid_1's multi_logloss: 1.0021\tvalid_1's quad_kappa: 0.5113\n",
      "[4800]\ttraining's multi_logloss: 0.811741\ttraining's quad_kappa: 0.6237\tvalid_1's multi_logloss: 1.00246\tvalid_1's quad_kappa: 0.511468\n",
      "[4900]\ttraining's multi_logloss: 0.809054\ttraining's quad_kappa: 0.624593\tvalid_1's multi_logloss: 1.0029\tvalid_1's quad_kappa: 0.512763\n",
      "[5000]\ttraining's multi_logloss: 0.806569\ttraining's quad_kappa: 0.626059\tvalid_1's multi_logloss: 1.00342\tvalid_1's quad_kappa: 0.512255\n",
      "[5100]\ttraining's multi_logloss: 0.804036\ttraining's quad_kappa: 0.627419\tvalid_1's multi_logloss: 1.00387\tvalid_1's quad_kappa: 0.512423\n",
      "[5200]\ttraining's multi_logloss: 0.801525\ttraining's quad_kappa: 0.62875\tvalid_1's multi_logloss: 1.00438\tvalid_1's quad_kappa: 0.512426\n",
      "[5300]\ttraining's multi_logloss: 0.79906\ttraining's quad_kappa: 0.630685\tvalid_1's multi_logloss: 1.00483\tvalid_1's quad_kappa: 0.513113\n",
      "[5400]\ttraining's multi_logloss: 0.796667\ttraining's quad_kappa: 0.631791\tvalid_1's multi_logloss: 1.00528\tvalid_1's quad_kappa: 0.513706\n",
      "[5500]\ttraining's multi_logloss: 0.794342\ttraining's quad_kappa: 0.632549\tvalid_1's multi_logloss: 1.00581\tvalid_1's quad_kappa: 0.514423\n",
      "Early stopping, best iteration is:                                                 \n",
      "[3544]\ttraining's multi_logloss: 0.84717\ttraining's quad_kappa: 0.606272\tvalid_1's multi_logloss: 0.999962\tvalid_1's quad_kappa: 0.513123\n",
      "Training until validation scores don't improve for 2000 rounds                     \n",
      "[100]\ttraining's multi_logloss: 1.13683\ttraining's quad_kappa: 0.259123\tvalid_1's multi_logloss: 1.14675\tvalid_1's quad_kappa: 0.244038\n",
      "[200]\ttraining's multi_logloss: 1.09152\ttraining's quad_kappa: 0.339939\tvalid_1's multi_logloss: 1.10858\tvalid_1's quad_kappa: 0.316552\n",
      "[300]\ttraining's multi_logloss: 1.06358\ttraining's quad_kappa: 0.373823\tvalid_1's multi_logloss: 1.08591\tvalid_1's quad_kappa: 0.350771\n",
      "[400]\ttraining's multi_logloss: 1.04305\ttraining's quad_kappa: 0.414784\tvalid_1's multi_logloss: 1.06967\tvalid_1's quad_kappa: 0.386829\n",
      "[500]\ttraining's multi_logloss: 1.02695\ttraining's quad_kappa: 0.444969\tvalid_1's multi_logloss: 1.05788\tvalid_1's quad_kappa: 0.423526\n",
      "[600]\ttraining's multi_logloss: 1.01328\ttraining's quad_kappa: 0.460753\tvalid_1's multi_logloss: 1.04897\tvalid_1's quad_kappa: 0.43552\n",
      "[700]\ttraining's multi_logloss: 1.00163\ttraining's quad_kappa: 0.476516\tvalid_1's multi_logloss: 1.04165\tvalid_1's quad_kappa: 0.457375\n",
      "[800]\ttraining's multi_logloss: 0.991891\ttraining's quad_kappa: 0.486532\tvalid_1's multi_logloss: 1.03598\tvalid_1's quad_kappa: 0.470736\n",
      "[900]\ttraining's multi_logloss: 0.983005\ttraining's quad_kappa: 0.498456\tvalid_1's multi_logloss: 1.03089\tvalid_1's quad_kappa: 0.48897\n",
      "[1000]\ttraining's multi_logloss: 0.974563\ttraining's quad_kappa: 0.505528\tvalid_1's multi_logloss: 1.02624\tvalid_1's quad_kappa: 0.498842\n",
      "[1100]\ttraining's multi_logloss: 0.966803\ttraining's quad_kappa: 0.518655\tvalid_1's multi_logloss: 1.02204\tvalid_1's quad_kappa: 0.507771\n",
      "[1200]\ttraining's multi_logloss: 0.959965\ttraining's quad_kappa: 0.52483\tvalid_1's multi_logloss: 1.01875\tvalid_1's quad_kappa: 0.509697\n",
      "[1300]\ttraining's multi_logloss: 0.953784\ttraining's quad_kappa: 0.528537\tvalid_1's multi_logloss: 1.01631\tvalid_1's quad_kappa: 0.520635\n",
      "[1400]\ttraining's multi_logloss: 0.948082\ttraining's quad_kappa: 0.535291\tvalid_1's multi_logloss: 1.01437\tvalid_1's quad_kappa: 0.52485\n",
      "[1500]\ttraining's multi_logloss: 0.942736\ttraining's quad_kappa: 0.539034\tvalid_1's multi_logloss: 1.01258\tvalid_1's quad_kappa: 0.525171\n",
      "[1600]\ttraining's multi_logloss: 0.937325\ttraining's quad_kappa: 0.541396\tvalid_1's multi_logloss: 1.01081\tvalid_1's quad_kappa: 0.524172\n",
      "[1700]\ttraining's multi_logloss: 0.932733\ttraining's quad_kappa: 0.543839\tvalid_1's multi_logloss: 1.00932\tvalid_1's quad_kappa: 0.52254\n",
      "[1800]\ttraining's multi_logloss: 0.928218\ttraining's quad_kappa: 0.546028\tvalid_1's multi_logloss: 1.00806\tvalid_1's quad_kappa: 0.524762\n",
      "[1900]\ttraining's multi_logloss: 0.923777\ttraining's quad_kappa: 0.549042\tvalid_1's multi_logloss: 1.00708\tvalid_1's quad_kappa: 0.526615\n",
      "[2000]\ttraining's multi_logloss: 0.919369\ttraining's quad_kappa: 0.552137\tvalid_1's multi_logloss: 1.00586\tvalid_1's quad_kappa: 0.531502\n",
      "[2100]\ttraining's multi_logloss: 0.915157\ttraining's quad_kappa: 0.55277\tvalid_1's multi_logloss: 1.00475\tvalid_1's quad_kappa: 0.530617\n",
      "[2200]\ttraining's multi_logloss: 0.911116\ttraining's quad_kappa: 0.554983\tvalid_1's multi_logloss: 1.00381\tvalid_1's quad_kappa: 0.52991\n",
      "[2300]\ttraining's multi_logloss: 0.907277\ttraining's quad_kappa: 0.556394\tvalid_1's multi_logloss: 1.00313\tvalid_1's quad_kappa: 0.53093\n",
      "[2400]\ttraining's multi_logloss: 0.903513\ttraining's quad_kappa: 0.559964\tvalid_1's multi_logloss: 1.00256\tvalid_1's quad_kappa: 0.53166\n",
      "[2500]\ttraining's multi_logloss: 0.899888\ttraining's quad_kappa: 0.561454\tvalid_1's multi_logloss: 1.00203\tvalid_1's quad_kappa: 0.532567\n",
      "[2600]\ttraining's multi_logloss: 0.896403\ttraining's quad_kappa: 0.562981\tvalid_1's multi_logloss: 1.00159\tvalid_1's quad_kappa: 0.53551\n",
      "[2700]\ttraining's multi_logloss: 0.892931\ttraining's quad_kappa: 0.566831\tvalid_1's multi_logloss: 1.00115\tvalid_1's quad_kappa: 0.536796\n",
      "[2800]\ttraining's multi_logloss: 0.889572\ttraining's quad_kappa: 0.569059\tvalid_1's multi_logloss: 1.00079\tvalid_1's quad_kappa: 0.539205\n",
      "[2900]\ttraining's multi_logloss: 0.886238\ttraining's quad_kappa: 0.572466\tvalid_1's multi_logloss: 1.00043\tvalid_1's quad_kappa: 0.538746\n",
      "[3000]\ttraining's multi_logloss: 0.8831\ttraining's quad_kappa: 0.574661\tvalid_1's multi_logloss: 1.00007\tvalid_1's quad_kappa: 0.540806\n",
      "[3100]\ttraining's multi_logloss: 0.879947\ttraining's quad_kappa: 0.576908\tvalid_1's multi_logloss: 0.999856\tvalid_1's quad_kappa: 0.537024\n",
      "[3200]\ttraining's multi_logloss: 0.876817\ttraining's quad_kappa: 0.578677\tvalid_1's multi_logloss: 0.999772\tvalid_1's quad_kappa: 0.536229\n",
      "[3300]\ttraining's multi_logloss: 0.873726\ttraining's quad_kappa: 0.579733\tvalid_1's multi_logloss: 0.999633\tvalid_1's quad_kappa: 0.5343\n",
      "[3400]\ttraining's multi_logloss: 0.870596\ttraining's quad_kappa: 0.582635\tvalid_1's multi_logloss: 0.999543\tvalid_1's quad_kappa: 0.533657\n",
      "[3500]\ttraining's multi_logloss: 0.867577\ttraining's quad_kappa: 0.585617\tvalid_1's multi_logloss: 0.999508\tvalid_1's quad_kappa: 0.531528\n",
      "[3600]\ttraining's multi_logloss: 0.864528\ttraining's quad_kappa: 0.588441\tvalid_1's multi_logloss: 0.999563\tvalid_1's quad_kappa: 0.530438\n",
      "[3700]\ttraining's multi_logloss: 0.861525\ttraining's quad_kappa: 0.590027\tvalid_1's multi_logloss: 0.999504\tvalid_1's quad_kappa: 0.529417\n",
      "[3800]\ttraining's multi_logloss: 0.858506\ttraining's quad_kappa: 0.592784\tvalid_1's multi_logloss: 0.999375\tvalid_1's quad_kappa: 0.528231\n",
      "[3900]\ttraining's multi_logloss: 0.85569\ttraining's quad_kappa: 0.59496\tvalid_1's multi_logloss: 0.999384\tvalid_1's quad_kappa: 0.531192\n",
      "[4000]\ttraining's multi_logloss: 0.85276\ttraining's quad_kappa: 0.595982\tvalid_1's multi_logloss: 0.999371\tvalid_1's quad_kappa: 0.530524\n",
      "[4100]\ttraining's multi_logloss: 0.849976\ttraining's quad_kappa: 0.597624\tvalid_1's multi_logloss: 0.999534\tvalid_1's quad_kappa: 0.530524\n",
      "[4200]\ttraining's multi_logloss: 0.847168\ttraining's quad_kappa: 0.600051\tvalid_1's multi_logloss: 0.999684\tvalid_1's quad_kappa: 0.531211\n",
      "[4300]\ttraining's multi_logloss: 0.844383\ttraining's quad_kappa: 0.601287\tvalid_1's multi_logloss: 0.999748\tvalid_1's quad_kappa: 0.532101\n",
      "[4400]\ttraining's multi_logloss: 0.841559\ttraining's quad_kappa: 0.603003\tvalid_1's multi_logloss: 0.999898\tvalid_1's quad_kappa: 0.535022\n",
      "[4500]\ttraining's multi_logloss: 0.838975\ttraining's quad_kappa: 0.605381\tvalid_1's multi_logloss: 1.00017\tvalid_1's quad_kappa: 0.53384\n",
      "[4600]\ttraining's multi_logloss: 0.83626\ttraining's quad_kappa: 0.608179\tvalid_1's multi_logloss: 1.00028\tvalid_1's quad_kappa: 0.535382\n",
      "[4700]\ttraining's multi_logloss: 0.833673\ttraining's quad_kappa: 0.61015\tvalid_1's multi_logloss: 1.00053\tvalid_1's quad_kappa: 0.534448\n",
      "[4800]\ttraining's multi_logloss: 0.831108\ttraining's quad_kappa: 0.611724\tvalid_1's multi_logloss: 1.00067\tvalid_1's quad_kappa: 0.538082\n",
      "[4900]\ttraining's multi_logloss: 0.828616\ttraining's quad_kappa: 0.612958\tvalid_1's multi_logloss: 1.00092\tvalid_1's quad_kappa: 0.539598\n",
      "[5000]\ttraining's multi_logloss: 0.826186\ttraining's quad_kappa: 0.615458\tvalid_1's multi_logloss: 1.00121\tvalid_1's quad_kappa: 0.540847\n",
      "[5100]\ttraining's multi_logloss: 0.823637\ttraining's quad_kappa: 0.615813\tvalid_1's multi_logloss: 1.00163\tvalid_1's quad_kappa: 0.53628\n",
      "[5200]\ttraining's multi_logloss: 0.821159\ttraining's quad_kappa: 0.616878\tvalid_1's multi_logloss: 1.002\tvalid_1's quad_kappa: 0.536106\n",
      "[5300]\ttraining's multi_logloss: 0.818731\ttraining's quad_kappa: 0.618471\tvalid_1's multi_logloss: 1.00244\tvalid_1's quad_kappa: 0.536106\n",
      "[5400]\ttraining's multi_logloss: 0.816363\ttraining's quad_kappa: 0.619957\tvalid_1's multi_logloss: 1.00283\tvalid_1's quad_kappa: 0.53481\n",
      "[5500]\ttraining's multi_logloss: 0.814004\ttraining's quad_kappa: 0.61981\tvalid_1's multi_logloss: 1.00328\tvalid_1's quad_kappa: 0.536149\n",
      "[5600]\ttraining's multi_logloss: 0.811561\ttraining's quad_kappa: 0.622101\tvalid_1's multi_logloss: 1.00363\tvalid_1's quad_kappa: 0.538403\n",
      "[5700]\ttraining's multi_logloss: 0.809237\ttraining's quad_kappa: 0.62278\tvalid_1's multi_logloss: 1.00394\tvalid_1's quad_kappa: 0.537109\n",
      "[5800]\ttraining's multi_logloss: 0.806999\ttraining's quad_kappa: 0.625287\tvalid_1's multi_logloss: 1.00426\tvalid_1's quad_kappa: 0.539738\n",
      "Early stopping, best iteration is:                                                 \n",
      "[3841]\ttraining's multi_logloss: 0.857333\ttraining's quad_kappa: 0.593408\tvalid_1's multi_logloss: 0.999335\tvalid_1's quad_kappa: 0.529859\n",
      "{'feature_fraction': 0.09, 'lambda_l1': 0.9186915836566155, 'lambda_l2': 0.24378982475915031, 'learning_rate': 0.007, 'max_depth': 3.0, 'metric': 'multiclass', 'n_estimators': 10000, 'num_classes': 4, 'num_leaves': 127, 'objective': 'multiclass', 'random_state': 2019, 'subsample': 0.66}\n",
      "Training until validation scores don't improve for 2000 rounds                     \n",
      " 28%|██▊       | 7/25 [1:20:29<3:28:44, 695.78s/it, best loss: -0.5188369088259418]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 1.1881\ttraining's quad_kappa: 0\tvalid_1's multi_logloss: 1.18126\tvalid_1's quad_kappa: 0\n",
      "[200]\ttraining's multi_logloss: 1.16114\ttraining's quad_kappa: 0.00473087\tvalid_1's multi_logloss: 1.15843\tvalid_1's quad_kappa: 0.00467145\n",
      "[300]\ttraining's multi_logloss: 1.13588\ttraining's quad_kappa: 0.0574882\tvalid_1's multi_logloss: 1.13675\tvalid_1's quad_kappa: 0.0565198\n",
      "[400]\ttraining's multi_logloss: 1.11581\ttraining's quad_kappa: 0.158511\tvalid_1's multi_logloss: 1.12074\tvalid_1's quad_kappa: 0.165525\n",
      "[500]\ttraining's multi_logloss: 1.10088\ttraining's quad_kappa: 0.220927\tvalid_1's multi_logloss: 1.10934\tvalid_1's quad_kappa: 0.227909\n",
      "[600]\ttraining's multi_logloss: 1.08705\ttraining's quad_kappa: 0.267114\tvalid_1's multi_logloss: 1.09926\tvalid_1's quad_kappa: 0.261057\n",
      "[700]\ttraining's multi_logloss: 1.07477\ttraining's quad_kappa: 0.305333\tvalid_1's multi_logloss: 1.09043\tvalid_1's quad_kappa: 0.300018\n",
      "[800]\ttraining's multi_logloss: 1.06288\ttraining's quad_kappa: 0.345558\tvalid_1's multi_logloss: 1.082\tvalid_1's quad_kappa: 0.332979\n",
      "[900]\ttraining's multi_logloss: 1.0525\ttraining's quad_kappa: 0.377398\tvalid_1's multi_logloss: 1.07485\tvalid_1's quad_kappa: 0.365879\n",
      "[1000]\ttraining's multi_logloss: 1.04222\ttraining's quad_kappa: 0.39899\tvalid_1's multi_logloss: 1.0681\tvalid_1's quad_kappa: 0.377902\n",
      "[1100]\ttraining's multi_logloss: 1.03345\ttraining's quad_kappa: 0.414105\tvalid_1's multi_logloss: 1.06259\tvalid_1's quad_kappa: 0.388369\n",
      "[1200]\ttraining's multi_logloss: 1.02466\ttraining's quad_kappa: 0.428811\tvalid_1's multi_logloss: 1.0569\tvalid_1's quad_kappa: 0.396264\n",
      "[1300]\ttraining's multi_logloss: 1.01662\ttraining's quad_kappa: 0.442719\tvalid_1's multi_logloss: 1.05202\tvalid_1's quad_kappa: 0.409534\n",
      "[1400]\ttraining's multi_logloss: 1.00895\ttraining's quad_kappa: 0.453954\tvalid_1's multi_logloss: 1.04749\tvalid_1's quad_kappa: 0.409943\n",
      "[1500]\ttraining's multi_logloss: 1.00326\ttraining's quad_kappa: 0.46388\tvalid_1's multi_logloss: 1.04489\tvalid_1's quad_kappa: 0.411554\n",
      "[1600]\ttraining's multi_logloss: 0.997018\ttraining's quad_kappa: 0.4717\tvalid_1's multi_logloss: 1.0418\tvalid_1's quad_kappa: 0.422652\n",
      "[1700]\ttraining's multi_logloss: 0.991442\ttraining's quad_kappa: 0.476053\tvalid_1's multi_logloss: 1.03933\tvalid_1's quad_kappa: 0.420276\n",
      "[1800]\ttraining's multi_logloss: 0.985531\ttraining's quad_kappa: 0.486153\tvalid_1's multi_logloss: 1.03662\tvalid_1's quad_kappa: 0.432499\n",
      "[1900]\ttraining's multi_logloss: 0.980286\ttraining's quad_kappa: 0.492004\tvalid_1's multi_logloss: 1.03426\tvalid_1's quad_kappa: 0.435046\n",
      "[2000]\ttraining's multi_logloss: 0.975417\ttraining's quad_kappa: 0.501096\tvalid_1's multi_logloss: 1.03219\tvalid_1's quad_kappa: 0.444727\n",
      "[2100]\ttraining's multi_logloss: 0.97096\ttraining's quad_kappa: 0.50535\tvalid_1's multi_logloss: 1.03066\tvalid_1's quad_kappa: 0.449878\n",
      "[2200]\ttraining's multi_logloss: 0.966775\ttraining's quad_kappa: 0.511657\tvalid_1's multi_logloss: 1.02946\tvalid_1's quad_kappa: 0.45943\n",
      "[2300]\ttraining's multi_logloss: 0.962526\ttraining's quad_kappa: 0.51574\tvalid_1's multi_logloss: 1.02793\tvalid_1's quad_kappa: 0.459139\n",
      "[2400]\ttraining's multi_logloss: 0.958381\ttraining's quad_kappa: 0.521597\tvalid_1's multi_logloss: 1.0264\tvalid_1's quad_kappa: 0.460118\n",
      "[2500]\ttraining's multi_logloss: 0.95415\ttraining's quad_kappa: 0.526257\tvalid_1's multi_logloss: 1.02484\tvalid_1's quad_kappa: 0.465676\n",
      "[2600]\ttraining's multi_logloss: 0.950315\ttraining's quad_kappa: 0.526986\tvalid_1's multi_logloss: 1.02353\tvalid_1's quad_kappa: 0.4634\n",
      "[2700]\ttraining's multi_logloss: 0.946617\ttraining's quad_kappa: 0.530921\tvalid_1's multi_logloss: 1.02239\tvalid_1's quad_kappa: 0.46596\n",
      "[2800]\ttraining's multi_logloss: 0.942954\ttraining's quad_kappa: 0.532776\tvalid_1's multi_logloss: 1.02141\tvalid_1's quad_kappa: 0.466409\n",
      "[2900]\ttraining's multi_logloss: 0.939583\ttraining's quad_kappa: 0.535999\tvalid_1's multi_logloss: 1.0204\tvalid_1's quad_kappa: 0.464954\n",
      "[3000]\ttraining's multi_logloss: 0.936128\ttraining's quad_kappa: 0.539414\tvalid_1's multi_logloss: 1.01936\tvalid_1's quad_kappa: 0.462783\n",
      "[3100]\ttraining's multi_logloss: 0.932411\ttraining's quad_kappa: 0.542684\tvalid_1's multi_logloss: 1.01818\tvalid_1's quad_kappa: 0.469001\n",
      "[3200]\ttraining's multi_logloss: 0.92902\ttraining's quad_kappa: 0.543787\tvalid_1's multi_logloss: 1.01726\tvalid_1's quad_kappa: 0.469717\n",
      "[3300]\ttraining's multi_logloss: 0.925665\ttraining's quad_kappa: 0.544479\tvalid_1's multi_logloss: 1.01623\tvalid_1's quad_kappa: 0.471773\n",
      "[3400]\ttraining's multi_logloss: 0.922122\ttraining's quad_kappa: 0.548722\tvalid_1's multi_logloss: 1.0151\tvalid_1's quad_kappa: 0.477259\n",
      "[3500]\ttraining's multi_logloss: 0.919067\ttraining's quad_kappa: 0.550997\tvalid_1's multi_logloss: 1.01445\tvalid_1's quad_kappa: 0.477519\n",
      "[3600]\ttraining's multi_logloss: 0.916032\ttraining's quad_kappa: 0.552833\tvalid_1's multi_logloss: 1.01392\tvalid_1's quad_kappa: 0.476408\n",
      "[3700]\ttraining's multi_logloss: 0.913151\ttraining's quad_kappa: 0.554751\tvalid_1's multi_logloss: 1.01334\tvalid_1's quad_kappa: 0.478233\n",
      "[3800]\ttraining's multi_logloss: 0.910451\ttraining's quad_kappa: 0.55651\tvalid_1's multi_logloss: 1.01295\tvalid_1's quad_kappa: 0.477497\n",
      "[3900]\ttraining's multi_logloss: 0.907672\ttraining's quad_kappa: 0.556105\tvalid_1's multi_logloss: 1.01232\tvalid_1's quad_kappa: 0.475408\n",
      "[4000]\ttraining's multi_logloss: 0.904907\ttraining's quad_kappa: 0.55784\tvalid_1's multi_logloss: 1.01192\tvalid_1's quad_kappa: 0.475408\n",
      "[4100]\ttraining's multi_logloss: 0.902212\ttraining's quad_kappa: 0.55993\tvalid_1's multi_logloss: 1.01138\tvalid_1's quad_kappa: 0.478178\n",
      "[4200]\ttraining's multi_logloss: 0.899575\ttraining's quad_kappa: 0.561881\tvalid_1's multi_logloss: 1.01111\tvalid_1's quad_kappa: 0.478928\n",
      "[4300]\ttraining's multi_logloss: 0.896862\ttraining's quad_kappa: 0.563449\tvalid_1's multi_logloss: 1.01073\tvalid_1's quad_kappa: 0.480666\n",
      "[4400]\ttraining's multi_logloss: 0.894437\ttraining's quad_kappa: 0.565419\tvalid_1's multi_logloss: 1.01062\tvalid_1's quad_kappa: 0.475194\n",
      "[4500]\ttraining's multi_logloss: 0.89188\ttraining's quad_kappa: 0.565594\tvalid_1's multi_logloss: 1.0103\tvalid_1's quad_kappa: 0.482514\n",
      "[4600]\ttraining's multi_logloss: 0.889642\ttraining's quad_kappa: 0.567907\tvalid_1's multi_logloss: 1.01025\tvalid_1's quad_kappa: 0.482113\n",
      "[4700]\ttraining's multi_logloss: 0.887321\ttraining's quad_kappa: 0.569493\tvalid_1's multi_logloss: 1.01011\tvalid_1's quad_kappa: 0.480516\n",
      "[4800]\ttraining's multi_logloss: 0.884992\ttraining's quad_kappa: 0.570849\tvalid_1's multi_logloss: 1.00994\tvalid_1's quad_kappa: 0.483276\n",
      "[4900]\ttraining's multi_logloss: 0.882642\ttraining's quad_kappa: 0.572623\tvalid_1's multi_logloss: 1.00987\tvalid_1's quad_kappa: 0.483013\n",
      "[5000]\ttraining's multi_logloss: 0.880326\ttraining's quad_kappa: 0.574116\tvalid_1's multi_logloss: 1.00983\tvalid_1's quad_kappa: 0.481878\n",
      "[5100]\ttraining's multi_logloss: 0.878014\ttraining's quad_kappa: 0.575144\tvalid_1's multi_logloss: 1.00976\tvalid_1's quad_kappa: 0.481569\n",
      "[5200]\ttraining's multi_logloss: 0.87574\ttraining's quad_kappa: 0.575716\tvalid_1's multi_logloss: 1.00965\tvalid_1's quad_kappa: 0.483278\n",
      "[5300]\ttraining's multi_logloss: 0.873633\ttraining's quad_kappa: 0.57662\tvalid_1's multi_logloss: 1.00975\tvalid_1's quad_kappa: 0.479958\n",
      "[5400]\ttraining's multi_logloss: 0.871425\ttraining's quad_kappa: 0.577903\tvalid_1's multi_logloss: 1.00956\tvalid_1's quad_kappa: 0.481872\n",
      "[5500]\ttraining's multi_logloss: 0.869377\ttraining's quad_kappa: 0.578724\tvalid_1's multi_logloss: 1.00959\tvalid_1's quad_kappa: 0.480946\n",
      "[5600]\ttraining's multi_logloss: 0.867281\ttraining's quad_kappa: 0.580497\tvalid_1's multi_logloss: 1.00958\tvalid_1's quad_kappa: 0.485402\n",
      "[5700]\ttraining's multi_logloss: 0.865147\ttraining's quad_kappa: 0.58087\tvalid_1's multi_logloss: 1.00946\tvalid_1's quad_kappa: 0.484884\n",
      "[5800]\ttraining's multi_logloss: 0.863151\ttraining's quad_kappa: 0.582206\tvalid_1's multi_logloss: 1.00941\tvalid_1's quad_kappa: 0.482046\n",
      "[5900]\ttraining's multi_logloss: 0.861182\ttraining's quad_kappa: 0.583485\tvalid_1's multi_logloss: 1.00942\tvalid_1's quad_kappa: 0.484454\n",
      "[6000]\ttraining's multi_logloss: 0.859282\ttraining's quad_kappa: 0.584608\tvalid_1's multi_logloss: 1.00937\tvalid_1's quad_kappa: 0.486507\n",
      "[6100]\ttraining's multi_logloss: 0.857339\ttraining's quad_kappa: 0.584833\tvalid_1's multi_logloss: 1.00945\tvalid_1's quad_kappa: 0.486188\n",
      "[6200]\ttraining's multi_logloss: 0.855343\ttraining's quad_kappa: 0.585341\tvalid_1's multi_logloss: 1.00937\tvalid_1's quad_kappa: 0.479836\n",
      "[6300]\ttraining's multi_logloss: 0.853239\ttraining's quad_kappa: 0.586034\tvalid_1's multi_logloss: 1.00935\tvalid_1's quad_kappa: 0.481053\n",
      "[6400]\ttraining's multi_logloss: 0.851304\ttraining's quad_kappa: 0.586455\tvalid_1's multi_logloss: 1.00944\tvalid_1's quad_kappa: 0.481967\n",
      "[6500]\ttraining's multi_logloss: 0.849431\ttraining's quad_kappa: 0.587223\tvalid_1's multi_logloss: 1.00949\tvalid_1's quad_kappa: 0.486048\n",
      "[6600]\ttraining's multi_logloss: 0.847572\ttraining's quad_kappa: 0.588973\tvalid_1's multi_logloss: 1.00945\tvalid_1's quad_kappa: 0.485077\n",
      "[6700]\ttraining's multi_logloss: 0.845662\ttraining's quad_kappa: 0.590328\tvalid_1's multi_logloss: 1.00941\tvalid_1's quad_kappa: 0.48405\n",
      "[6800]\ttraining's multi_logloss: 0.843808\ttraining's quad_kappa: 0.591445\tvalid_1's multi_logloss: 1.00955\tvalid_1's quad_kappa: 0.486734\n",
      "[6900]\ttraining's multi_logloss: 0.841993\ttraining's quad_kappa: 0.59266\tvalid_1's multi_logloss: 1.00966\tvalid_1's quad_kappa: 0.488394\n",
      "[7000]\ttraining's multi_logloss: 0.840172\ttraining's quad_kappa: 0.593709\tvalid_1's multi_logloss: 1.0097\tvalid_1's quad_kappa: 0.487952\n",
      " 28%|██▊       | 7/25 [1:26:13<3:28:44, 695.78s/it, best loss: -0.5188369088259418]"
     ]
    }
   ],
   "source": [
    "best_params=tune(check_hyperparams, n_tries=25, n_learning_rate_tries=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_fraction': 0.58,\n",
       " 'lambda_l1': 0.45619796864269707,\n",
       " 'lambda_l2': 0.033257384218246686,\n",
       " 'learning_rate': 0.007,\n",
       " 'max_depth': 14,\n",
       " 'metric': 'multiclass',\n",
       " 'n_estimators': 10000,\n",
       " 'num_classes': 4,\n",
       " 'num_leaves': 31,\n",
       " 'objective': 'multiclass',\n",
       " 'random_state': 2019,\n",
       " 'subsample': 0.9500000000000001}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was selected on 20% of the data\n",
    "\n",
    "```{'feature_fraction': 0.27,\n",
    " 'lambda_l1': 0.9296219935562766,\n",
    " 'lambda_l2': 0.9285156686215876,\n",
    " 'learning_rate': 0.222,\n",
    " 'max_depth': 5,\n",
    " 'metric': 'multiclass',\n",
    " 'n_estimators': 10000,\n",
    " 'num_classes': 4,\n",
    " 'num_leaves': 15,\n",
    " 'objective': 'multiclass',\n",
    " 'random_state': 2019,\n",
    " 'subsample': 0.73}```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was selected on 100% of the data\n",
    "\n",
    "```\n",
    "{'feature_fraction': 0.58,\n",
    " 'lambda_l1': 0.45619796864269707,\n",
    " 'lambda_l2': 0.033257384218246686,\n",
    " 'learning_rate': 0.007,\n",
    " 'max_depth': 14,\n",
    " 'metric': 'multiclass',\n",
    " 'n_estimators': 10000,\n",
    " 'num_classes': 4,\n",
    " 'num_leaves': 31,\n",
    " 'objective': 'multiclass',\n",
    " 'random_state': 2019,\n",
    " 'subsample': 0.9500000000000001}```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params={'feature_fraction': 0.58,\n",
    " 'lambda_l1': 0.45619796864269707,\n",
    " 'lambda_l2': 0.033257384218246686,\n",
    " 'learning_rate': 0.007,\n",
    " 'max_depth': 14,\n",
    " 'metric': 'multiclass',\n",
    " 'n_estimators': 10000,\n",
    " 'num_classes': 4,\n",
    " 'num_leaves': 31,\n",
    " 'objective': 'multiclass',\n",
    " 'random_state': 2019,\n",
    " 'subsample': 0.9500000000000001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2000 rounds\n",
      "[100]\ttraining's multi_logloss: 1.08977\ttraining's quad_kappa: 0.264106\tvalid_1's multi_logloss: 1.12916\tvalid_1's quad_kappa: 0.240477\n",
      "[200]\ttraining's multi_logloss: 1.01707\ttraining's quad_kappa: 0.477512\tvalid_1's multi_logloss: 1.07882\tvalid_1's quad_kappa: 0.425825\n",
      "[300]\ttraining's multi_logloss: 0.968452\ttraining's quad_kappa: 0.528077\tvalid_1's multi_logloss: 1.04972\tvalid_1's quad_kappa: 0.485027\n",
      "[400]\ttraining's multi_logloss: 0.93349\ttraining's quad_kappa: 0.551051\tvalid_1's multi_logloss: 1.03293\tvalid_1's quad_kappa: 0.496872\n",
      "[500]\ttraining's multi_logloss: 0.905467\ttraining's quad_kappa: 0.567028\tvalid_1's multi_logloss: 1.02182\tvalid_1's quad_kappa: 0.504934\n",
      "[600]\ttraining's multi_logloss: 0.882504\ttraining's quad_kappa: 0.579941\tvalid_1's multi_logloss: 1.01512\tvalid_1's quad_kappa: 0.506612\n",
      "[700]\ttraining's multi_logloss: 0.862744\ttraining's quad_kappa: 0.590794\tvalid_1's multi_logloss: 1.01108\tvalid_1's quad_kappa: 0.508686\n",
      "[800]\ttraining's multi_logloss: 0.845345\ttraining's quad_kappa: 0.598279\tvalid_1's multi_logloss: 1.00884\tvalid_1's quad_kappa: 0.509733\n",
      "[900]\ttraining's multi_logloss: 0.829583\ttraining's quad_kappa: 0.608557\tvalid_1's multi_logloss: 1.00728\tvalid_1's quad_kappa: 0.51702\n",
      "[1000]\ttraining's multi_logloss: 0.815118\ttraining's quad_kappa: 0.618018\tvalid_1's multi_logloss: 1.00635\tvalid_1's quad_kappa: 0.521889\n",
      "[1100]\ttraining's multi_logloss: 0.801722\ttraining's quad_kappa: 0.625508\tvalid_1's multi_logloss: 1.00525\tvalid_1's quad_kappa: 0.524286\n",
      "[1200]\ttraining's multi_logloss: 0.78956\ttraining's quad_kappa: 0.6324\tvalid_1's multi_logloss: 1.0048\tvalid_1's quad_kappa: 0.526518\n",
      "[1300]\ttraining's multi_logloss: 0.778141\ttraining's quad_kappa: 0.639267\tvalid_1's multi_logloss: 1.00466\tvalid_1's quad_kappa: 0.523475\n",
      "[1400]\ttraining's multi_logloss: 0.767323\ttraining's quad_kappa: 0.646835\tvalid_1's multi_logloss: 1.00465\tvalid_1's quad_kappa: 0.521554\n",
      "[1500]\ttraining's multi_logloss: 0.757016\ttraining's quad_kappa: 0.65273\tvalid_1's multi_logloss: 1.00448\tvalid_1's quad_kappa: 0.523296\n",
      "[1600]\ttraining's multi_logloss: 0.747208\ttraining's quad_kappa: 0.659122\tvalid_1's multi_logloss: 1.00453\tvalid_1's quad_kappa: 0.521952\n",
      "[1700]\ttraining's multi_logloss: 0.737633\ttraining's quad_kappa: 0.6635\tvalid_1's multi_logloss: 1.00506\tvalid_1's quad_kappa: 0.520018\n",
      "[1800]\ttraining's multi_logloss: 0.728449\ttraining's quad_kappa: 0.667478\tvalid_1's multi_logloss: 1.00581\tvalid_1's quad_kappa: 0.519793\n",
      "[1900]\ttraining's multi_logloss: 0.719691\ttraining's quad_kappa: 0.672408\tvalid_1's multi_logloss: 1.00633\tvalid_1's quad_kappa: 0.521464\n",
      "[2000]\ttraining's multi_logloss: 0.711019\ttraining's quad_kappa: 0.678134\tvalid_1's multi_logloss: 1.00724\tvalid_1's quad_kappa: 0.524032\n",
      "[2100]\ttraining's multi_logloss: 0.702708\ttraining's quad_kappa: 0.683287\tvalid_1's multi_logloss: 1.00803\tvalid_1's quad_kappa: 0.521558\n",
      "[2200]\ttraining's multi_logloss: 0.694465\ttraining's quad_kappa: 0.688584\tvalid_1's multi_logloss: 1.00875\tvalid_1's quad_kappa: 0.517228\n",
      "[2300]\ttraining's multi_logloss: 0.686461\ttraining's quad_kappa: 0.691932\tvalid_1's multi_logloss: 1.00979\tvalid_1's quad_kappa: 0.518731\n",
      "[2400]\ttraining's multi_logloss: 0.678725\ttraining's quad_kappa: 0.696201\tvalid_1's multi_logloss: 1.01085\tvalid_1's quad_kappa: 0.520107\n",
      "[2500]\ttraining's multi_logloss: 0.671451\ttraining's quad_kappa: 0.699149\tvalid_1's multi_logloss: 1.01189\tvalid_1's quad_kappa: 0.521343\n",
      "[2600]\ttraining's multi_logloss: 0.664243\ttraining's quad_kappa: 0.702868\tvalid_1's multi_logloss: 1.013\tvalid_1's quad_kappa: 0.52347\n",
      "[2700]\ttraining's multi_logloss: 0.657063\ttraining's quad_kappa: 0.706297\tvalid_1's multi_logloss: 1.01428\tvalid_1's quad_kappa: 0.522891\n",
      "[2800]\ttraining's multi_logloss: 0.650229\ttraining's quad_kappa: 0.709835\tvalid_1's multi_logloss: 1.01549\tvalid_1's quad_kappa: 0.522773\n",
      "[2900]\ttraining's multi_logloss: 0.64346\ttraining's quad_kappa: 0.71304\tvalid_1's multi_logloss: 1.01656\tvalid_1's quad_kappa: 0.522309\n",
      "[3000]\ttraining's multi_logloss: 0.636869\ttraining's quad_kappa: 0.716666\tvalid_1's multi_logloss: 1.01782\tvalid_1's quad_kappa: 0.523773\n",
      "[3100]\ttraining's multi_logloss: 0.630377\ttraining's quad_kappa: 0.721055\tvalid_1's multi_logloss: 1.01914\tvalid_1's quad_kappa: 0.523223\n",
      "Early stopping, best iteration is:\n",
      "[1198]\ttraining's multi_logloss: 0.789784\ttraining's quad_kappa: 0.632322\tvalid_1's multi_logloss: 1.00483\tvalid_1's quad_kappa: 0.526518\n"
     ]
    }
   ],
   "source": [
    "baseline_model=train_baseline(train_features.drop([\"installation_id\", \"accuracy_group\"], axis=1), train_features.accuracy_group.values, \n",
    "               params=best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7fc5c904e0b8>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model.save_model(str(MODELS_DIR / \"game_baseline.lgb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>time</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>cv_scores</th>\n",
       "      <th>notebook_path</th>\n",
       "      <th>submission_path</th>\n",
       "      <th>submission_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game baseline</td>\n",
       "      <td>2019-10-30 01:43:03.755180+04:00</td>\n",
       "      <td>0.515705</td>\n",
       "      <td>[0.5472283470243167, 0.4797202169826231, 0.478...</td>\n",
       "      <td>notebooks/Game baseline.ipynb</td>\n",
       "      <td>notebooks/submissions/Game baseline submission...</td>\n",
       "      <td>0.445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name                              time  mean_score  \\\n",
       "0  Game baseline  2019-10-30 01:43:03.755180+04:00    0.515705   \n",
       "\n",
       "                                           cv_scores  \\\n",
       "0  [0.5472283470243167, 0.4797202169826231, 0.478...   \n",
       "\n",
       "                   notebook_path  \\\n",
       "0  notebooks/Game baseline.ipynb   \n",
       "\n",
       "                                     submission_path  submission_score  \n",
       "0  notebooks/submissions/Game baseline submission...             0.445  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_score, cv_scores = (0.5157051296362365,\n",
    " [0.5472283470243167,\n",
    "  0.4797202169826231,\n",
    "  0.47854404188486,\n",
    "  0.5041272227182371,\n",
    "  0.5055032393246791,\n",
    "  0.5232401248520073,\n",
    "  0.5510630168932551,\n",
    "  0.5215215852330887,\n",
    "  0.5147618813899562,\n",
    "  0.531341620059342])\n",
    "name = \"Game baseline\"\n",
    "notebook_path=\"notebooks/Game baseline.ipynb\"\n",
    "submission_path=\"notebooks/submissions/Game baseline submission.ipynb\"\n",
    "track_experiment(name, mean_score, cv_scores, notebook_path)\n",
    "track_submission_info(name, submission_path, 0.445)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
