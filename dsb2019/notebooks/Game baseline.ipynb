{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from target_encoding import TargetEncoderClassifier, TargetEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from functools import reduce\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import json\n",
    "from functools import partial\n",
    "\n",
    "from dsb2019.data.validation import InstallationFold, cross_validate, quad_kappa\n",
    "from dsb2019.visualization import session_browser\n",
    "from dsb2019.data import DATA_DIR\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "pd.options.display.max_rows=999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_DIR / 'raw/train.csv')\n",
    "test = pd.read_csv(DATA_DIR / 'raw/test.csv')\n",
    "train_labels = pd.read_csv(DATA_DIR / 'raw/train_labels.csv')\n",
    "submission = pd.read_csv(DATA_DIR / 'raw/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = ['Scrub-A-Dub', 'All Star Sorting', 'Mushroom Sorter (Assessment)',\n",
    "       'Air Show', 'Crystals Rule', 'Bird Measurer (Assessment)',\n",
    "       'Dino Drink', 'Bubble Bath', 'Dino Dive', 'Chow Time',\n",
    "       'Cauldron Filler (Assessment)', 'Pan Balance', 'Happy Camel',\n",
    "       'Cart Balancer (Assessment)', 'Chest Sorter (Assessment)',\n",
    "       'Leaf Leader']\n",
    "\n",
    "\n",
    "def unwrap_event_data(df):\n",
    "    unwrapped=pd.DataFrame(data=list(df.event_data.apply(json.loads).values))\n",
    "    return pd.concat([unwrapped.reset_index(),df.reset_index()],axis=1)\n",
    "\n",
    "\n",
    "def process_installations(train_labels, train, process_log):\n",
    "    result = []\n",
    "    train=train.sort_values(\"timestamp\")\n",
    "    installations = train.groupby(\"installation_id\")\n",
    "    for i, game_session, title, installation_id, accuracy_group in tqdm(train_labels[[\"game_session\", \"title\", \"installation_id\", \"accuracy_group\"]].itertuples(), \n",
    "                                                              total=len(train_labels)):\n",
    "        player_log = installations.get_group(installation_id).reset_index()\n",
    "        log_length = player_log[(player_log.game_session==game_session) & (player_log.title==title)].index[0]\n",
    "        player_log = player_log.iloc[:(log_length + 1)]\n",
    "        player_log[\"accuracy_group\"] = accuracy_group\n",
    "        player_log[\"target_game_session\"] = game_session\n",
    "        features = process_log(player_log)\n",
    "        features[\"installation_id\"] = installation_id\n",
    "        features[\"accuracy_group\"] = accuracy_group\n",
    "        result.append(features)\n",
    "    return pd.DataFrame(data=result)\n",
    " \n",
    "    \n",
    "def process_log(df):\n",
    "    assessment_title=df.title.iloc[-1]    \n",
    "\n",
    "    history = df.iloc[:-1]\n",
    "    history = history[history.type.isin([\"Game\", \"Assessment\"])].copy()\n",
    "\n",
    "    def calculate_ratios(df):\n",
    "        n_correct=df.correct_move.sum()\n",
    "        n_incorrect=df.wrong_move.sum()\n",
    "        ratio=n_correct/(n_correct+n_incorrect)\n",
    "        return n_correct, n_incorrect, ratio\n",
    "    \n",
    "    def make_move_stats(df, title,n_lags=2):\n",
    "        df=df.copy()\n",
    "        if len(df):\n",
    "            df = unwrap_event_data(df)\n",
    "        if \"correct\" in df.columns:\n",
    "            df[\"correct_move\"] = df.correct == True\n",
    "            df[\"wrong_move\"] = df.correct == False\n",
    "        else:\n",
    "            df[\"correct_move\"]=False\n",
    "            df[\"wrong_move\"]=False\n",
    "        result = []\n",
    "        result.extend(zip([f\"n_correct {title}\", f\"n_incorrect {title}\", f\"global_ratio {title}\"], calculate_ratios(df)))\n",
    "        if n_lags:\n",
    "            last_sessions = df.game_session.unique()[-n_lags:]\n",
    "            for i in range(n_lags):\n",
    "                if i < len(last_sessions): \n",
    "                    result.extend(zip([f\"n_correct {title} {i}\", f\"n_incorrect {title} {i}\",f\"ratio {title} {i}\"], \n",
    "                                      calculate_ratios(df[df.game_session==last_sessions[i]])))\n",
    "                else:\n",
    "                    result.extend(zip([f\"n_correct {title} {i}\", f\"n_incorrect {title} {i}\",f\"ratio {title} {i}\"], [None, None, None]))\n",
    "        return {k: v for k, v in result}\n",
    "    result = {\"title\": games.index(assessment_title)}\n",
    "    for game in games:\n",
    "        stats=history[history.title==game]\n",
    "        stats=make_move_stats(stats, game)\n",
    "        result.update(stats)\n",
    "    return result\n",
    "\n",
    "\n",
    "#train_features = process_installations(train_labels, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.to_csv(DATA_DIR / \"interim/train_features_game_counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features=train_features.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'n_correct Scrub-A-Dub', 'n_incorrect Scrub-A-Dub',\n",
       "       'global_ratio Scrub-A-Dub', 'n_correct Scrub-A-Dub 0',\n",
       "       'n_incorrect Scrub-A-Dub 0', 'ratio Scrub-A-Dub 0',\n",
       "       'n_correct Scrub-A-Dub 1', 'n_incorrect Scrub-A-Dub 1',\n",
       "       'ratio Scrub-A-Dub 1',\n",
       "       ...\n",
       "       'n_incorrect Leaf Leader', 'global_ratio Leaf Leader',\n",
       "       'n_correct Leaf Leader 0', 'n_incorrect Leaf Leader 0',\n",
       "       'ratio Leaf Leader 0', 'n_correct Leaf Leader 1',\n",
       "       'n_incorrect Leaf Leader 1', 'ratio Leaf Leader 1', 'installation_id',\n",
       "       'accuracy_group'],\n",
       "      dtype='object', length=147)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_baseline(x_train,y_train):\n",
    "    x_train_all, x_val_all,y_train_all,y_val_all = train_test_split(\n",
    "        x_train,y_train,\n",
    "        test_size=0.15,\n",
    "        random_state=2019,\n",
    "    )\n",
    "    train_set = lgb.Dataset(x_train_all, y_train_all)\n",
    "    val_set = lgb.Dataset(x_val_all, y_val_all)\n",
    "\n",
    "    params = {\n",
    "        'learning_rate': 0.01,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'feature_fraction': 0.9,\n",
    "        'num_leaves': 14,\n",
    "        'lambda_l1': 0.1,\n",
    "        'lambda_l2': 1,\n",
    "        'metric': 'multiclass',\n",
    "        'objective': 'multiclass',\n",
    "        'num_classes': 4,\n",
    "        'random_state': 2019\n",
    "    }\n",
    "\n",
    "    return lgb.train(params, train_set, num_boost_round=10000, early_stopping_rounds=300, valid_sets=[train_set, val_set], verbose_eval=100)\n",
    "\n",
    "\n",
    "def make_features_wrapper(train, test):\n",
    "    def make_features(df):\n",
    "        return df.drop([\"installation_id\", \"accuracy_group\"], axis=1), df.accuracy_group.values\n",
    "    \n",
    "    return make_features(train), make_features(test) \n",
    "\n",
    "\n",
    "def make_predictions(model,x_test_all,y_test):\n",
    "    pred=model.predict(x_test_all).argmax(axis=1)\n",
    "    return pred,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.07328\tvalid_1's multi_logloss: 1.07759\n",
      "[200]\ttraining's multi_logloss: 1.01715\tvalid_1's multi_logloss: 1.03323\n",
      "[300]\ttraining's multi_logloss: 0.984614\tvalid_1's multi_logloss: 1.01267\n",
      "[400]\ttraining's multi_logloss: 0.96036\tvalid_1's multi_logloss: 1.00071\n",
      "[500]\ttraining's multi_logloss: 0.941326\tvalid_1's multi_logloss: 0.992596\n",
      "[600]\ttraining's multi_logloss: 0.925133\tvalid_1's multi_logloss: 0.987378\n",
      "[700]\ttraining's multi_logloss: 0.911415\tvalid_1's multi_logloss: 0.983922\n",
      "[800]\ttraining's multi_logloss: 0.898807\tvalid_1's multi_logloss: 0.981824\n",
      "[900]\ttraining's multi_logloss: 0.887318\tvalid_1's multi_logloss: 0.980442\n",
      "[1000]\ttraining's multi_logloss: 0.876624\tvalid_1's multi_logloss: 0.979759\n",
      "[1100]\ttraining's multi_logloss: 0.866517\tvalid_1's multi_logloss: 0.979412\n",
      "[1200]\ttraining's multi_logloss: 0.856904\tvalid_1's multi_logloss: 0.979122\n",
      "[1300]\ttraining's multi_logloss: 0.847715\tvalid_1's multi_logloss: 0.97909\n",
      "[1400]\ttraining's multi_logloss: 0.83887\tvalid_1's multi_logloss: 0.97901\n",
      "[1500]\ttraining's multi_logloss: 0.83025\tvalid_1's multi_logloss: 0.97896\n",
      "[1600]\ttraining's multi_logloss: 0.821988\tvalid_1's multi_logloss: 0.979189\n",
      "[1700]\ttraining's multi_logloss: 0.814059\tvalid_1's multi_logloss: 0.979535\n",
      "Early stopping, best iteration is:\n",
      "[1439]\ttraining's multi_logloss: 0.835437\tvalid_1's multi_logloss: 0.978891\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.06932\tvalid_1's multi_logloss: 1.10294\n",
      "[200]\ttraining's multi_logloss: 1.0113\tvalid_1's multi_logloss: 1.05476\n",
      "[300]\ttraining's multi_logloss: 0.978526\tvalid_1's multi_logloss: 1.03462\n",
      "[400]\ttraining's multi_logloss: 0.954979\tvalid_1's multi_logloss: 1.0227\n",
      "[500]\ttraining's multi_logloss: 0.935756\tvalid_1's multi_logloss: 1.01439\n",
      "[600]\ttraining's multi_logloss: 0.919501\tvalid_1's multi_logloss: 1.00875\n",
      "[700]\ttraining's multi_logloss: 0.905189\tvalid_1's multi_logloss: 1.00557\n",
      "[800]\ttraining's multi_logloss: 0.892816\tvalid_1's multi_logloss: 1.00394\n",
      "[900]\ttraining's multi_logloss: 0.881538\tvalid_1's multi_logloss: 1.00281\n",
      "[1000]\ttraining's multi_logloss: 0.871119\tvalid_1's multi_logloss: 1.00165\n",
      "[1100]\ttraining's multi_logloss: 0.860906\tvalid_1's multi_logloss: 1.00053\n",
      "[1200]\ttraining's multi_logloss: 0.851421\tvalid_1's multi_logloss: 0.999679\n",
      "[1300]\ttraining's multi_logloss: 0.8422\tvalid_1's multi_logloss: 0.999007\n",
      "[1400]\ttraining's multi_logloss: 0.833055\tvalid_1's multi_logloss: 0.997913\n",
      "[1500]\ttraining's multi_logloss: 0.824378\tvalid_1's multi_logloss: 0.99724\n",
      "[1600]\ttraining's multi_logloss: 0.816194\tvalid_1's multi_logloss: 0.997121\n",
      "[1700]\ttraining's multi_logloss: 0.808469\tvalid_1's multi_logloss: 0.997346\n",
      "[1800]\ttraining's multi_logloss: 0.800856\tvalid_1's multi_logloss: 0.997872\n",
      "[1900]\ttraining's multi_logloss: 0.793161\tvalid_1's multi_logloss: 0.998365\n",
      "Early stopping, best iteration is:\n",
      "[1652]\ttraining's multi_logloss: 0.812108\tvalid_1's multi_logloss: 0.997084\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.06902\tvalid_1's multi_logloss: 1.08315\n",
      "[200]\ttraining's multi_logloss: 1.01018\tvalid_1's multi_logloss: 1.03649\n",
      "[300]\ttraining's multi_logloss: 0.975932\tvalid_1's multi_logloss: 1.01508\n",
      "[400]\ttraining's multi_logloss: 0.951862\tvalid_1's multi_logloss: 1.00365\n",
      "[500]\ttraining's multi_logloss: 0.932292\tvalid_1's multi_logloss: 0.996146\n",
      "[600]\ttraining's multi_logloss: 0.915908\tvalid_1's multi_logloss: 0.991547\n",
      "[700]\ttraining's multi_logloss: 0.901665\tvalid_1's multi_logloss: 0.988317\n",
      "[800]\ttraining's multi_logloss: 0.889073\tvalid_1's multi_logloss: 0.986108\n",
      "[900]\ttraining's multi_logloss: 0.877555\tvalid_1's multi_logloss: 0.98464\n",
      "[1000]\ttraining's multi_logloss: 0.867342\tvalid_1's multi_logloss: 0.983376\n",
      "[1100]\ttraining's multi_logloss: 0.857589\tvalid_1's multi_logloss: 0.982404\n",
      "[1200]\ttraining's multi_logloss: 0.848022\tvalid_1's multi_logloss: 0.981397\n",
      "[1300]\ttraining's multi_logloss: 0.838842\tvalid_1's multi_logloss: 0.980229\n",
      "[1400]\ttraining's multi_logloss: 0.830185\tvalid_1's multi_logloss: 0.979169\n",
      "[1500]\ttraining's multi_logloss: 0.821768\tvalid_1's multi_logloss: 0.978632\n",
      "[1600]\ttraining's multi_logloss: 0.813807\tvalid_1's multi_logloss: 0.978095\n",
      "[1700]\ttraining's multi_logloss: 0.806102\tvalid_1's multi_logloss: 0.977874\n",
      "[1800]\ttraining's multi_logloss: 0.798736\tvalid_1's multi_logloss: 0.977729\n",
      "[1900]\ttraining's multi_logloss: 0.79147\tvalid_1's multi_logloss: 0.977815\n",
      "[2000]\ttraining's multi_logloss: 0.784346\tvalid_1's multi_logloss: 0.977674\n",
      "[2100]\ttraining's multi_logloss: 0.777469\tvalid_1's multi_logloss: 0.977891\n",
      "[2200]\ttraining's multi_logloss: 0.770788\tvalid_1's multi_logloss: 0.97828\n",
      "Early stopping, best iteration is:\n",
      "[1960]\ttraining's multi_logloss: 0.78713\tvalid_1's multi_logloss: 0.977528\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.07189\tvalid_1's multi_logloss: 1.08454\n",
      "[200]\ttraining's multi_logloss: 1.01417\tvalid_1's multi_logloss: 1.03954\n",
      "[300]\ttraining's multi_logloss: 0.981921\tvalid_1's multi_logloss: 1.01933\n",
      "[400]\ttraining's multi_logloss: 0.958461\tvalid_1's multi_logloss: 1.00686\n",
      "[500]\ttraining's multi_logloss: 0.939064\tvalid_1's multi_logloss: 0.998199\n",
      "[600]\ttraining's multi_logloss: 0.922703\tvalid_1's multi_logloss: 0.992505\n",
      "[700]\ttraining's multi_logloss: 0.908359\tvalid_1's multi_logloss: 0.988126\n",
      "[800]\ttraining's multi_logloss: 0.895838\tvalid_1's multi_logloss: 0.985542\n",
      "[900]\ttraining's multi_logloss: 0.88426\tvalid_1's multi_logloss: 0.983306\n",
      "[1000]\ttraining's multi_logloss: 0.873773\tvalid_1's multi_logloss: 0.981828\n",
      "[1100]\ttraining's multi_logloss: 0.863606\tvalid_1's multi_logloss: 0.980869\n",
      "[1200]\ttraining's multi_logloss: 0.853977\tvalid_1's multi_logloss: 0.979937\n",
      "[1300]\ttraining's multi_logloss: 0.844927\tvalid_1's multi_logloss: 0.97936\n",
      "[1400]\ttraining's multi_logloss: 0.836485\tvalid_1's multi_logloss: 0.978803\n",
      "[1500]\ttraining's multi_logloss: 0.828105\tvalid_1's multi_logloss: 0.978386\n",
      "[1600]\ttraining's multi_logloss: 0.820056\tvalid_1's multi_logloss: 0.978296\n",
      "[1700]\ttraining's multi_logloss: 0.812274\tvalid_1's multi_logloss: 0.977961\n",
      "[1800]\ttraining's multi_logloss: 0.804795\tvalid_1's multi_logloss: 0.977975\n",
      "[1900]\ttraining's multi_logloss: 0.797549\tvalid_1's multi_logloss: 0.977897\n",
      "[2000]\ttraining's multi_logloss: 0.79037\tvalid_1's multi_logloss: 0.978083\n",
      "[2100]\ttraining's multi_logloss: 0.78333\tvalid_1's multi_logloss: 0.978019\n",
      "Early stopping, best iteration is:\n",
      "[1834]\ttraining's multi_logloss: 0.802252\tvalid_1's multi_logloss: 0.977884\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.07148\tvalid_1's multi_logloss: 1.09532\n",
      "[200]\ttraining's multi_logloss: 1.01253\tvalid_1's multi_logloss: 1.05309\n",
      "[300]\ttraining's multi_logloss: 0.979038\tvalid_1's multi_logloss: 1.03416\n",
      "[400]\ttraining's multi_logloss: 0.954742\tvalid_1's multi_logloss: 1.02279\n",
      "[500]\ttraining's multi_logloss: 0.935545\tvalid_1's multi_logloss: 1.0159\n",
      "[600]\ttraining's multi_logloss: 0.919342\tvalid_1's multi_logloss: 1.01128\n",
      "[700]\ttraining's multi_logloss: 0.905407\tvalid_1's multi_logloss: 1.00776\n",
      "[800]\ttraining's multi_logloss: 0.892945\tvalid_1's multi_logloss: 1.00521\n",
      "[900]\ttraining's multi_logloss: 0.881479\tvalid_1's multi_logloss: 1.00338\n",
      "[1000]\ttraining's multi_logloss: 0.870758\tvalid_1's multi_logloss: 1.00228\n",
      "[1100]\ttraining's multi_logloss: 0.860679\tvalid_1's multi_logloss: 1.00167\n",
      "[1200]\ttraining's multi_logloss: 0.85105\tvalid_1's multi_logloss: 1.00118\n",
      "[1300]\ttraining's multi_logloss: 0.841713\tvalid_1's multi_logloss: 1.00014\n",
      "[1400]\ttraining's multi_logloss: 0.832825\tvalid_1's multi_logloss: 0.999194\n",
      "[1500]\ttraining's multi_logloss: 0.824154\tvalid_1's multi_logloss: 0.998787\n",
      "[1600]\ttraining's multi_logloss: 0.81584\tvalid_1's multi_logloss: 0.998578\n",
      "[1700]\ttraining's multi_logloss: 0.807869\tvalid_1's multi_logloss: 0.99824\n",
      "[1800]\ttraining's multi_logloss: 0.800205\tvalid_1's multi_logloss: 0.998604\n",
      "[1900]\ttraining's multi_logloss: 0.792763\tvalid_1's multi_logloss: 0.999088\n",
      "Early stopping, best iteration is:\n",
      "[1690]\ttraining's multi_logloss: 0.808661\tvalid_1's multi_logloss: 0.998187\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.07167\tvalid_1's multi_logloss: 1.09987\n",
      "[200]\ttraining's multi_logloss: 1.01368\tvalid_1's multi_logloss: 1.05525\n",
      "[300]\ttraining's multi_logloss: 0.980709\tvalid_1's multi_logloss: 1.03626\n",
      "[400]\ttraining's multi_logloss: 0.956592\tvalid_1's multi_logloss: 1.02599\n",
      "[500]\ttraining's multi_logloss: 0.937374\tvalid_1's multi_logloss: 1.01954\n",
      "[600]\ttraining's multi_logloss: 0.921329\tvalid_1's multi_logloss: 1.01546\n",
      "[700]\ttraining's multi_logloss: 0.907272\tvalid_1's multi_logloss: 1.01267\n",
      "[800]\ttraining's multi_logloss: 0.894821\tvalid_1's multi_logloss: 1.01114\n",
      "[900]\ttraining's multi_logloss: 0.883537\tvalid_1's multi_logloss: 1.01046\n",
      "[1000]\ttraining's multi_logloss: 0.873103\tvalid_1's multi_logloss: 1.01017\n",
      "[1100]\ttraining's multi_logloss: 0.863341\tvalid_1's multi_logloss: 1.00994\n",
      "[1200]\ttraining's multi_logloss: 0.85376\tvalid_1's multi_logloss: 1.00983\n",
      "[1300]\ttraining's multi_logloss: 0.844605\tvalid_1's multi_logloss: 1.00969\n",
      "[1400]\ttraining's multi_logloss: 0.835811\tvalid_1's multi_logloss: 1.00956\n",
      "[1500]\ttraining's multi_logloss: 0.827399\tvalid_1's multi_logloss: 1.00952\n",
      "[1600]\ttraining's multi_logloss: 0.819073\tvalid_1's multi_logloss: 1.00962\n",
      "[1700]\ttraining's multi_logloss: 0.811029\tvalid_1's multi_logloss: 1.00998\n",
      "[1800]\ttraining's multi_logloss: 0.803418\tvalid_1's multi_logloss: 1.01017\n",
      "Early stopping, best iteration is:\n",
      "[1508]\ttraining's multi_logloss: 0.826742\tvalid_1's multi_logloss: 1.00946\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.07489\tvalid_1's multi_logloss: 1.09055\n",
      "[200]\ttraining's multi_logloss: 1.01702\tvalid_1's multi_logloss: 1.04641\n",
      "[300]\ttraining's multi_logloss: 0.983885\tvalid_1's multi_logloss: 1.02606\n",
      "[400]\ttraining's multi_logloss: 0.959481\tvalid_1's multi_logloss: 1.01397\n",
      "[500]\ttraining's multi_logloss: 0.940005\tvalid_1's multi_logloss: 1.00566\n",
      "[600]\ttraining's multi_logloss: 0.923888\tvalid_1's multi_logloss: 1.0004\n",
      "[700]\ttraining's multi_logloss: 0.909921\tvalid_1's multi_logloss: 0.997009\n",
      "[800]\ttraining's multi_logloss: 0.897336\tvalid_1's multi_logloss: 0.994774\n",
      "[900]\ttraining's multi_logloss: 0.885911\tvalid_1's multi_logloss: 0.993468\n",
      "[1000]\ttraining's multi_logloss: 0.875305\tvalid_1's multi_logloss: 0.992662\n",
      "[1100]\ttraining's multi_logloss: 0.865495\tvalid_1's multi_logloss: 0.992024\n",
      "[1200]\ttraining's multi_logloss: 0.85582\tvalid_1's multi_logloss: 0.991241\n",
      "[1300]\ttraining's multi_logloss: 0.846656\tvalid_1's multi_logloss: 0.990909\n",
      "[1400]\ttraining's multi_logloss: 0.837724\tvalid_1's multi_logloss: 0.99043\n",
      "[1500]\ttraining's multi_logloss: 0.829302\tvalid_1's multi_logloss: 0.990287\n",
      "[1600]\ttraining's multi_logloss: 0.821148\tvalid_1's multi_logloss: 0.99039\n",
      "[1700]\ttraining's multi_logloss: 0.81342\tvalid_1's multi_logloss: 0.990518\n",
      "Early stopping, best iteration is:\n",
      "[1479]\ttraining's multi_logloss: 0.831048\tvalid_1's multi_logloss: 0.990196\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.0713\tvalid_1's multi_logloss: 1.07711\n",
      "[200]\ttraining's multi_logloss: 1.01257\tvalid_1's multi_logloss: 1.03606\n",
      "[300]\ttraining's multi_logloss: 0.979202\tvalid_1's multi_logloss: 1.01866\n",
      "[400]\ttraining's multi_logloss: 0.954781\tvalid_1's multi_logloss: 1.00789\n",
      "[500]\ttraining's multi_logloss: 0.935305\tvalid_1's multi_logloss: 1.00124\n",
      "[600]\ttraining's multi_logloss: 0.919358\tvalid_1's multi_logloss: 0.997258\n",
      "[700]\ttraining's multi_logloss: 0.905522\tvalid_1's multi_logloss: 0.99496\n",
      "[800]\ttraining's multi_logloss: 0.893242\tvalid_1's multi_logloss: 0.99322\n",
      "[900]\ttraining's multi_logloss: 0.882145\tvalid_1's multi_logloss: 0.992318\n",
      "[1000]\ttraining's multi_logloss: 0.871805\tvalid_1's multi_logloss: 0.991657\n",
      "[1100]\ttraining's multi_logloss: 0.86186\tvalid_1's multi_logloss: 0.991477\n",
      "[1200]\ttraining's multi_logloss: 0.85249\tvalid_1's multi_logloss: 0.991536\n",
      "[1300]\ttraining's multi_logloss: 0.84351\tvalid_1's multi_logloss: 0.991602\n",
      "[1400]\ttraining's multi_logloss: 0.834989\tvalid_1's multi_logloss: 0.991804\n",
      "Early stopping, best iteration is:\n",
      "[1126]\ttraining's multi_logloss: 0.859334\tvalid_1's multi_logloss: 0.991351\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.08004\tvalid_1's multi_logloss: 1.07027\n",
      "[200]\ttraining's multi_logloss: 1.02218\tvalid_1's multi_logloss: 1.02336\n",
      "[300]\ttraining's multi_logloss: 0.98935\tvalid_1's multi_logloss: 1.00247\n",
      "[400]\ttraining's multi_logloss: 0.965559\tvalid_1's multi_logloss: 0.99198\n",
      "[500]\ttraining's multi_logloss: 0.946249\tvalid_1's multi_logloss: 0.983708\n",
      "[600]\ttraining's multi_logloss: 0.9299\tvalid_1's multi_logloss: 0.978399\n",
      "[700]\ttraining's multi_logloss: 0.915961\tvalid_1's multi_logloss: 0.975015\n",
      "[800]\ttraining's multi_logloss: 0.903566\tvalid_1's multi_logloss: 0.972849\n",
      "[900]\ttraining's multi_logloss: 0.892015\tvalid_1's multi_logloss: 0.971226\n",
      "[1000]\ttraining's multi_logloss: 0.881085\tvalid_1's multi_logloss: 0.96959\n",
      "[1100]\ttraining's multi_logloss: 0.870903\tvalid_1's multi_logloss: 0.968767\n",
      "[1200]\ttraining's multi_logloss: 0.861222\tvalid_1's multi_logloss: 0.967879\n",
      "[1300]\ttraining's multi_logloss: 0.852093\tvalid_1's multi_logloss: 0.96739\n",
      "[1400]\ttraining's multi_logloss: 0.843339\tvalid_1's multi_logloss: 0.967011\n",
      "[1500]\ttraining's multi_logloss: 0.834934\tvalid_1's multi_logloss: 0.966985\n",
      "[1600]\ttraining's multi_logloss: 0.826937\tvalid_1's multi_logloss: 0.96684\n",
      "[1700]\ttraining's multi_logloss: 0.819002\tvalid_1's multi_logloss: 0.967043\n",
      "[1800]\ttraining's multi_logloss: 0.811479\tvalid_1's multi_logloss: 0.967442\n",
      "[1900]\ttraining's multi_logloss: 0.804229\tvalid_1's multi_logloss: 0.967871\n",
      "Early stopping, best iteration is:\n",
      "[1611]\ttraining's multi_logloss: 0.826031\tvalid_1's multi_logloss: 0.966781\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's multi_logloss: 1.07221\tvalid_1's multi_logloss: 1.08889\n",
      "[200]\ttraining's multi_logloss: 1.01378\tvalid_1's multi_logloss: 1.04399\n",
      "[300]\ttraining's multi_logloss: 0.980207\tvalid_1's multi_logloss: 1.02546\n",
      "[400]\ttraining's multi_logloss: 0.955771\tvalid_1's multi_logloss: 1.01482\n",
      "[500]\ttraining's multi_logloss: 0.9364\tvalid_1's multi_logloss: 1.00709\n",
      "[600]\ttraining's multi_logloss: 0.920112\tvalid_1's multi_logloss: 1.00215\n",
      "[700]\ttraining's multi_logloss: 0.90599\tvalid_1's multi_logloss: 0.999285\n",
      "[800]\ttraining's multi_logloss: 0.893351\tvalid_1's multi_logloss: 0.997108\n",
      "[900]\ttraining's multi_logloss: 0.881906\tvalid_1's multi_logloss: 0.996074\n",
      "[1000]\ttraining's multi_logloss: 0.871288\tvalid_1's multi_logloss: 0.995467\n",
      "[1100]\ttraining's multi_logloss: 0.861309\tvalid_1's multi_logloss: 0.995003\n",
      "[1200]\ttraining's multi_logloss: 0.851779\tvalid_1's multi_logloss: 0.994686\n",
      "[1300]\ttraining's multi_logloss: 0.84281\tvalid_1's multi_logloss: 0.994298\n",
      "[1400]\ttraining's multi_logloss: 0.834013\tvalid_1's multi_logloss: 0.994308\n",
      "[1500]\ttraining's multi_logloss: 0.825492\tvalid_1's multi_logloss: 0.994343\n",
      "[1600]\ttraining's multi_logloss: 0.817328\tvalid_1's multi_logloss: 0.995141\n",
      "Early stopping, best iteration is:\n",
      "[1352]\ttraining's multi_logloss: 0.838261\tvalid_1's multi_logloss: 0.994202\n"
     ]
    }
   ],
   "source": [
    "predictions = cross_validate(train_features, train_features.accuracy_group, make_features_wrapper, train_baseline, make_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5157051296362365,\n",
       " [0.5472283470243167,\n",
       "  0.4797202169826231,\n",
       "  0.47854404188486,\n",
       "  0.5041272227182371,\n",
       "  0.5055032393246791,\n",
       "  0.5232401248520073,\n",
       "  0.5510630168932551,\n",
       "  0.5215215852330887,\n",
       "  0.5147618813899562,\n",
       "  0.531341620059342])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([quad_kappa(true, pred) for pred, true in predictions]), [quad_kappa(true, pred) for pred, true in predictions]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
