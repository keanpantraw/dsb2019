{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from target_encoding import TargetEncoderClassifier, TargetEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from functools import reduce\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import json\n",
    "from functools import partial\n",
    "from dsb2019.models.coeff import ThresholdClassifier\n",
    "\n",
    "from dsb2019.models.tracking import track_experiment, track_submission_info\n",
    "from dsb2019.data.validation import InstallationFold, cross_validate, quad_kappa\n",
    "from dsb2019.visualization import session_browser\n",
    "from dsb2019.data import DATA_DIR\n",
    "from dsb2019.models import MODELS_DIR\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, Trials, tpe, STATUS_OK\n",
    "tqdm.pandas()\n",
    "pd.options.display.max_rows=999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-83f87fcd448c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'raw/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'raw/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'raw/train_labels.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'raw/sample_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m     \"\"\"\n\u001b[1;32m    680\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(DATA_DIR / 'raw/train.csv')\n",
    "test = pd.read_csv(DATA_DIR / 'raw/test.csv')\n",
    "train_labels = pd.read_csv(DATA_DIR / 'raw/train_labels.csv')\n",
    "submission = pd.read_csv(DATA_DIR / 'raw/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = ['Scrub-A-Dub', 'All Star Sorting', 'Mushroom Sorter (Assessment)',\n",
    "       'Air Show', 'Crystals Rule', 'Bird Measurer (Assessment)',\n",
    "       'Dino Drink', 'Bubble Bath', 'Dino Dive', 'Chow Time',\n",
    "       'Cauldron Filler (Assessment)', 'Pan Balance', 'Happy Camel',\n",
    "       'Cart Balancer (Assessment)', 'Chest Sorter (Assessment)',\n",
    "       'Leaf Leader']\n",
    "worlds = ['NONE', 'MAGMAPEAK', 'TREETOPCITY', 'CRYSTALCAVES']\n",
    "\n",
    "def unwrap_event_data(df):\n",
    "    unwrapped=pd.DataFrame(data=list(df.event_data.apply(json.loads).values))\n",
    "    return pd.concat([unwrapped.reset_index(),df.reset_index()],axis=1)\n",
    "\n",
    "\n",
    "def process_installations(train_labels, train, process_log):\n",
    "    result = []\n",
    "    train=train.sort_values(\"timestamp\")\n",
    "    installations = train.groupby(\"installation_id\")\n",
    "    for i, game_session, title, installation_id, accuracy_group in tqdm(train_labels[[\"game_session\", \"title\", \"installation_id\", \"accuracy_group\"]].itertuples(), \n",
    "                                                              total=len(train_labels)):\n",
    "        player_log = installations.get_group(installation_id).reset_index()\n",
    "        log_length = player_log[(player_log.game_session==game_session) & (player_log.title==title)].index[0]\n",
    "        player_log = player_log.iloc[:(log_length + 1)]\n",
    "        player_log[\"accuracy_group\"] = accuracy_group\n",
    "        player_log[\"target_game_session\"] = game_session\n",
    "        features = process_log(player_log)\n",
    "        features[\"installation_id\"] = installation_id\n",
    "        features[\"accuracy_group\"] = accuracy_group\n",
    "        result.append(features)\n",
    "    return pd.DataFrame(data=result)\n",
    " \n",
    "    \n",
    "def process_log(df):\n",
    "    assessment_title=df.title.iloc[-1]   \n",
    "    world=df.world.iloc[-1]\n",
    "\n",
    "    history = df.iloc[:-1]\n",
    "    history = history[history.type.isin([\"Game\", \"Assessment\"])].copy()\n",
    "\n",
    "    def calculate_ratios(df):\n",
    "        n_correct=df.correct_move.sum()\n",
    "        n_incorrect=df.wrong_move.sum()\n",
    "        ratio=n_correct/(n_correct+n_incorrect)\n",
    "        return n_correct, n_incorrect, ratio\n",
    "    \n",
    "    def make_move_stats(df, title,n_lags=2):\n",
    "        df=df.copy()\n",
    "        if len(df):\n",
    "            df = unwrap_event_data(df)\n",
    "        if \"correct\" in df.columns:\n",
    "            df[\"correct_move\"] = df.correct == True\n",
    "            df[\"wrong_move\"] = df.correct == False\n",
    "        else:\n",
    "            df[\"correct_move\"]=False\n",
    "            df[\"wrong_move\"]=False\n",
    "        result = []\n",
    "        result.extend(zip([f\"n_correct_{title}\", f\"n_incorrect_{title}\", f\"global_ratio_{title}\"], calculate_ratios(df)))\n",
    "        result.append((\"mean_n_rounds\", df.groupby(\"game_session\").round.max().mean()))\n",
    "        result.append((\"max_n_rounds\", df.round.max()))\n",
    "\n",
    "        last_sessions = df[[\"game_session\", \"timestamp\"]].sort_values(\"timestamp\").game_session.unique()[-n_lags:]\n",
    "        if n_lags:\n",
    "            for i in range(n_lags):\n",
    "                if i < len(last_sessions): \n",
    "                    result.extend(zip([f\"n_correct_{title}_{i}\", f\"n_incorrect_{title} {i}\",f\"ratio_{title}_{i}\"], \n",
    "                                      calculate_ratios(df[df.game_session==last_sessions[i]])))\n",
    "                else:\n",
    "                    result.extend(zip([f\"n_correct_{title}_{i}\", f\"n_incorrect_{title}_{i}\",f\"ratio_{title}_{i}\"], [None, None, None]))\n",
    "                result.append((f\"n_rounds_{title}_{i}\", df[df.game_session==last_sessions[i]].round.max()))\n",
    "        last_round=df[df.game_session==last_sessions[-1]]\n",
    "        result.extend(zip([f\"last_round_n_correct_{title}\", \n",
    "                           f\"last_round_n_incorrect_{title}\", \n",
    "                           f\"last_round_global_ratio_{title}\"], calculate_ratios(last_round[last_round.round.max()==last_round.round])))\n",
    "        return {k: v for k, v in result}\n",
    "    \n",
    "    \n",
    "    result = {\"title\": games.index(assessment_title),\n",
    "              \"world\": worlds.index(world),\n",
    "              \"n_activities\": df[df.type==\"Activity\"].game_session.nunique(),\n",
    "              \"n_games\": df[df.type==\"Game\"].game_session.nunique(),\n",
    "              \"event_code_count\": df.event_code.nunique(),\n",
    "              \"event_id_count\": df.event_id.nunique(),\n",
    "              \"title_count\": df.title.nunique(),\n",
    "              \"session_id_count\": df.game_session.nunique(),\n",
    "              \"n_actions\": len(df),\n",
    "              \"world_title_count\": df[df.world==world].title.nunique(),\n",
    "             }\n",
    "    for game in games:\n",
    "        stats=history[history.title==game]\n",
    "        stats_features=make_move_stats(stats, game)\n",
    "        stats_features[f\"{game}_event_code_count\"] = stats.event_code.nunique()\n",
    "        stats_features[f\"{game}_event_id_count\"] = stats.event_id.nunique()\n",
    "        stats_features[f\"{game}_session_id_count\"] = stats.game_session.nunique()\n",
    "        stats_features[f\"{game}_n_actions\"] = len(stats)\n",
    "        result.update(stats_features)\n",
    "    world_games = history[history.world==world]\n",
    "    for game in games:\n",
    "        stats=world_games[world_games.title==game]\n",
    "        stats_features=make_move_stats(stats, game)\n",
    "        stats_features = {f\"world_{k}\": v for k, v in stats_features.items()}\n",
    "        stats_features[f\"world_{game}_event_code_count\"] = stats.event_code.nunique()\n",
    "        stats_features[f\"world_{game}_event_id_count\"] = stats.event_id.nunique()\n",
    "        stats_features[f\"world_{game}_session_id_count\"] = stats.game_session.nunique()\n",
    "        stats_features[f\"world_{game}_n_actions\"] = len(stats)\n",
    "        result.update(stats_features)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = process_installations(train_labels, train, process_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features=train_features.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_quad_kappa(preds, true):\n",
    "    true = true.get_label()\n",
    "    #preds = preds.reshape((4, -1)).argmax(axis=0)\n",
    "    preds = np.rint(preds)\n",
    "    preds = np.maximum(0, preds)\n",
    "    preds = np.minimum(3, preds)\n",
    "    return \"quad_kappa\", quad_kappa(true, preds), True\n",
    "    \n",
    "    \n",
    "def train_baseline(x_train,y_train, params=None):\n",
    "    x_train_all, x_val_all,y_train_all,y_val_all = train_test_split(\n",
    "        x_train,y_train,\n",
    "        test_size=0.15,\n",
    "        random_state=2019,\n",
    "    )\n",
    "    train_set = lgb.Dataset(x_train_all, y_train_all)\n",
    "    val_set = lgb.Dataset(x_val_all, y_val_all)\n",
    "\n",
    "#     params = {\n",
    "#         'learning_rate': 0.01,\n",
    "#         'bagging_fraction': 0.9,\n",
    "#         'feature_fraction': 0.9,\n",
    "#         'num_leaves': 14,\n",
    "#         'lambda_l1': 0.1,\n",
    "#         'lambda_l2': 1,\n",
    "#         'metric': 'multiclass',\n",
    "#         'objective': 'multiclass',\n",
    "#         'num_classes': 4,\n",
    "#         'random_state': 2019\n",
    "#     }\n",
    "\n",
    "    return lgb.train(params, train_set, num_boost_round=10000, early_stopping_rounds=2000, valid_sets=[val_set], verbose_eval=100)#,\n",
    "                    #feval=lgb_quad_kappa)\n",
    "\n",
    "def make_features(df):\n",
    "    return df.drop([\"installation_id\", \"accuracy_group\"], axis=1), df.accuracy_group.values\n",
    "\n",
    "def make_features_wrapper(train, test):\n",
    "    def make_features(df):\n",
    "        return df.drop([\"installation_id\", \"accuracy_group\"], axis=1), df.accuracy_group.values\n",
    "    \n",
    "    return make_features(train), make_features(test) \n",
    "\n",
    "\n",
    "def make_predictions(model,x_test_all,y_test):\n",
    "    preds=model.predict(x_test_all)\n",
    "    #preds = np.rint(preds)\n",
    "    #preds = np.maximum(0, preds)\n",
    "    #preds = np.minimum(3, preds)\n",
    "    return preds,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_installations(test):\n",
    "    test = test.sort_values(\"timestamp\")\n",
    "    test=test.groupby(\"installation_id\").progress_apply(process_log).reset_index()\n",
    "    test.columns = [\"installation_id\", \"features\"]\n",
    "    result = []\n",
    "    for i, installation_id, feature in test.itertuples():\n",
    "        result.append(feature)\n",
    "        feature[\"installation_id\"]=installation_id\n",
    "    return pd.DataFrame(result).fillna(-1)\n",
    "test_features=process_test_installations(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtrain_installations=pd.Series(train_features.installation_id.unique()).sample(frac=1., random_state=2019)\n",
    "subtrain_features=train_features[train_features.installation_id.isin(subtrain_installations.values)].copy()\n",
    "def check_hyperparams(params):\n",
    "    print(params)\n",
    "    if \"max_depth\" in params:\n",
    "        params[\"max_depth\"] = int(params[\"max_depth\"])\n",
    "    if \"num_leaves\" in params:\n",
    "        params[\"num_leaves\"] = int(params[\"num_leaves\"])\n",
    "\n",
    "    train_baseline_with_params = partial(train_baseline, params=params)\n",
    "    cv=InstallationFold(n_splits=3)\n",
    "    predictions = cross_validate(subtrain_features, subtrain_features.accuracy_group, make_features_wrapper, train_baseline_with_params, make_predictions,\n",
    "                                cv=cv)\n",
    "    return {\n",
    "        \"loss\": np.mean([mean_squared_error(true, pred) for pred, true in predictions]),\n",
    "        \"status\": STATUS_OK,\n",
    "        \"params\": params\n",
    "    }\n",
    "\n",
    "\n",
    "def tune(check_params, n_tries=25, n_learning_rate_tries=15, learning_rate=None, n_estimators=10_000):        \n",
    "    if learning_rate is None:\n",
    "        learning_rate_space = {\n",
    "            'learning_rate': hp.loguniform(\"learning_rate\", np.log(0.005), np.log(0.3)),\n",
    "            'metric': 'rmse',\n",
    "            'objective': 'rmse',\n",
    "            #'num_classes': 4,\n",
    "            'random_state': 2019,\n",
    "            \"n_estimators\": n_estimators,\n",
    "\n",
    "        }\n",
    "        trials = Trials()\n",
    "        result = fmin(check_params,\n",
    "                      learning_rate_space, tpe.suggest, n_learning_rate_tries, trials=trials)\n",
    "        print(result)\n",
    "        learning_rate = round(trials.best_trial[\"result\"][\"params\"][\"learning_rate\"], 3)\n",
    "\n",
    "    param_space = {\n",
    "        'metric': 'rmse',\n",
    "        'objective': 'rmse',\n",
    "        #'num_classes': 4,\n",
    "        'lambda_l1': hp.uniform(\"lamba_l1\", 1e-10, 1),\n",
    "        'lambda_l2': hp.uniform(\"lambda_l2\", 1e-10, 1),\n",
    "        'random_state': 2019,\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"max_depth\": hp.quniform(\"max_depth\", 2, 16, 1),\n",
    "        \"num_leaves\": hp.choice(\"num_leaves\", [3, 7, 15, 31, 63, 127, 255, 511, 1023, 2047, 4095]),\n",
    "        \"subsample\": hp.quniform(\"subsample\", 0.01, 1, 0.01),\n",
    "        \"feature_fraction\": hp.quniform(\"feature_fraction\", 0.01, 1, 0.01),\n",
    "    }\n",
    "\n",
    "    trials = Trials()\n",
    "    fmin(check_params,\n",
    "         param_space, tpe.suggest, n_tries, trials=trials)\n",
    "    best_params = trials.best_trial[\"result\"][\"params\"]\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params=tune(check_hyperparams, n_tries=100, n_learning_rate_tries=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was selected on 100% of the data\n",
    "\n",
    "```\n",
    "{'feature_fraction': 0.44,\n",
    " 'lambda_l1': 0.2342366019673217,\n",
    " 'lambda_l2': 0.20913848894987938,\n",
    " 'learning_rate': 0.04,\n",
    " 'max_depth': 9,\n",
    " 'metric': 'rmse',\n",
    " 'n_estimators': 10000,\n",
    " 'num_leaves': 31,\n",
    " 'objective': 'rmse',\n",
    " 'random_state': 2019,\n",
    " 'subsample': 0.86}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params={'feature_fraction': 0.58,\n",
    "#  'lambda_l1': 0.45619796864269707,\n",
    "#  'lambda_l2': 0.033257384218246686,\n",
    "#  'learning_rate': 0.007,\n",
    "#  'max_depth': 14,\n",
    "#  'metric': 'multiclass',\n",
    "#  'n_estimators': 10000,\n",
    "#  'num_classes': 4,\n",
    "#  'num_leaves': 31,\n",
    "#  'objective': 'multiclass',\n",
    "#  'random_state': 2019,\n",
    "#  'subsample': 0.9500000000000001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../dsb2019/models/regression_baseline_round_params.json\", \"w\") as f:\n",
    "    json.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model=train_baseline(train_features.drop([\"installation_id\", \"accuracy_group\"], axis=1), train_features.accuracy_group.values, \n",
    "               params=best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cross_validate(train_features, train_features.accuracy_group, make_features_wrapper, partial(train_baseline, params=best_params), \n",
    "                             make_predictions)\n",
    "np.mean([mean_squared_error(true, pred) for pred, true in predictions]), [mean_squared_error(true, pred) for pred, true in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.save_model(str(MODELS_DIR / \"regression_baseline_round.lgb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target = make_features(train_features)\n",
    "prediction=baseline_model.predict(features)\n",
    "clf = ThresholdClassifier()\n",
    "clf.fit(prediction, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.coef_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
